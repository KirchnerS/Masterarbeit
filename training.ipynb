{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a6ddffa6c384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()\n",
    "#os.chdir('c:\\\\Users\\\\Kirchner\\\\Desktop\\\\Masterarbeit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 50\n",
    "# def read_annotations(txt_name, mode):\n",
    "#     texts = []\n",
    "#     labels = []\n",
    "\n",
    "#     with open (txt_name, encoding = \"utf-8\", mode = \"r+\") as f:\n",
    "#         for line in f.readlines():\n",
    "#             texts.append(line.split(\"\\t\")[8])\n",
    "#             if mode == \"opinion\":\n",
    "#                 labels.append(line.split(\"\\t\")[5])\n",
    "#             elif mode == \"sentiment\":\n",
    "#                 labels.append(line.split(\"\\t\")[6])\n",
    "#             else:\n",
    "#                 print(f\"There is no label for {mode}\")\n",
    "\n",
    "#     return texts,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meine_texte, meine_labels  = read_annotations(\"cleaned_annotated_data_training.txt\", \"sentiment\")\n",
    "\n",
    "# texts_train = meine_texte[:train_size]\n",
    "# texts_test = meine_texte[train_size:]\n",
    "# labels_train = meine_labels[:train_size]\n",
    "# labels_test = meine_labels[train_size:]\n",
    "\n",
    "# print(len(labels_train), len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we import the tokenizer that we already trained if we change the flag to False, otherwise we take the default\n",
    "### model\n",
    "default = True\n",
    "if os.path.isdir(\"meine_tokenizer\") and not default:\n",
    "    print(\"Loading finetuned tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meine_tokenizer_10E_sentiment_500\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "if os.path.isdir(\"Sentiment_Bert_mit_spiegel\") and not default:\n",
    "    print(\"Loading finetuned model...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"Sentiment_Bert_mit_spiegel_10E_sentiment_500\")\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'negative', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809aa30c5fc548cb851c9787b578d5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23ac1a8d02a4de98ca63bf99aa01c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.632600</td>\n",
       "      <td>0.707747</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>9.786900</td>\n",
       "      <td>31.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>0.769817</td>\n",
       "      <td>0.668852</td>\n",
       "      <td>9.790200</td>\n",
       "      <td>31.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>1.031478</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>9.831000</td>\n",
       "      <td>31.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>1.484996</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>9.823500</td>\n",
       "      <td>31.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>1.884604</td>\n",
       "      <td>0.659016</td>\n",
       "      <td>9.893600</td>\n",
       "      <td>30.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>1.986675</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.813900</td>\n",
       "      <td>31.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>2.206053</td>\n",
       "      <td>0.681967</td>\n",
       "      <td>9.803400</td>\n",
       "      <td>31.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>2.267210</td>\n",
       "      <td>0.678689</td>\n",
       "      <td>9.803700</td>\n",
       "      <td>31.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>2.320161</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.798400</td>\n",
       "      <td>31.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>2.387798</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.887400</td>\n",
       "      <td>30.847000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 2 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 2\n",
      " 1 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 2 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 1 1 1 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 0 1 1 2 2 2 1 1\n",
      " 1 2 2 2 1 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [1 1 0 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 0 1 1 1 1 1 1 2\n",
      " 1 2 0 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 0 1 2 1 1 1 1 2 1 1\n",
      " 0 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 0 1 2 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 1 1 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 1 2 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 0 1 1 2 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [1 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 0 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 1 0 1 2 1 1 1 1 2 2 2\n",
      " 0 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1\n",
      " 0 2 2 2 2 2 1 2 1 2 2 2 2 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1\n",
      " 1 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 1 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 2 2 2 1 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 2 2 1 2 1 2 1 1 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 0 1 2 1 1 1 1 2 1 2\n",
      " 0 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 2 2 1 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 1 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 0 1 1 2 1 1 1 1\n",
      " 1 2 2 2 1 1 1 1 1] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 1 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 2 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 0 1 2 1 1 1 1 2 2 2\n",
      " 0 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 1 2 1 2 1 0 2 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 2\n",
      " 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 2 1 1 1 0 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 0 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 0 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a68ecee5ece470ab8f8b77f440ed755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fde903d47e4a6f943bce0ad4bb172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.740900</td>\n",
       "      <td>0.660094</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>9.839400</td>\n",
       "      <td>30.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.728909</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>9.750900</td>\n",
       "      <td>31.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>1.141877</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>9.899800</td>\n",
       "      <td>30.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>1.551630</td>\n",
       "      <td>0.695082</td>\n",
       "      <td>9.824600</td>\n",
       "      <td>31.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>1.897262</td>\n",
       "      <td>0.662295</td>\n",
       "      <td>9.834300</td>\n",
       "      <td>31.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>1.901902</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>9.756200</td>\n",
       "      <td>31.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>2.076849</td>\n",
       "      <td>0.652459</td>\n",
       "      <td>9.896900</td>\n",
       "      <td>30.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>2.204491</td>\n",
       "      <td>0.665574</td>\n",
       "      <td>9.905500</td>\n",
       "      <td>30.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>2.335374</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>9.918300</td>\n",
       "      <td>30.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>2.357194</td>\n",
       "      <td>0.662295</td>\n",
       "      <td>9.839000</td>\n",
       "      <td>30.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 0 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 2 1 1 1 2 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 0 2 1 1 2 2 2 1 1 1 1 2 1 0 2 2 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 1 2 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 0 2 1 2 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 0 1 2 2 1 1 1 2\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 1 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 2 2 1 2 1 1 2 2 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 2 2 1 1 1 2\n",
      " 2 2 1 1 1 1 1 1 0 1 1 1 2 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2 2 1 2 1 2\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 2 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 2 2 0 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 0 1 1 1 2 1 2 1 2 1 2 2 2 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 1 2 2 1 1 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 2 2 1 1 1 2\n",
      " 2 2 1 1 1 1 1 1 0 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 1 1 1 1 0 1 1 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2\n",
      " 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 0 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 0 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 0 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 1 1 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 0 2\n",
      " 2 2 1 1 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 1 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 2 1 2 1 1 2 1 2 2 1 2 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c714c2b617fe44e8a7414f84408ebb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153a243b0ba84d7c837388fee2577b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.716900</td>\n",
       "      <td>0.694590</td>\n",
       "      <td>0.685246</td>\n",
       "      <td>10.011400</td>\n",
       "      <td>30.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.807873</td>\n",
       "      <td>0.665574</td>\n",
       "      <td>9.951600</td>\n",
       "      <td>30.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>1.140784</td>\n",
       "      <td>0.645902</td>\n",
       "      <td>9.953100</td>\n",
       "      <td>30.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>1.661156</td>\n",
       "      <td>0.632787</td>\n",
       "      <td>10.023300</td>\n",
       "      <td>30.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>2.039891</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>10.001100</td>\n",
       "      <td>30.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>2.158947</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>10.004500</td>\n",
       "      <td>30.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>2.279195</td>\n",
       "      <td>0.642623</td>\n",
       "      <td>10.017400</td>\n",
       "      <td>30.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.427160</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>9.941900</td>\n",
       "      <td>30.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>2.470231</td>\n",
       "      <td>0.652459</td>\n",
       "      <td>10.001800</td>\n",
       "      <td>30.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>2.566108</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>10.121600</td>\n",
       "      <td>30.133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2\n",
      " 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 2 1 1 1 1 1 1 1 2 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 1 2 0 1 1 1 2 1 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 2 1 1 1 2 1 1 1 1 1 2 2 1 1 1 0 1 1 1\n",
      " 0 1 2 1 1 2 0 1 2 2 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 1 2 2 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1\n",
      " 1 2 1 2 1 1 2 1 1] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [1 1 1 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 0 1 2 1 2 1 1 1 1 1 2\n",
      " 1 2 2 2 2 2 1 2 2 1 1 1 2 2 1 1 1 0 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 1 2 2 2\n",
      " 1 1 1 2 1 1 1 2 1 1 1 0 1 1 1 1 1 1 2 1 1 1 1 2 0 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 0 1 2 1 1 1 0 1 1 2 1 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1\n",
      " 1 1 2 1 2 1 0 1 2 2 1 2 1 0 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 2 0 1 1\n",
      " 1 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 2 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 2 1 1 1 2 2 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 2 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 1 2 0 2 1 1 1 2 1 1 2 2 1 2 2 1 1 1 0 2 1 2\n",
      " 2 1 2 1 1 2 0 1 1 2 2 2 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 2 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 0 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 0 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 2 0 1 2 2 2 2 1 1 2 2 2 0 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 0 1 2 2 1 1 2 1 0 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 1 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 2 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 0 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 0 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 0 1 2 2 1 1 2 1 0 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 2 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 2 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 2 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 2 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 2 2 2 2 1 1 2 1 2 2 1 1 1 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 1 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 0 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 2 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 2 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba6f5ae85f847868213bfe7bbbd4bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21963b1c3e9541b5a892c19361e91255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.745369</td>\n",
       "      <td>0.634868</td>\n",
       "      <td>10.223300</td>\n",
       "      <td>29.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.793736</td>\n",
       "      <td>0.638158</td>\n",
       "      <td>10.166500</td>\n",
       "      <td>29.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>1.057242</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.224800</td>\n",
       "      <td>29.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>1.513468</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.323400</td>\n",
       "      <td>29.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>1.772506</td>\n",
       "      <td>0.641447</td>\n",
       "      <td>10.154800</td>\n",
       "      <td>29.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>2.146400</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10.157700</td>\n",
       "      <td>29.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>2.136032</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10.207800</td>\n",
       "      <td>29.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>2.245049</td>\n",
       "      <td>0.621711</td>\n",
       "      <td>10.226800</td>\n",
       "      <td>29.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>2.434262</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>10.238200</td>\n",
       "      <td>29.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>2.476676</td>\n",
       "      <td>0.634868</td>\n",
       "      <td>10.320700</td>\n",
       "      <td>29.455000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 1 1 2 2 1\n",
      " 2 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 2\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1\n",
      " 1 1 1 2 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 2 1 1 1 2 1 1\n",
      " 2 1 1 1 1 1 2 1] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 1 2 1 2 1 1 1 2 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2\n",
      " 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 2 1 1 1 1 2 2 1\n",
      " 2 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 2\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 2 1 1 1 2\n",
      " 1 1 1 0 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 0 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1\n",
      " 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 1] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 2 1 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 1 1 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 0 1 2 1 1 2 1 2\n",
      " 1 1 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 2 0 2 2 1 2 1 1 1 1 2 1 2 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 1 1 1 2 1 0 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 1 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 1 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 2 1 1 0 2 2 2 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 2 1 2 1 1 1 2 1 2 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 0 2 1 2 2 1 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 2 1 0 2 1 2 1 1 1 2 2 1 2 1 2 1 1 2 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 2 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 2 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 1 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 2 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 1 1 0 2 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 0 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12f8cb3d99a4706b030bd27edb5796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ad267b43f948138319301a136e13d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>0.803334</td>\n",
       "      <td>0.641447</td>\n",
       "      <td>9.999100</td>\n",
       "      <td>30.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.836447</td>\n",
       "      <td>0.654605</td>\n",
       "      <td>10.002300</td>\n",
       "      <td>30.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>1.390960</td>\n",
       "      <td>0.572368</td>\n",
       "      <td>9.999800</td>\n",
       "      <td>30.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>1.543026</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.017400</td>\n",
       "      <td>30.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>1.986813</td>\n",
       "      <td>0.601974</td>\n",
       "      <td>10.032600</td>\n",
       "      <td>30.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>2.164478</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>9.927600</td>\n",
       "      <td>30.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>2.321298</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>10.039400</td>\n",
       "      <td>30.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>2.476327</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>10.091400</td>\n",
       "      <td>30.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>2.412344</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>10.102600</td>\n",
       "      <td>30.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>2.613653</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>9.959000</td>\n",
       "      <td>30.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 2 1 2 1\n",
      " 1 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 1 2 1\n",
      " 1 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 1 1 1 2 2 0 1 1 1 1 1 1 0 1 2 1 1 1 1 2 2 1 1 2 2 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 2 1 1 2 1 2 1 1 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 1 2 2 2 1 1 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1\n",
      " 1 1 1 1 1 2 2 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 2 1\n",
      " 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 1 1 1 2 2 0 1 1 1 1 1 1 0 1 1 1 1 1 2 2 2 1 1 2 2 2 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 1 1 1 2 2 2 1 1 1 2 1 2 1 1\n",
      " 2 1 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 2 1 1 2 2 1 1 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 2 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 1 1 2 1 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 2 2 1 2 2 1 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 1 2 1 2 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 1 2 1 1 2 1 1 2 2 1 1 2 1 2 2 2 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 2 2 2 0 2 2 2 1 1 1 0 2 2 2 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 2 2 2 2 2 1 1 1 2 1 1 2 1 2 2 2 2 1 2 2 1 2 2 1 2 2 2 1 1 1 2 2 2 2 2\n",
      " 2 2 1 1 2 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 2 2 0 1 1 2\n",
      " 2 1 2 1 2 2 2 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 1 2 1 2 2 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 1 1 2 2\n",
      " 1 2 1 1 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 1 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 1 2 2 0 1\n",
      " 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 1 2 2 1 1 2 2 2 2 1 1 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 0 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 0 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 2 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 1 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 1 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "data_text = []\n",
    "data_labels = []\n",
    "text_train = []\n",
    "labels_train = []\n",
    "text_test = np.array([])\n",
    "labels_test = np.array([])\n",
    "\n",
    "\n",
    "label_to_id = {\"positive\" : 0, \"negative\" : 1, \"neutral\" : 2}\n",
    "id_to_label = {0:\"positive\", 1:\"negative\", 2:\"neutral\"}\n",
    "\n",
    "### Here we create a training set that can be used to compare across different sizes of training data\n",
    "\n",
    "mein_dataframe1 = pd.read_csv(\"annotated_data_with_users_automatic.csv\", header=None)\n",
    "mein_dataframe1.columns = [\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\",\n",
    "                          \"topic_comment\", \"Topic_article\", \"Comment\", \"Method\"]\n",
    "\n",
    "display(len(mein_dataframe1))\n",
    "# split_index = int(len(mein_dataframe1)*0.8)\n",
    "for index, row in mein_dataframe1.iterrows():\n",
    "    data_text.append(row[\"Comment\"])\n",
    "    data_labels.append(row[\"Sentiment\"])\n",
    "\n",
    "print(data_labels)   \n",
    "# ### Define test and train set\n",
    "# text_test = text_train[split_index+1:]\n",
    "# text_train = text_train[:split_index]\n",
    "# labels_test = labels_train[split_index+1:]\n",
    "# labels_train = labels_train[:split_index]\n",
    "\n",
    "\n",
    "### Replace label as int\n",
    "for idx, labels in enumerate(data_labels):\n",
    "    data_labels[idx] = label_to_id[labels]\n",
    "\n",
    "\n",
    "# for idx, labels in enumerate(labels_test):\n",
    "#     labels_test[idx] = label_to_id[labels]\n",
    "    \n",
    "    \n",
    "\n",
    "# with open (\"cleaned_annotated_data_training.txt\", encoding=\"utf-8\", mode=\"r+\") as f:\n",
    "#     training_data = f.readlines()\n",
    "#     split_index = int(len(mein_dataframe1)*0.8)\n",
    "    \n",
    "#     ### The split on index 6 gives us Sentiment, split on 5 Opinion\n",
    "    \n",
    "#     ### The first 88 annotations had been annotated without a article topic\n",
    "#     for line in training_data[:88]:\n",
    "#         text_train.append(line.split(\"\\t\")[8])\n",
    "#         labels_train.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "#     for line in training_data[89:split_index]:\n",
    "#         text_train.append(line.split(\"\\t\")[9])\n",
    "#         labels_train.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "#     for line in training_data[split_index+1:]:\n",
    "#         text_test.append(line.split(\"\\t\")[9])\n",
    "#         labels_test.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding = True, truncation=True)\n",
    "\n",
    "def calculate_entropy(logits):\n",
    "    probas = torch.nn.Softmax(dim=1)(torch.from_numpy(logits))\n",
    "    samples_entropy = entropy(probas.transpose(0, 1).cpu())\n",
    "    samples_entropy = torch.from_numpy(samples_entropy)\n",
    "    return samples_entropy\n",
    "\n",
    "def compute_metrics_accuracy(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        print(\"Predictions\", predictions, \"Labels\", labels)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "### Define splits for k fold cross validation\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "### Convert to numpy array\n",
    "data_text = np.array([i for i in data_text])\n",
    "data_labels = np.array([i for i in data_labels])\n",
    "\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "metric = load_metric(\"accuracy\")\n",
    "hello = []\n",
    "for train_index, test_index in folds.split(data_text, data_labels):\n",
    "    text_train, labels_train  = data_text[train_index], data_labels[train_index]\n",
    "    text_test, labels_test  = data_text[test_index], data_labels[test_index]\n",
    "\n",
    "    train_dict = {\"texts\": text_train, \"labels\" : labels_train}\n",
    "    test_dict = {\"texts\": text_test, \"labels\" : labels_test}\n",
    "\n",
    "    # print([len(z) for z in [text_train, text_test]])\n",
    "\n",
    "\n",
    "    ### Remove newline characters\n",
    "    for idx, text in enumerate(train_dict[\"texts\"]):\n",
    "        train_dict[\"texts\"][idx] = text.rstrip(\"\\n\")\n",
    "\n",
    "    for idx2, text2 in enumerate(test_dict[\"texts\"]):\n",
    "        test_dict[\"texts\"][idx2] = text2.rstrip(\"\\n\")\n",
    "        \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    meine_dataset_train = Dataset.from_dict(train_dict)\n",
    "\n",
    "    mein_dataset_test = Dataset.from_dict(test_dict)\n",
    "\n",
    "    tokenized_dataset_train = meine_dataset_train.map(preprocess_function, batched= True)\n",
    "    tokenized_dataset_test = mein_dataset_test.map(preprocess_function, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model= AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\"),\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset_train,\n",
    "        eval_dataset=tokenized_dataset_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics = compute_metrics_accuracy\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "#     index_topk = torch.topk(calculate_entropy(trainer.predict(tokenized_dataset_test).predictions), 20).indices\n",
    "#     print(index_topk)\n",
    "#     for x in index_topk:\n",
    "#         print(meine_dataset_train[\"texts\"][x], \"SATZ\")\n",
    "    accuracies.append(trainer.evaluate()['eval_accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6401488352027609"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cross validated accuracy\n",
    "print(len(text_train))\n",
    "sum(accuracies)/len(accuracies)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text_tokenized = tokenizer(text_train, truncation=True, padding=True)\n",
    "\n",
    "# test_text_tokenized = tokenizer(text_test, truncation=True, padding=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding = True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b87b2cbca73061b8\n",
      "Reusing dataset text (C:\\Users\\Kirchner\\.cache\\huggingface\\datasets\\text\\default-b87b2cbca73061b8\\0.0.0\\e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "100%|██████████| 2/2 [00:00<00:00, 795.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# spiegel = SpiegelDataset(\"cleaned_annotated_data_training.txt\")\n",
    "\n",
    "# spiegel_data = load_dataset(\"text\", data_files={\"train\": \"Spiegel_train.txt\", \"test\" : \"Spiegel_test.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c72160823f460793d6a558ba67693b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bf08d370394d8287aee2c48336df4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dict = {\"texts\" : text_test,\n",
    "            \"labels\" : labels_test}\n",
    "            \n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(\"Predictions\", predictions, \"Labels\", labels)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "meine_dataset_train = Dataset.from_dict(train_dict)\n",
    "\n",
    "mein_dataset_test = Dataset.from_dict(test_dict)\n",
    "\n",
    "\n",
    "tokenized_dataset_train = meine_dataset_train.map(preprocess_function, batched= True)\n",
    "tokenized_dataset_test = mein_dataset_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "158\n",
      "514\n",
      "149\n",
      "285\n",
      "228\n",
      "379\n",
      "197\n",
      "373\n",
      "242\n",
      "399\n",
      "547\n",
      "252\n",
      "669\n",
      "105\n",
      "601\n",
      "944\n",
      "301\n",
      "353\n",
      "329\n",
      "216\n",
      "315\n",
      "149\n",
      "244\n",
      "423\n",
      "589\n",
      "369\n",
      "434\n",
      "392\n",
      "594\n",
      "137\n",
      "457\n",
      "417\n",
      "147\n",
      "298\n",
      "117\n",
      "561\n",
      "62\n",
      "389\n",
      "312\n",
      "180\n",
      "661\n",
      "160\n",
      "173\n",
      "132\n",
      "85\n",
      "650\n",
      "174\n",
      "398\n",
      "703\n",
      "891\n",
      "454\n",
      "120\n",
      "220\n",
      "1074\n",
      "159\n",
      "238\n",
      "534\n",
      "451\n",
      "431\n",
      "181\n",
      "308\n",
      "117\n",
      "146\n",
      "84\n",
      "468\n",
      "100\n",
      "306\n",
      "193\n",
      "167\n",
      "554\n",
      "79\n",
      "771\n",
      "409\n",
      "846\n",
      "403\n",
      "350\n",
      "477\n",
      "193\n",
      "296\n",
      "635\n",
      "274\n",
      "201\n",
      "191\n",
      "347\n",
      "124\n",
      "796\n",
      "173\n",
      "550\n",
      "109\n",
      "318\n",
      "211\n",
      "81\n",
      "537\n",
      "781\n",
      "459\n",
      "513\n",
      "106\n",
      "374\n",
      "156\n",
      "312\n",
      "156\n",
      "168\n",
      "310\n",
      "97\n",
      "250\n",
      "131\n",
      "93\n",
      "323\n",
      "136\n",
      "214\n",
      "339\n",
      "188\n",
      "545\n",
      "391\n",
      "375\n",
      "313\n",
      "691\n",
      "424\n",
      "333\n",
      "510\n",
      "253\n",
      "480\n",
      "178\n",
      "126\n",
      "203\n",
      "130\n",
      "270\n",
      "436\n",
      "376\n",
      "360\n",
      "263\n",
      "539\n",
      "547\n",
      "174\n",
      "222\n",
      "254\n",
      "226\n",
      "328\n",
      "660\n",
      "263\n",
      "238\n",
      "562\n",
      "70\n",
      "821\n",
      "328\n",
      "378\n",
      "702\n",
      "190\n",
      "509\n",
      "294\n",
      "449\n",
      "409\n",
      "151\n",
      "406\n",
      "675\n",
      "345\n",
      "414\n",
      "313\n",
      "297\n",
      "233\n",
      "101\n",
      "275\n",
      "428\n",
      "494\n",
      "466\n",
      "70\n",
      "510\n",
      "1376\n",
      "326\n",
      "287\n",
      "455\n",
      "241\n",
      "983\n",
      "345\n",
      "278\n",
      "292\n",
      "264\n",
      "138\n",
      "135\n",
      "105\n",
      "236\n",
      "468\n",
      "359\n",
      "364\n",
      "433\n",
      "300\n",
      "741\n",
      "352\n",
      "137\n",
      "124\n",
      "197\n",
      "929\n",
      "188\n",
      "844\n",
      "206\n",
      "181\n",
      "132\n",
      "144\n",
      "91\n",
      "207\n",
      "104\n",
      "439\n",
      "289\n",
      "306\n",
      "104\n",
      "873\n",
      "459\n",
      "397\n",
      "252\n",
      "576\n",
      "471\n",
      "121\n",
      "386\n",
      "257\n",
      "97\n",
      "118\n",
      "234\n",
      "444\n",
      "648\n",
      "572\n",
      "281\n",
      "288\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_dataset_test[\"texts\"]:\n",
    "    print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1130' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1130/1130 15:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.751194</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>12.594500</td>\n",
       "      <td>17.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.883527</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>10.334500</td>\n",
       "      <td>21.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.501034</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>10.227100</td>\n",
       "      <td>21.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>2.193896</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>10.247200</td>\n",
       "      <td>21.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>2.759660</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>10.233900</td>\n",
       "      <td>21.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>3.217661</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>12.104400</td>\n",
       "      <td>18.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.350807</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>11.324300</td>\n",
       "      <td>19.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>3.392122</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>10.154500</td>\n",
       "      <td>22.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.372744</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>10.282700</td>\n",
       "      <td>21.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>3.416090</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>10.338800</td>\n",
       "      <td>21.666000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 1 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 2 1 0 1\n",
      " 2 1 0 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 0 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 1 2 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 1 1 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1\n",
      " 1 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 2 2 2 2 1 1 2 1 1 1 2 2 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 1 1 1 2 1 1 2 1 2 2 2 2 1 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 2 2 1 1 1 2 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2\n",
      " 2 2 1 2 2 1 2 2 1 2 2 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 2 2 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 1 0 1 1 1 2 1 2 1 1 2 1 2 2 1 1 2 1 2 1\n",
      " 2 1 0 1 1 2 1 2 1 2 2 1 1 1 1 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 2 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 1 2 1\n",
      " 1 1 1 2 1 2 1 2 2 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1\n",
      " 1 1] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 2 1 1 1\n",
      " 2 1 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 1 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 0 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 0 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 2 2 2\n",
      " 2 2 1 2 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 2 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 2 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 1 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 0 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 1 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 0 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1130, training_loss=0.25791671365639607, metrics={'train_runtime': 913.8611, 'train_samples_per_second': 1.237, 'total_flos': 2339215992120240, 'epoch': 10.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics_accuracy\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX TITAN X'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('meine_tokenizer_10E_sentiment_1000_2e-5/tokenizer_config.json',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/special_tokens_map.json',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/vocab.txt',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save_pretrained(\"Sentiment_Bert_mit_spiegel_10E_sentiment_1000_2e-5\")\n",
    "tokenizer.save_pretrained(\"meine_tokenizer_10E_sentiment_1000_2e-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "len(train_text_tokenized[\"attention_mask\"])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/730226842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\data\\data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         batch = self.tokenizer.pad(\n\u001b[0m\u001b[0;32m    222\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m             raise ValueError(\n\u001b[1;32m-> 2693\u001b[1;33m                 \u001b[1;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m                 \u001b[1;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# training_args = TrainingArguments(output_dir=\"./results\",\n",
    "#                     learning_rate=2e-5,\n",
    "#                     per_device_eval_batch_size=4,\n",
    "#                     per_device_train_batch_size=4,\n",
    "#                     num_train_epochs=3,\n",
    "#                     weight_decay=0.01\n",
    "#                     )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             train_dataset=train_text_tokenized,\n",
    "#             eval_dataset=test_text_tokenized,\n",
    "#             tokenizer = tokenizer,\n",
    "#             data_collator= data_collator\n",
    "# )\n",
    "\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nachtrag: Dieser Artikel ist wirklich enttäuschend. Dass es manchem Leser vielleicht schwerfällt, sich an den Ablauf der Ereignisse zu erinnern, oder diese in einen Kontext zu setzen, okay. Aber der Spiegel? Da könnte man ja wirklich vermuten, das sei Click-Baiting, um Seitenaufrufe zu generieren, oder vom US-Außenministerium abgeschrieben. Wahrscheinlich aber doch einfach nur Naivität und leichte Beeinflussbarkeit der Autoren.\\n',\n",
       " 'Ein Flugzeug aus China macht noch keinen Frühling. Die Kritik dieses Artikels ist völlig unangebracht. Die EU hat gesundheitspolitisch fast keine Befugnisse. Das ist so gewollt und an sich auch sehr vorteilhaft. Koordinierte politische Aktionen auf europäischer Ebene würden hier gar nicht weiterhelfen. Jede Region in Europa trifft die für sie und der Lage angemessenen Entscheidungen. Das gibt dann kein einheitliches Bild ab, aber der Virus tritt auch nicht überall einheitlich auf. Die einzige Ebene auf der ein Austausch wirklich erforderlich ist, ist die wissenschaftliche Ebene. Und da findet ein Austausch sehr wohl und sehr gut über die WHO statt. Der Artikel ist nur papperlapapp. \\n',\n",
       " 'Ganz Belgien hatte einen Wert von 1750 über 14 Tage. Wollten die Protestierer vielleicht den belgischen Rekord brechen?\\n',\n",
       " 'Ganz ehrlich als ich da war gestern, war nur etwas Stau in der Innenstadt, aber sonst freie Fahrt,,,,,, auf den Bergen fanden sich Menschen mit aus eigenem Interesse, Abstand und joar ansich sehr transparent , das Foto beweist doch nur geparkte Autos stehen ordentlich in der Reihe!! Und ein Auto ist unterwegs. Hut ab! Leute geniesst eure Freiheit!,,,,,\\n',\n",
       " '\"Der Anstieg der Sterblichkeit könnte mit der seit Oktober steigenden Zahl der Corona-Toten in Deutschland zusammenhängen.\" - Da war offensichtlich Sherlock Holmes am Werk.\\n',\n",
       " 'Es scheint so, als würden durch das Virus allgemein viele Abgründe oder unschöne Eigenschaften ans Licht kommen, die bisher nicht auffielen. Nach der Krise wird man sich viele grundliegende Fragen stellen müssen.\\n',\n",
       " 'Die Anzahl der Tests in KW52 lag 1/3 geringer als in der Woche davor. In BW und Bayern haben wir am Mittwoch einen Feiertag. Erst danach werden alle Laborkapazitäten wieder voll zur Verfügung.im Moment irgendwelche Entwicklungen aus den gemeldeten Zahlen abzulesen, ist wohl eher der Blick in eine Glaskugel aus Milchglas.  Kann mit allerdings schon vorstellen, dass Nebeneffekte wie Schulschließungen und geringere Nutzung der öffentlichen Verkehrsmittel einen Einfluss haben.\\n',\n",
       " 'SPON: Die \"Industrie\" ist keine Branche sondern ein Sektor\\n',\n",
       " 'SPON: Die \"Industrie\" ist keine Branche sondern ein Sektor\\n',\n",
       " 'Wer oder was hindert Söder denn, in Bayern zu tun was er für richtig hält. Außerhalb Bayerns hat ihn jedenfalls keiner zum Mitbestimmer ernannt. (Gilt selbstverständlich jeweils auch für alle anderen MPs.)\\n',\n",
       " 'Herr Gassen weiß aber auch nicht was er will, erst hat er im Oktober alles für übertrieben erklärt und jetzt ist bei ihm sogar ein lockdown keine geeignete Massnahme. Was qualifiziert ihn eigentlich, sich die ganze Zeit zu der Sache zu äußern? Er ist weder Virologe noch hat er Erfahrungen mit Pandemien. Evtl sollte man auch Mal aufhören ihm auch immer zu Wort kommen lassen. Dafür gibt es außerhalb von Telegramm Fachleute.\\n',\n",
       " 'Man könnte fast vermuten dass die ganze Veranstaltung ein vorgezogener Aprilscherz war. Wirklich ernst nehmen kann man die Ergebnisse der Ministerpräsidenten Konferenzen nicht mehr wenn selbst die Teilnehmer 2 Tage danach noch immer nicht konkret erklären können, was sie da eigentlich beschlossen haben. Es ist höchste Zeit für einen Wechsel in Berlin. Eine gute Idee wäre, für jeden Tag sinnlosen Lockdowns minus 1% im Wahlergebnis beider Regierungsparteien. \\n',\n",
       " 'Nicht nur dass der Impfstoff der effektivste und wirksamste ist, nein, er kann auch am besten gelagert werden.   Deutsche und Amerikaner. Wer sonst. \\n',\n",
       " 'Millionen von ausländischen Arbeitskräften sind nach den Feiertagen wieder eingereist. Da hieß es: registrieren, 5 Tage Quarantäne, dann Test. (also für diejenigen, die sich dran gehalten haben, versteht sich)  wer testet, der findet. \\n',\n",
       " 'Alle reden nur von Vorteilen/Rückgabe der Grundrechte für Geimpfte!  Wie wärs mal, wenn wir über Lockerungen für alle reden, jetzt wo die Durchimpfung der Risikogruppe in den nächsten Wochen abgeschlossen ist?\\n',\n",
       " 'In der medialen Darstellung sind die Neuinfektionen irrelevant (da Dunkelziffer vorhanden). Die wirklich wichtigen Zahlen sollten sein: von den 18.000 positiv Getesteten sind X in Behandlung, davon Y intensiv, die Auslastung der Betten ist Z. Und dazu einen Vergleich / Trend zur Vorwoche.\\n',\n",
       " 'Wenn sich der Einzelhandel nicht gegen die Aufhebung der Maskenpflicht wehrt, gibts halt die Sontagsbrötchen auch noch von Amazon. Spahn hat genug verbockt um ihn endlich abzusägen.\\n',\n",
       " 'Im März/April wurde zumindest noch argumentiert, dass harte Maßnahmen auch wirtschaftlich besser seien, weil man so schneller zur Normalität zurück kommen könnte. Diese These kann man inzwischen verwerfen. Was allerdings schon lange bestätigt ist: Die positive Korrelation zwischen Wirtschaftskraft und Lebenserwartung . Zu glauben, dass ein wirtschaftlicher Einbruch nicht auch zu Todesopfern führt ist reichlich naiv. Allerdings sind die Zusammenhänge komplexer.\\n',\n",
       " 'Die Reaktion von Tschechien, keine Hilfe von Deutschland anzunehmen, ist tragisch und d.umm zugleich. Da geht man vor lauter Stolz offensichtlich über Leichen.\\n',\n",
       " 'Ich würde da den Biotech -Impfstoff vorziehen, als mich auf Daten einer womöglich von Trump-Genossen  unterwanderten Zulassungsbehörde zu verlassen\\n',\n",
       " 'Auch wenn das RKI den Anteil der Geimpften an der Gesamtbevölkerung noch nicht angibt, ist es doch ziemlich leicht, dieses selbst zu ermitteln, da die Einwohnerzahlen sowohl für ganz Deutschland als auch die Bundesländer bekannt ist. Für die Faulen: momentan (01.01.2021, Zahlen von 12:30 Uhr) hat Deutschland bei 83,166 Millionen Einwohnern eine Erst-Impfquote von übersichtlichen 0,199 %. Da ist noch Luft nach oben.\\n',\n",
       " 'Was wird passieren:  Ein guter Teil des Volkes hat bisher die Maßnahmen der Regierung akzeptiert und mitgetragen  Nur: Immer mehr stellt man fest, dass die Bundesländer durch die Bank durch es in 7 Monaten Cororna nicht geschafft haben, irgendetwas substantiell zu ändern Nur der Status Quo vom März wurde besser verwaltet  Frtschritte: Fehlanzeige Maßnahmen, die weiterbringen: Fehlanzeige oder im Streit der Landesfürsten steckengeblieben  Und was passiert jetzt: Nun droht man auch den Rückhalt des Volkes zu verlieren, denn das was nun vorgeschlagen wird, das reicht nicht aus, um für die Zukunft zu planen, sondern es ist nur ein Spiel auf Zeit  Das agieren planloser und mutloser Landesfürsten, die die Großmutter evrscherbeln würden , um die Macht zu erhalten  Zukunftsplanung ist was anderes\\n',\n",
       " '\"60 Prozent der Krankenhausfälle bei komplett Geimpften\"  Und jetzt? Wir werden hier doch komplett v. a r. sch.t inzwischen!  Vielmehr scheinen die unterdrückten Studien und Warnungen recht zu haben, die sagen, dass es so nicht funktionieren und das Virus doppelt und dreifach zurückschlagen wird.\\n',\n",
       " 'Völlig unausgegoren, eigensinnig, unüberlegt und einsichtsresistent! Die Regierung hat sich in eine Sackgasse manöviert und findet mit ihren Mitteln nicht mehr heraus!\\n',\n",
       " 'Irgendwie hat man hier den Eindruck - die Masse der LockDowner - gehört bereits der Risikogruppe an. Und befindet sich in Todesangst.  Das ist nur konditioniert, möchte man den Verzweifelten entgegen rufen. Die Chance an Krebs zu sterben ist rund 50 Mal höher.\\n',\n",
       " 'Super Idee, da kann Spahn wieder mal tüchtig einkaufen. Babys sollten auch nicht vergessen werden.\\n',\n",
       " 'Diese maßlose Selbstüberhöhung ist Teil des Narrativs der sogenannten Querdenker. Da ist kein Vergleich zu peinlich. Sich unterdrückt und verfolgt zu fühlen, während man in aller Öffentlichkeit unter den Augen der Polizei Reden schwingt, dazu gehört schon ein gigantisches Maß an Realitätsverweigerung. Dieses Gefühl der eigenen Unterdrückung und des Nicht-Teilhaben-Dürfens am Wissen der Mächten ist wohl der Kitt, welcher Esoteriker, Ökos, Wutbürger und Neonazis in ihrem Ungeist miteinander verbindet. \\n',\n",
       " 'Für seinen  Satz sollte Herr Scheele den Bundesverdienstorden bekommen.Solche Menschen braucht unser Land!\\n',\n",
       " '\"CDU-Politiker Rudolf Henke spricht sich für schrittweise Lockerungen aus.\" Ich will einfach nicht begreifen, dass die klare Vorgabe, die von der Politik von Anfang gemacht wurde, immer noch diskutiert werden muss und unterschiedlich ausgelegt wird.  Wenn alle ein Impfangebot bekommen haben, fallen alle Einschränkungen weg. Das war von Anfang klar. Vor allem das Maskentragen. So und nicht anders wird es gehen. Ob das Maskentragen für mich eine Beeinträchtigung ist, entscheide ich noch immer selbst. Für mich ist es ein schwerer Eingriff in meine Freiheitsrechte. Das mag jeder für sich entscheiden. Maskentragen ist nach wie vor zu bestimmten Gelegenheit vom Ordnungsamt durchsetzbar und kann bei Zuwiderhandlung mit Bußgeldern belegt werden. Das passt nicht mehr in unsere aktuelle Situation. Die Risikogruppen sind geimpft und wer sich bemüht bekommt auch einen Impftermin. Es muss endlich Schluss sein, mit jeder Art von Bevormundung. Wir sind bereits jetzt in einer Situation, in der jeder selbst entscheiden kann, wie er mit dem Virus umgehen will. FFP2 Masken schützen auch den Träger. Die kann jeder der möchte weiter tragen und wer nicht mehr will, der soll sie endlich selbst bestimmt ablegen können.\\n',\n",
       " '»Wir sollten aber diejenigen Maßnahmen zurücknehmen, die ganz offensichtlich keine Schutzwirkung entfalten.« Revolutionärer Ansatz, die Maßnahmen sollen auf Effektivität überprüft werden. Dann mal los, da geht noch einiges.  Und beim nächsten Mal vielleicht vorher überlegen? Ist ja nicht unser erster Lockdown. \\n',\n",
       " 'Leider trifft es bei pauschaler Kritik immer auch die Falschen. Fakt ist: Das System hat vollkommen versagt; von oben bis unten. Lassen wir die wenigen engagierten Schulen und Lehrer/innen mal außen vor. In meinem Bekanntenkreis gibt es niemanden, der auch nur etwas Positives erkennen kann; Ausnahmen wie vor. In der Privatwirtschaft hätte es keine Hilfen gegeben, weil das System schon vor dem Lockdown insolvent war. Und die Mitarbeiter? Ein Drittel war krank und die anderen beim Brückentag. Es macht mich wütend, weil ich gegen Privatschulen bin, gegen Ungleichbehandlung und für mehr Anerkennung der Arbeit der Lehrer/innen. Das System und die handelnden Akteure haben sich selbst ausgeknockt. \\n',\n",
       " '\"Die Herausforderung ist, dass auf der ganzen Welt alle Länder Schutzausrüstung suchen, bestellen und sich gegenseitig auch weg kaufen. Wir müssen uns auf eine Knappheit einstellen.\"  Genau deshalb haette es sich empfohlen, das bereits vor vier Wochen zu tun. Das naemlich meint man mit VORbereitung. Seit mindestens zwei Monaten weiss man um den Ernst der Lage. In dieser Zeit haette man schon laengst automatische Waermekameras an Flughaefen installieren koennen, sich mit Schutzausruestung eindecken, die Absage von Grossveranstaltungen pruefen, den internationalen Reiseverkehr einschraenken. Man haette auch damals schon die Pandemieplaene aktualisieren koennen. Was haette es geschadet? Selbst wenn man von der Seuche verschont worden waere, waere man auf ein zukuenftiges Ereignis im Sinne einer Uebung besser vorbereitet gewesen. JETZT muesste man in allen Krankenhaeusern nicht notwendige Operationen verschieben, und nicht zu kranke Leute nach Hause schicken. JETZT muesste man in Altenheimen den Zugang einschraenken. JETZT muessten Hausaerzte ihre chronisch kranken Patienten mit Medikamenten fuer drei Monate eindecken. Aber nichts von alledem ist geschehen oder geschieht. Man tut einfach...NICHTS. Es ist absurd.\\n',\n",
       " 'Hört sich an wie eine Auftragsstudie des Herrn Laschet, die seine Vorgehensweise stützen soll.\\n',\n",
       " 'Herr Spahn wählt Formulierungen als wäre er Aussenstehender. Der Typ ist nicht ganz dicht - meine Meinung.\\n',\n",
       " 'Auf die durchaus naheliegende Idee, dass die Zunahme nachgewiesener Infektionen (oder vielmehr Virenbestandteile) etwas mit der drastischen Erhöhung der Tests (inzwischen sogar privat möglich) zu tun haben könnte, kommt man medial offenbar nicht.\\n',\n",
       " 'Dass es den britischen Gesundheitsminister trifft scheint im gewissermaßen multivalenten Sinn \"kein Zufall\"... Es ist bekannt, dass die Wirksamkeit gegen den leichten Verlauf 64 Prozent beträgt. Das heißt doch, ca. 4 von 10 Personen, die ohne Impfung den leichten bekommen hätten, bekommen ihn auch danach - nicht richtig? Und wird übrigens der quizzige mittlere Verlauf zum ganz schwachen ge-kirkt, meistens?\\n',\n",
       " 'Kommt der von Trump befohlene gewaltige  Aufschwung auch in Deutschland???           Ja-----weil die große Mehrheit keine Einkommenseinbussen haben, aber monatelang weniger Möglichkeiten zu Geldausgeben.                                                      Weil viel echter Bedarf oder shoping-Lust.       zu einem Sturm auf die Läden führt.              Weil enorm Staatskohle reingebuttert wird.             NEIN-----weil sehr viele gewaltige Einkommenseinbussen haben.                        Weil sehr viele aus Zukunftsangst ihre Kohle zusammenhalten.                                               Weil sehr viele aus medizinischen Gründen eher selten shoppen gehen, und die blöde Maske ne echte Spaßbremse ist.                    Ich denke, dass die negativen Faktoren überwiegen....   \\n',\n",
       " 'Wenn man bedenkt, das mit einem Schnelltest so ziemlich alles gemacht werden darf…. Habe mir mal so ein Ding auf meinem Handy genauer angeschaut. So einfach das Datum zu ändern, selbst das Negativ Ergebnis ist ohne große Kenntnise zu ändern ( also wenn man positiv wäre) Das heißt, wenn man nur ein wenig Aufwand betreibt, ohne große Gefahr erwischt zu werden, braucht man keine Test mehr zu machen. Wieviel das wohl machen ? Bin mal gespannt wie das mit den Impfpässen weiter läuft…\\n',\n",
       " 'Was nutz es, wenn wir jeden Tag neue Gruppen definieren, die bitte schön als Erste geimpft werden sollen/müssen? Garnichts - solange kein Impfstoff vorhanden ist\\n',\n",
       " 'War nicht vorher die Rede von einer historischen Debatte der MP, also mit diesen Ergebnissen haben diese das Jalta Abkommen komplett in Vergessenheit gebracht. \\n',\n",
       " 'Zitat RKI< Wir wüssten nicht, ob es der Beginn einer zweiten Welle sei, aber er könnte es sein. >  Mit dem was das RKI nicht weiß liesen sich ganze Bibliotheken füllen.   Unvorbereitet in eine Pandemie gestolpert, planlose Aussagen zu Masken, keine Konzepte, keine Medikamente, das RKI ist ein total Ausfall. \\n',\n",
       " 'Düsseldorf ist wegen seiner 120 prozentigen Anglopalaberie bei Britischen Besöfnistouristen sehr beliebt gewesen, aber der Zusammenhang scheint abwegig...🤔\\n',\n",
       " 'In unserer Stadt gibt es gerade das Advents-Gratisparken in allen städtischen Parkhäusern, um dem Einzelhandel zu helfen. Die Grünen beschweren sich nun darüber, weil das ein Schlag ins Gesicht der zahlenden ÖPNV-Nutzer sei.  Ich habe in Anbetracht der ganzjährig samstags vollen Parkhäuser und Parkplätze Bedenken, ob überhaupt so viele Leute aus dem Umland per ÖPNV zum Shoppen in die Stadt kommen.   Wenn sich die Grünen am Gratisparken stören, sollen sie halt die ÖPNV-Tickets im Advent kostenlos machen... ;-)\\n',\n",
       " 'Also wenn man sich die Breite des NASDAQ und die Marktkapitalisierung der darin liegenden Firmen anschaut, dann steht die USA im Vergleich zum DAX nicht schlechter da. Selbst wenn Delivery Hero also die Nummer 30 der deutschen Firmengrößen im DAX auftauchen sollte, kann der NASDAQ dem noch etwas entgegen setzen. Auch europaweit. Und wenn die Infektionswelle in den USA vorbei ist, steht sie Europa noch bevor. Falls man wirklich Europa/USA vergleichen möchte, was auch immer das für einen Sinn fürs persönliche Ego macht, den relativ pauschalen Titel \"Euopa macht es besser\" würde ich so gesehen in einem halben Jahr nochmal getstet sehen wollen.\\n',\n",
       " 'Das hätte doch schon lange gemacht werden müssen. So kann es nicht gehen. Auf der einen Seite alles zu und von der anderen Seite alles offen. Typischer Irrsinn von den Spezialisten.\\n',\n",
       " 'Also ich bin für einen harten lockdown und schnell tests für jeden. Weil sich ja eh die meisten bicht an die regeln halten \\n',\n",
       " 'Es ist ein Unding dass im Gesundheitswesen (nicht nur bei Coronatests) die Dienstleister:innen ohne jegliche Kontrolle mit den Kassen und staatlichen Stellen abrechnen. Kontrolle wäre so einfach; die Patienten müssen die erbrachten Leistungen unterschreiben. Warum gibt es das nicht?\\n',\n",
       " 'Pandemie ist ein weltweites Problem, da sollten sich Vertreter aller Kontinente an einen Tisch setzen und nach Strategien und Lösungen suchen. Wenn es um wirtschaftliche Vorteile geht, haben es die Akteure auch geschafft die Globalisierung aus der Taufe zu heben, geht es aber um humanitäre Aufgaben - Fehlanzeige. Da herrscht dann eine Ellenbogen-Mentalität.  Das ist immerwieder ernüchternd und traurig. Eine weltweit verbreitetes Virus macht keinen Unterschied, ob es einen armen oder reichen Menschen ansteckt.\\n',\n",
       " 'Der ehemalige Bundesverkehrtminister Dobrindt bietet eine CSU- Variante des Nationalismus an und macht damit klar, dass er den Sinn der Europäischen Union immer noch nicht verstanden hat. Der Meister soll sich um den bayerischen Landkreis mit der höchsten Inzidenzzahl in Deutschland kümmern!!\\n',\n",
       " 'Die Meldung kommt etwas spät. Im Forum der Onlineausgabe eines Blattes aus dem Hause Springer wird das Thema schon seit 14 Stunden diskutiert. Zur Sache: Wer nach Verstaatlichung von CureVac ruft, sollte zunächst einen Blick ins Grundgesetz werfen. Das lässt Verstaatlichungen nur gegen Entschädigung zu und über die Höhe der Entschädigung entscheiden die Zivilgerichte. Wenn die Entwicklung des Impfstoffs gegen Covid-19 gelingt, dann dürfte der Wert von CureVac durch die Decke gehen. Dennoch sollte es Möglichkeiten geben, zu verhindern, dass sich die USA den Impfstoff exklusiv unter den Nagel reißen, zumal das bundeseigene Paul-Ehrlich-Institut, das zum Geschäftsbereich des Bundesministeriums für Gesundheit gehört, an der Entwicklung des Impfstoffs beteiligt sein soll. Vor allem sollte man seitens der Bundesregierung die Sache publik machen und den Konflikt mit den USA offen austragen. Schließlich lässt Mr. Trump keine Gelegenheit aus, der EU und Deutschland öffentlich ans Bein zu pinkeln.  \\n',\n",
       " 'Jetzt ist es erst mal wichtig, die pandemische Notlage und das 4. Bevölkerungsschutzgesetz zu verlängern. Am besten gleich bis zum Herbst, damit man immer schnell reagieren kann.  Dann können wir wenigstens in aller Ruhe auf neue Mutationen warten und sie analysieren und sind immer geschützt. Auch die Einreiseblockade gegen UK muss verlängert werden. Vielleicht stimmt das dann doch nicht so, dass unsere Impfungen helfen, man weiß ja nie.  Und mit den Lockerungen sollten wir wirklich noch 1-2 Monate warten. Das kann nach sieben Monaten ja nicht mehr zu viel verlangt sein. Wir dürfen das Erreichte um keinen Preis verspielen.\\n',\n",
       " 'Die Restriktionen gelten wohl eher den tausenden Demonstranten, die am WE in London auf der Straße waren, denn anders als mit Bestrafung bekommt man sie nie gebändigt. So glaubt man zumindest. Nicht nur in GB, sondern in ganz Europa rumort es kräftig auf den Straßen. Aber darüber berichten die gleichgeschalteten Medioten nicht, sondern verlieren sich lieber weiter angstvoll emsig in den Zahlenspekulationen des RKI. Zumindest solange bis die Kartenhäuser einstürzen.\\n',\n",
       " 'Schulen, Restaurants, Öffis, Geschäfte, Büros, Werkstätten... Es gibt kein Patentrezept außer dem eigenen Verhalten. Die Vorsicht und Achtsamkeit - also die Distanz zueinander - hat die erste Welle bereits gebrochen, bevor die Maßnahmen im März und April starteten. Ähnlich sieht es jetzt aus... Wir sollten weniger auf die Politik warten (und dann jammern), sondern selbstverantwortlich Abstand halten - auch MIT Maske! \\n',\n",
       " 'Das ist das übliche Spiel mit absoluten Zahlen - die natürlich drastisch aussehen - oGottoGottoGott über eine Million - und relativen Zahlen: 1Mio von 330 Mio Einwohnern sind: 0,3%, d.h. aktuell als infiziert nachgewiesen sind 0,3% der Bevölkerung der USA. Das soll nicht die Bedeutung des Sachverhalts herunterspielen - auf jeden Fall MUSS die Intensität der Infektion durch Corona Viren gewürdigt und entsprechend agiert werden. Wichtig ist nur den Sachverhalt korrekt darzustellen.\\n',\n",
       " 'Die Todesrate... Die Intensivkapazitäten.... Die Zahl der Neuinfektionen pro 100.000 Einwohner...  Der R-Wert... Die Verdopplungszeit ... die absolute Anzahl der Infizierten ....  Willkommen beim lustigen Referenzroulette. \\n',\n",
       " 'Wer jetzt zur Vorsicht aufruft, will ja grade nicht, dass es zu Maßnahmen wie hin zu Lockdowns kommt. Wir sind ja alle bald geimpft. Lasst uns bis dahin doch ein einziges Mal klug sein, und die Freiheiten, die wir im Vergleich zu sonst grade in recht hohem Maß haben, weitgehend bewahren, statt wieder in so stressige Lockdownsituationen zu kommen, wo man wieder nicht in die Außengastro kann.\\n',\n",
       " '𝗦𝗶𝗲𝗯𝗲𝗻-𝗧𝗮𝗴𝗲-𝗜𝗻𝘇𝗶𝗱𝗲𝗻𝘇 𝘀𝗶𝗻𝗸𝘁 𝗮𝘂𝗳 𝟭𝟭𝟱,𝟰 Ist also noch ein sehr langer Weg bis wir bundesweit unter 20 und landesweit unter 35 sind. Auch ist die Positivrate weiterhin viel zu hoch, bei unter 3% haben wir die Lage wieder unter Kontrolle. Noch kontrolliert die Pandemie uns.\\n',\n",
       " 'Schön und gut was die WHO rät, allerdings sollte dann auch flächendeckend getestet werden, was allerdings auch wieder nicht möglich ist. \\n',\n",
       " ' Es geht also unter Biden genauso weiter wie bei Trump   Hier sind einige Floristen unterwegs, warum auch immer, jedoch recht einfach China an den Pranger stellen. Zeitschiene sagt aber etwas anderes, die ersten sichtbaren Lungenerkrankungen Traten 2018 in die USA. Von dort sind sie nach Italien und Frankreich gewandert. 2019 war die Militär der USA in Wuhan\\n',\n",
       " 'Europa hat 2 Monate wirklich nichts getan, um das Risiko zu erkranken sinnvoll zu minimieren. Jetzt muß es für seine Politiker halt auch den Preis zahlen. Vielleicht wird es in ein paar Jahren auch wieder besser. Erst müssen wir mal durch die Krise durch, einige Millionen könnten sterben, aber viele Politiker sind ja auch über 30.\\n',\n",
       " \"Ich halte es für extrem fahrlässig, die Kontaktnachverfolgung bei jüngeren Menschen aufzugeben und sich dabei auf die 'Risikogruppen' zu konzentrieren.  Beipiel: 20-Jähriger feiert mit 20 Freunden beiderlei Geschlechts. 15 sind danach infiziert, aber keiner lässt sich testen (aus welchen Gründen auch immer). Zehn fahren am Wochenende zu den Eltern und stecken jeweils ein Elternteil an. Die haben aber keine Ahnung davon. Also 10 weitere Infizierte, die in der kommenden Woche weitere ggfs. ungeschützte Kontakte haben - Freunde, Kollegen, die Großeltern der Studenten. Und schwupps ist ein Pflegeheim betroffen.   Es schlagen ja manche vor, bei jüngeren Infizierten die Kontaktverfolgung aufzugeben und nennen das 'neue Strategie'. Ich rechne die, die das vorschlagen zu den 'Durchseuchungsbefürworten', die sich nur vorgeblich um den Schutz von Risikogruppen bemühen.\\n\",\n",
       " 'Es ist für mich nicht nachvollziehbar, dass es immer noch Politiker gibt, die mit dem \"Weichspülprogramm\" Erfolge erzielen wollen. Welche persönlichen Ziele wollen sie damit ereichen? Dem Wohl von Bürgern und Wirtschaft ist damit nicht gedient. Mehr Infizierte und Sterbende, mehr Verluste in der Wirtschaft, weil dadurch die Corona Krise verlängert wird und viele Kleinunternehmen es nicht mehr schaffen. Das die zugesagten Hilfen nicht ankommen ist bekannt, wird auf die Software der Ämter geschoben. Einfach mal Bürokratie beiseite legen, einfach mal wirklich etwas für den Staat, für die Bürger und die vielen Kleinunternehmen tun. Diesen unbürokratischen Willen zur Lösung sehe ich nirgendwo!\\n',\n",
       " 'Die Unverletzlichkeit der Wohnung ist auch ohne Durchsetzung der entsprechenden Paragraphen des Infektionsschutzgesetzrs ein ziemlich löcheriges Grundrecht.  Wer das nicht glaubt, kann ja mal versuchen dem Schornsteinfeger abzuweisen, nur weil der keine gerichtliche Anordnung dabei hat. Zahllose Ämter haben de jure Zugang zu Privatwohnungen.  Ganz arg ist es, wenn man ganz unten angekommen ist. Gerichtsvollzieher, Mitarbeiter des Jobcenters, des Sozialamts , des Wohnungsamts etc haben jederzeit Zutritt und dürfen sich auch mittels Einblick in Schränke etc. einen Überblick über Wohnungsbelegung oder Vermögenswerte beschaffen.  Coronakontrollen wären bezüglich Unverletzlichkeit der Wohnung nur noch ein weiteres Loch im Sieb gewesen. \\n',\n",
       " 'Das ist in Deutschland jetzt nur noch Theater. Frankreich ist da schon weiter. Deutschland will weiter mit dem Kopf durch die Wand. Unsere Regierung(en) sollten sich darüber im klaren sein, dass  wir zwar geduldiger und  folgsamer, als die Franzosen sind aber auch Grenzen haben. Alles auf dieses Inzidenzzahlen abzustellen, ist doch Quatsch. Wer sind die Toten? Wo sind die Toten?  Ich kenne persönlich keinen bisher, der dran gestorben ist. Die, von denen ich gehört habe, waren alle an der Altersgrenze. So wot?\\n',\n",
       " 'Prognose: 60-70 % der Deutschen werden sich anstecken. Bei der Mehrheit wird es als Erkältung vorüberziehen. Bleibt noch die Risikogruppe, für die es nicht so rosig aussieht. Die Leute hamstern gerade Nudeln und Klopapier. Gemüse- und Obstregale sind weniger frequentiert. Wobei das einzig sinnvolle gerade wäre, das Immunsystem zu stärken (sofern man es aus medizinischer Sicht kann). Ich stehe völlig hinter allen Maßnahmen, die gerade getroffen werden, um die Risikogruppen zu schützen. Aber gerade kam der Kommentar auf ZDF, dass die Einnahme von Vitamin D3 nichts bringt. Ernsthaft? \\n',\n",
       " 'Dann geht der Hamster für mich arbeiten und einkaufen:) \\n',\n",
       " 'Da mal wieder jemand den absolut nicht relativierenden UK-Impglory -Kommentar hierher kopiert hat: MEINE Geschäftsfreunde im UK bibbern vor Sorge ob der Brexitfolgen. Und sie kalkulieren bereits eine baldige Verschärfung dieser Folgen aufgrund des “solidarischen” Verhaltens des UK hinsichtlich der Impfstoffexporte ein. Was nun?\\n',\n",
       " 'Die Bundeswehr zur Unterstützung wollten die ja nicht. Jetzt fängt das Gejammer an. War ja gar nicht absehbar...wer RRG wählt, wählt seinen eigenen Untergang, aber damit hat Deutschland und insbesondere Berlin ja Erfahrung\\n',\n",
       " '\"Daher wünsche er sich, dass der Frühling warm und frühzeitig beginne.\"  Ei  gucke da! Wer hätte je so einen Satz in Zeiten des Klimawandels erwartet. :-) Es fragt sich nur, ob das Wetter wirklich so einen Einfluss hat. In Südafrika und Brasilien steigen und steigen die Zahlen und dort ist jetzt Sommer.\\n',\n",
       " 'Wir sehen hier in Echtzeit ein Versagen des Förderalismus. Traurig, aber wahr. Die Bereichtschaft zum treffen von unpopulären, jedoch notwendigen Entscheidungen ist leider bei vielen Landeschefs nicht vorhanden.\\n',\n",
       " 'Einen Monat noch, dann sollten verwertbare Ergebnisse aus den Phase 3 Studien vorliegen und wir wissen in welche Richtung es geht. Drücken wir die Daumen.\\n',\n",
       " 'Diese Ökonomen. Anstatt nichts zu sagen. Wie immer stimmen diese Kaffeesatzlesereien sowieso nicht. Warum gehen diese Ökonomen nicht auf den Jahrmarkt zur Hellseherin. Die hat eine dicke Glaskugel. \\n',\n",
       " 'die uni der bundeswehr hat im sommer eine umfangeiche studie dazu gemacht und hat auch eines der geräte klar empfohlen ... das umweltbundesamt hat es bestätigt\\n',\n",
       " 'Der Streit spitzt sich zu. Ein Türke droht mit einer Reise nach Berlin! :-)\\n',\n",
       " 'Das ist schon Kunst die kommenden Schritte als Lockerungen zu verkaufen, obwohl es eigentlich keine sind.\\n',\n",
       " 'Ohne Rücksicht auf die Alten und die Pflegekräfte beiden hätte ich gegängelt. Allerdings den Pflegekräften für die Zeit das 3 fache bezahlt. Für die Alten wäre das keine Veränderung zu der jetzigen Situation, für den Rest schon..... \\n',\n",
       " 'Ist Indien eigentlich im Totallockdown, da deren Inzidenz bei 7 liegt oder wie machen die das?\\n',\n",
       " 'Freie Fahrt für freie Bürger - Die Richter urteilten im Sinne Kohls.\\n',\n",
       " 'Demnächst muss die Bundesregierung dann wohl auch eine Reisewarnung für einige Regionen des eigenen Landes aussprechen. Die Zahl der Neuinfektionen steigt weiter an, es ist kein Ende in Sicht.\\n',\n",
       " 'Söders Dauer-Alarmismus nutzt sich ab. Viele Bürger sind es leid, dass politische Vorgaben (wie z.B. die Empfehlung zu Urlaub innerhalb Deutschlands) nur noch eine Halbwertszeit von wenigen Tagen oder maximal Wochen haben, gefühlt fast täglich von ihm und anderen eine neue Verbots-Sau durchs Dorf gejagt wird, inzwischen an jedem Briefkasten andere Regeln gelten und keiner mehr durchsieht. Mit der Forderung nach Einheitlichkeit hat Söder recht. Aber untrennbar damit verbunden sein müssen Einfachheit, Klarheit, Nachvollziehbarkeit und Konsistenz! Bei Maskenzwang auf offenen Straßen, temporären oder lokalen Alkoholverboten, Sperrstunden oder Beherbergungsverboten ist das alles nicht erkennbar!\\n',\n",
       " 'Das hätte vielleicht am Anfang geholfen. Aber bezüglich Grenzkontrolle scheinen von ihren \"Erfolgen\" bei der Flüchtlingskrise abgeschaut zu haben. Sprich wir kontrollieren erst, wenn der Virus schon zehntausende Menschen angesteckt hat.\\n',\n",
       " 'Immerhin scheint das Impfen Fortschritte zu machen. Jetzt wäre eine Übersicht über die bereits gelieferten und die in den nächsten Wochen erwarteten Impfdosen hilfreich. Dann liesse sich abschätzen wie es weiter geht. Dabei erwarte ich nicht, dass alle Produktions und Nutzungserweiterungen völlig reibungslos funktionieren aber die Zulassung von Marburg, die absehbare Zulassung des Asta Zeneca Impfstoffe Ende Januar und das leichtere Handling stimmen zuversichtlich. Wichtig wäre jetzt, dass sich die Länder auf ein en best prächtige Prozess verständigen und den umsetzen. Die massiven Differenzen zwischen den Bundesländern sind nicht nur unverständlich sondern kosten Menschenleben \\n',\n",
       " 'Aus dem Jahr 2015 gibt es Zahlen zu Verstorbenen in Krankenhäusern an Infektionen mit multiresistenten Keimen. Deutschland ca. 2400, Italien gut 10.000. Unabhängig von Covid 19 läuft in Italien etwas unglaublich schief.\\n',\n",
       " 'Kitas und Schule öffnen, je früher je besser. Dann sind in wenigen Wochen alle Kinder und Jugendlichen immunisiert und können dann wieder zu ihren Großeltern. Bis dahin natürlich, wie jetzt auch, Kontakt zu Risikogruppen meiden. – Bin eigentlich kein Laschet-Freund, aber für mich momentan der einzige Politiker, der die Lage im gesamten betrachtet und vernünftige Lösungen bietet. Ein längerer Lock-down hat keinen Mehrwert, die Krankenhäuser sind vorbereitet, also worauf noch warten? Doch wohl kaum auf den Impfstoff.\\n',\n",
       " 'Lockdown verlaengern - OK. Dann aber auch konsequent ueberwachen und nicht bei jeder Demo deeskalierend zuschauen. Dann haben wir den Lockdiwn noch 12 Monate \\n',\n",
       " 'Warum sagt uns eigentlich niemand was vor den Verhandlungen die Wissenschaft gesagt hat. Oder ist es nur wichtig was die einzelnen Landesfürsten wollen. Es sollte durchweg nur das gemacht werden was die Fachleute sagen. Außerdem hat die Öffentlichkeit ein Anrecht auf Information. \\n',\n",
       " 'Ich kann in den Filmchen keine Konstruktive Kritik finden! Oder ging es nur um Provokation und Knalleffekt?\\n',\n",
       " 'Man  stelle sich nur mal vor, alle Deutschen wären Querlenker - was wäre in diesem Land jetzt los ...\\n',\n",
       " 'In einer dieser Maschinen vom DXB sitze ich morgen, mit allen Papieren sauber in der Tasche.  Negativer Covid-Test von gestern ( gestern abend 23 Uhr Probennahme, 8:34 Uhr heute morgen das Negativ-Resultat-Zertifikat bekommen), sauber die Einreiseanmeldung gemacht und Bestätigung ausgedruckt. Emirates sollte eigentlich niemanden in den Flieger lassen, der kein Negativ-Zertifikat hat. Heute morgen habe ich eine SMS bekommen, dass man das Negativ-Resultat zum Check-In mitbringen muss.  Ich war 2 Monate hier (Familie + Doktorbesuche hier, in DE ging ja gar nichts terminmässig,  selbst für chronisch Kranke, grausam... bin also aus hauptsächlich aus Familiengründen hier, meine Frau arbeitet hier)  Wer morgen ohne Negativ-Test am Gate in DXB angewiesen wird, hat es nicht anders verdient, sorry. Mir ist auch sehr daran gelegen, nicht mit ungetesteten Petrischalen 7 Std in einem Flieger zu sitzen. Als ob es zuviel verlangt wäre,  kurz bei den dutzenden Doktoren hier einen Test 48std vor Abflug zu nehmen... hier konnte man sogar für 55 Euro einen Test direkt an seiner Wohnadresse (egal wo) machen lassen, die Test-teams waren jederzeit verfügbar. Direkt in einem der Testzentren wäre es 30 Euro gewesen, mit 24std Resultat Garantie.  Ich seh das Problem also wirklich nicht. Dass man 10 Tage in Quarantäne muss wenn man zurück kommt, das wusste man schon vorher, schon seit November war das bekannt. Also, auch easy. Wer morgen in Trouble kommt, der hat es nicht anders verdient, sorry. \\n',\n",
       " 'Das Gefühl es ist jetzt günstiger spielt eine viel wichtigere Rolle als das wieviel es günstiger ist. Ein Feuer frei Signal für alle, die viel Geld gespart haben, weil sie nicht ins Restaurant, ins Kino, in den Biergarten, ins Theater, usw. gehen konnten. Die Zielgruppe, die sich über 20€ gespartes Geld im Monat freut, kurbelt die Wirtschaft wohl kaum an. Das Ziel ist, die Konsumstimmung derer zu heben, die auch konsumieren können. \\n',\n",
       " 'Der zweite Mann im Staat (Pence) ist Anhänger des\\xa0Prosperity Gospelund somit der Auffassung, dass entsprechend der Vorstellungen zur\\xa0Prädestination\\xa0Gottes materieller Reichtum und persönlicher Erfolg (oder aber Misserfolg) ein Beweis für die Gunst (oder Ungunst) Gottes seien, eine bei Anhängern fundamentalistischer Freikirchen verbreitete Ansicht. (Quelle Wikipedia)  Damit ist wohl klar, was die Herren im weißen Haus über die Armensiedlungen denken.\\n',\n",
       " 'Es muss einfach geimpft werden.....alles andere macht keinen Sinn!!!  Lockdown ist eine begrenzte Lösung.....wenn ich 6 Wochen auf Schokolade verzichte; hau ich mir danach umso mehr rein und danach gehen die Pfunde wieder hoch 😉\\n',\n",
       " 'Es ist gekommen wie ich es geahnt habe, das Thema ist durch. Keiner der Experten redet mehr von Corona, aktuell ist es natürlich das Unwetter und danach wird Klima allgemein das bestimmende Wahlkampfthema werden. Wenn man die täglichen Medien verfolgt, kann man schon erkennen, wie die Priorität ganz bewusst verschoben wird.\\n',\n",
       " \"Mir fällt auf, dass hier kaum über die 'Sparsamen Vier' diskutiert wird. Ausgerechnet Österreich, ohne deren besinnungsloses Apres-Ski Feiern in Ischgl wir gar nicht in der Misere stecken würden, weigert sich zu helfen. Und Schweden, die bislang ungefähr alles falsch gemacht haben in der Bekämpfung von Corona.   \\n\",\n",
       " 'Vielen Dank Herr Söder, für Ihr umsichtiges Handeln! Corona ist -  wenn’s inzwischen auch jede Menge Verharmloser gibt - ein gefährliches Virus, ob’s uns nun gefällt oder nicht. Ein wie es vorher mal war, wird es nicht mehr geben.\\n',\n",
       " 'Sport, Leute, Ostern soll es regnen. Regenschirme sind leider gerade aus, rausgehen ohne Schutz wäre unverantwortlich: Wir brauchen Ausgangssperren! (Vor einem Jahr hat man in einer ähnlichen Situation Corona-Behandlungszentren gebaut und Reserve-Intentensivbetten eingerichtet. Und den Einzelhandel geöffnet. Ohne Tests ohne Impfungen. Und mit der Folge, dass die Inzidenzen gesunken sind. Weil sich die Menschen drinnen anstecken und nicht draussen.)\\n',\n",
       " 'Die CDU koennte auf ein Online-Format umstellen - wie viele Schulen, Unternehmen und Universitaeten es tun. Allerdings gaebe es dann keinen Grund mehr, die Entscheidung auf 1001 Delegierte zu beschraenken...\\n',\n",
       " 'schöne Arbeit der CDU, verhindert seit Jahren eine Reform in diesem Sektor. und sollte durch diesen Hotspot in der Umgebung neue Infektionen aufpoppen sollte der träge Laschet langsam einpacken.  ich denke in der Gegend sind die Bürger leicht angespannt.\\n',\n",
       " 'Was für eine Geschichte! Folgt eine Fortsetzung? Oder ein Buch? \"Babylon Berlin - der Tanz auf dem Vulkan\".\\n',\n",
       " 'Habe so das Gefühl, als wenn man in München wie eine Maus vor einer Schlange sitzt. Die Zahlen werden größer, aber man tut nichts, weil wenn man die Augen zumacht es verschwindet. Wann will man einschreiten? Wenn die Zahlen über 100 sind? 1000?\\n',\n",
       " 'Wie soll das Abstandhalten nach Bordell-Hygienekonzept funktionieren? Vielleicht kann das jemand erklären...\\n',\n",
       " 'Was interessiert mich in dem Zusammenhang Friedrich Merz? Will man uns damit sagen, der ist zwar infiziert, lebt aber noch?\\n',\n",
       " 'Hier wird wieder der Sozialismus herbei gewünscht. Weil die Notenpresse und klassische Verteilmechanismen (wie Kurzarbeitergeld) angeblich nicht ausreichen, soll jetzt das Geld pauschal pro Nase verteilt werden. Das führt vor allem dazu, dass die Geldmenge weiter erhöht wird und Sparer noch stärker enteignet werden. Auch die Aktienkurse würden noch weiter steigen und Konzerne noch reicher werden. Italien und Spanien haben strukturelle Probleme, weil sie schon vor Corona über ihre Verhältnisse gelebt haben.\\n',\n",
       " 'Dieses Scheinfaktengeschwurbel der Coronaverherrlicher hier im Forum um die Lockdowns zu rechtfertigen und diese als notwendig und Alternativlos darzustellen ist kaum mehr zu ertragen. Der Realitätsverlust verursacht durch die Politik und die Leitmedien ist leider irreversibel.\\n',\n",
       " 'Steuersenkungen nach der Krise sind sehr sinnvoll. Einmalzahlungen an Krankenhausmitarbeiterung, okay zur Motivation, aber unwichtig weil eher Selbstständige und Mitarbeiter anderer kleiner Unternehmen nach Entlassungen in Not sind. Nicht entlassene Mitarbeiter haben noch nie so wenig Geld ausgegeben wie jetzt und könnten eher für die an der Front etwas abgeben. Aber großes Geschrei: natürlich nicht durchsetzbar, weil, ja weil wir Menschen sind, die alles brauchen.  Söder hat endlich eine pragmatische gute Idee, die sinnvoller ist als Billionen in europäische Fässer ohne Böden zu schütten. \\n',\n",
       " 'Und ich werde angeraunzt wenn ich etwas mehr Abstand will beim Einkauf. ... War an der Flaschenrückgabe.\\n',\n",
       " 'Im Grund hat man doch Angst davor, das für die zweite Impfung nicht genug Impfstoff da ist weil man keine Rückstellungen bilden will. Ist zumindest mein Eindruck. \\n',\n",
       " 'Ja, ist echt Schade dass die FDP keine Möglichkeit zur Regierungsbeteiligung hatte. Was hätten sie nicht alles besser machen können... Oder war es doch so, dass sie drauf verzichtet haben um gute Ratschläge ohne Verantwortung geben zu können? Ich erinnere mich grad so schlecht... \\n',\n",
       " 'Ob die App funktioniert spielt doch sowieso keine Rolle. Bringt es was, wenn ich eine Meldung bekomme, dass ich mich zu lange in der Nähe eines der aktuell 0,025% falsch positiv getesteten aufgehalten habe. Ich muss statistisch gesehen über 3000 Menschen treffen, damit dies der Fall ist. \\n',\n",
       " 'Das Kartenhaus der naiven Einfalt repräsentiert von Merkel und Söder wird in dieser Woche umfallen. Merkel mag wieder weinerlich mit falschen Zahlen argumentieren, Söder mag weiter für die Käfighaltung der Bürger eintreten - der Rest der Republik wird lieber auf Vernunft setzen und einen Ausgleich aller Interessen suchen. Die bedingungslose Hysterie ist endlich vorbei.\\n',\n",
       " 'Die Pandemie wütet weltweit und von Tag zu Tag finde ich viele Kommentare  erschreckender. Hallo!? Es gibt noch 194 weitere Staaten und alle wollen einen Impfstoff gegen dieses ver.damm.te Virus. Wir sollten froh und dankbar sein, dass es überhaupt schon Impfstoffe gibt. Das hätte durchaus noch sehr viel länger dauern können. \\n',\n",
       " 'Gut das wir nach fast genau beginnen, Experten zu nutzen und qualifizierte Pläne zu entwerfen. Schade das es sich lediglich um einen Vorschlag handelt\\n',\n",
       " 'Facebook, Twitter und all die anderen (a)sozialen Medien liessen nicht nur alle Trumpluegen 4 Jahre lang ungefiltert zu, nein, sie verstaerkten sie durch ihre Algorithmen, welche Gleichgesinnte zusammen fuehren.   Sie sind die Architekten der Echokammern, in denen sich die Trumpleute, ausserhalb der realen Welt, treffen und austauschen.   Nun stehen sie wie die Zauberlehrlinge da, denen die Besen entglltten. Zu spaet! Allfaellige Werbeverbote fuer Waffenbestandteile helfen auch nicht weiter. mfG Beat Adler\\n',\n",
       " 'Ideale Grundposition für einen typischen GroKo-Kompromiss: die Leute sollen ihre Raketen und Böller kaufen, dürfen sie aber nicht benutzen. :)\\n',\n",
       " 'Da es sich um eine einmalige Sache handelt kann man die paar Euros gerne mal zahlen. Das sind Peanuts. Wenn man das Geld später unbedingt einsparen will kann man gerne mal im Etat der Bundeswehr nachsehen. Da wird genug Geld sinnlos verpulvert. \\n',\n",
       " 'Das ist halt alles was er kann. Warnen, mahnen und übergriffig sein.  Fühlt sich halt gut an, wenn man endlich mal wer ist und \\n',\n",
       " 'Kürzlich gab es rund 130 Positive in Euskirchen. War das ein Testfall für Laschet? Söder hat vieles besser gemacht als der CDU-NRW-Chef. So auch diesmal, denn der Obsthof in Euskirchen wurde nicht abgeriegelt. Und, oh Wunder, Dutzende sind aus der Quarantäne auf nimmer Wiedersehen verschwunden.\\n',\n",
       " 'Wenn Corona so harmlos ist,  wie vielfach behauptet,  warum „dreht dann langsam die ganze Welt durch“ ? Warum gibt es in vielen Ländern auf der ganzen Welt einen Lockdown ? Warum riskieren viele Länder ( egal ob Demokratie, Diktatur, etc. )  auf der ganzen Welt durch einen Lockdown den wirtschaftlichen Kollaps ? Sind die Bilder von Leichenbergen ( Südamerika, USA , etc. ) nur Fälschungen? Meines Erachtens ist auch weiterhin äußerste Vorsicht angebracht. Insofern ist Söder im Recht.\\n',\n",
       " 'DANKE für die Entscheidung! Habe die ganze Zeit in einem Wohnheim gearbeitet und meinen Job gemacht. Und auch Karfreitag bin ich 13 Stunden vor Ort. Danach endlich mal 3 Tage frei und die dann auch noch in den eigenen 4 Wänden?! Leute, geht raus und haltet Abstand! Und alles ist gut. Kann so einfach sein🌻\\n',\n",
       " 'Ganz böse. Da sind doch tatsächlich Menschen in einem Hotel abgestiegen. Wie können sie nur. Ganz schlimme Superspreader, das.\\n',\n",
       " 'Was bitte hat Seehofer mit Friseuren am Haar ähm am Hut? Der Innenminister hat hier gar nichts ... das ist Ländersache.\\n',\n",
       " 'Auch wenn ich keine Hoffnung hab, dass dieser Virus-Typ nicht schon bei uns ist, so muß man sich mal der Tragweite dieser sehr kurzfristig anberaumten Maßnahme vor Augen halten auf beiden Seite des Ärmelkanals in einer Phase wo genug Unruhe durch den möglichen harten Brexit besteht Zutiefst beunruhigt kann es jetzt nur noch schlimmer werden und erwarte alsbald die ersten Fälle hier dokumentiert sind heftigste Einschränkungen für uns alle, die wir bislang noch nicht erleben mußten.  \\n',\n",
       " 'Wieviel brauchen die französischen Banken für die Ablösung des italienischen Kreditgeschäfts?\\n',\n",
       " 'Es gibt bei der offiziellen Inflationsrate neben dem Problem der unzureichend erfassten Immobilienpreissteigerungen, des wohl nicht mehr repräsentativen  Warenkorbes, auch das Problem mit den hedonischen  Bewertungsmethoden, die in die Berechnung der Inflation im gewissen Umfang auch willkürliche anmutende Korrekturfaktoren einfließen lassen. So weist die alternative Inflationsberechnung der Webseite Shadowstats.com schon seit Jahren eine \"wahre\" Inflationsrate von über 6% aus wie Dirk Müller und Max Otte in einem Artikel des Focus schon 2014 verdeutlichten.\\n',\n",
       " 'Junge,Junge,ist das nicht\"Singen im dunklen Walde\"? Zum einen ist doch der Inzidenzwert schon immer willkürlich gewesen,selbst das Argument der \"Kontaktnachverfolgung\"ist-im Grunde- Unsinn, denn wenn nicht nachverfolgt wird ,wie wir derzeit sehen, ist es auch nicht tragisch. Man kann sich gut wichtigere Einsatzmöglichkeiten für Gesundheitsamtsmitarbeiter vorstellen! Und nun die MUTANTE!!!!Uih! Sollen wir uns nun im Keller verstecken?Fast das einzige,was als unsinnige Massnahme noch fehlt? Nein,wirklich, nur weil die Politik in der Pandemiebekämpfung mit ihrer Klaviatur unsinniger Massnahmen versagt,und versagt,und versagt, muss der Bürger\"bluten\"? NIEMAND! kann belegen, welche Einzelmassnahme welche-wenn überhaupt- Wirkung hat. NIEMAND! kann eindeutig sagen, ob und wieviel gefährlicher die neuen Mutationen sind. NIEMAND!kann genau beziffern,wieviele Insolvenzen,wieviele Selbsttötungen,wieviele psychischen Störungen auf das Konto der Pandemiebekämpfung gehen. NIEMAND! kann sagen, welche Alternativen zu den bisherigen Massnahmen erfolgversprechend wären, weil man sie nicht ge-und versucht hat! Was man allerdings genau sagen kann ist,wieviele Menschen sterben mussten,weil sie nicht rechtzeitig geimpft wurden. Insofern ist ein\"weiter-so\" keinesfalls der richtige Weg.\\n',\n",
       " 'Vielleicht macht BG einfach den Anfang - die Kohle sollte er ja haben. Dann hätte er vielleicht wenigstens biologische Viren mal erfolgreich bekämpft :-).\\n',\n",
       " 'Warum hat man sich seit 2013 nicht darum gekümmert? Bundestagsdrucksache 1712051  Nicht nur da Totalausfall. \\n',\n",
       " '\"Erstmals seit Januar über 30.000 Neuinfektionen in Großbritannien\"  Uiuiui - und das mitten im Hochsommer, bei warmen Temperaturen und viel UV-Strahlung. Da werden jetzt einige der \"Corona ist ein saisonales Virus\" Fans aber Kopfschmerzen bekommen und neue Ausreden gegen Corona-Maßnahmen im Sommer finden müssen ...\\n',\n",
       " 'Daumen hoch dafür Frau Lambrecht, in diese Richtung muss es jetzt in großen Schritten weiter gehen... Zurück zur Normalität für geimpfte Mitbürger,- vollkommen egal ob die Medien jetzt eine Neid-Debatte herbeireden wollen oder nicht.\\n',\n",
       " 'Wie erwartet! : 170 Tote mehr zum Vergleichs-Wichentag 23.12.20 !! - auch unter Lockdown-Bedinigung! Das wird die beiden letzten Tage so weiter gehen wie auch im Jan.21!! Frohes Neues!!\\n',\n",
       " 'Also - von der \"Deutsche Gesellschaft für Krankenhaushygiene\" zum Beispiel, hätte ich eher ein Update erwartet, wie der aktuelle Stand der Dinge in Sachen multiresistente Keime in Krankenhäusern ist, sprich wird jetzt endlich gründlich genug geputzt oder sollte man planbare OPs doch vorzugsweise im angrenzenden Ausland durchführen lassen, ich denke da an NL, wo es dieses vermeidbare Problem nicht gibt. Zur Öffnung der Schulen - ich würde sagen, Ende Mai wissen wir Bescheid, z.B. aus Österreich, Dänemark oder auch Sachsen, welche Auswirkungen das hat und ob es ein gangbarer Weg, wobei man auf die jeweils durchgeführten Hygienemaßnahmen und Abläufe schauen muss und dann kann man entscheiden. Die 2 Wochen stehen wir auch noch durch.  \\n',\n",
       " 'So langsam ist die Zeit reif. Wie kann ich einfach und schnell testen, ob die Menschen, die etwas betreten wollen, geimpft sind ? Na, indem die geimpften gechipt werden und an einem Scanner vorbeilaufen sobald sie z. B. in ein Fußballstadion oder Flugzeug wollen. Es wäre die sicherste, zuverlässigste Methode. ( Satire aus )\\n',\n",
       " 'Inkubationszeit 14-28 Tage.....also ist die heutige Situation ein Abbild der Infektionsrate vom 1. - 15. Februar. Die italienische Regierung hat vor 10 Tagen drastische Massnahmen getroffen und Ende Januar den Notstand ausgerufen und Chinaflüge verboten. Auch dort basieren sich die Zahlen von heute auf die Zeit vor dem 15. Februar und vor den Massnahmen...die Massnahmen werden erst in 10 Tagen beginnen zu greiffen....und dann sollte sich die Kurve abflachen.....die WHO lobte das Land. Unverständlich dass Deutschland nichts tut und nicht auf die Erfahrungen Italiens baut, das ein umfassendes hervorragendes staatliches Gesundheitswesen hat, das NICHT am Limit arbeitet. Das Fehlen von Massnahmen wird dramatische Folgen haben in Deutschland. Man lässt Messetermine stehen, den Karneval laufen und Fussballspiele....\\n',\n",
       " 'Impfstoff nicht verfallen lassen ist o. k. und das man Ü 80 am Abend nicht zusammentrommeln kann, ist mir auch klar, aber ich glaube nicht, daß alles medizinische und Pflegepersonal vor Ort schon geimpft war, damit wäre man auch regelkonform gewesen. Trotzdem finde ich die Empörung bis hin zu Rücktrittsforderungen reichlich übertrieben.\\n',\n",
       " 'Über die Kirchen habe ich nichts gelesen. Bleiben die offen, macht der Virus aus Achtung vor den Gläubigen an der Kirchentür halt? In Sachsen hieß es, die entscheiden in eigener Verantwortung. Das geht doch wohl überhaupt nicht.  Die Regeln müssen für alle gültig sein.\\n',\n",
       " 'Na kein Wunder, dass die Pandemiemaßnahmen so populär sind. Nei Kurzarbeiterheld zu Hause die Garage und den Keller aufräumen, mal runterkommen vom Streß... nur hoffentlich sind die Arbeitsplätze dann nach anderthalb Jahren wirklich noch da...\\n',\n",
       " 'Warum kommt er eigentlich erst jetzt mit dieser Selbstverständlichkeit um die Ecke???\\n',\n",
       " 'Ach, in den USA geht das? Bei Amazon-Deutschland nehmen mittlerweile manche Leute Preise für die übliche Handdesinfektionsbrühe, die das 2,5...3 fache des bisher üblichen betragen. In der Apotheken ist das kaum mehr zu kriegen, also kochen einige da wohl ihr Süppchen. Ich warte eigentlich nur drauf, dass da welche das Zeug obendrein schlicht mit Wasser verstrecken.\\n',\n",
       " 'Ein interessanter Artikel, der die Grenzen der Wissenschaft, präzise Aussagen zu machen, verdeutlicht. Es gibt keinen weder theortisch begründbaren geschweige denn exakt umsetzbaren Grenzwert für einen sicheren Abstand. Der Soll-Abstand muss ein sinnvoller Kompromiss zwischen Ansteckungsschutz und anderen berechtigten Interessen sein. Wenn die Infektionszahlen wieder steigen, war der wohl zu kurz und Lokalitätten, an denen sich der Abstand nicht einhalten läßt, müssen wieder geschlossen werden. \\n',\n",
       " 'Klartext: Corona ist eine schöne Gelegenheit, gratis marginalisierte Menschen zeitnah verschwinden zu lassen. Die Reichen begeben sich auf die Azoren zum Golfen, die Armen sind ein Makel im Straßenbild. Wenn die Reichen zurückkommen, sind vielleicht weniger Arme unterwegs, die das Bild beeinträchtigen, ganz automatisch, ganz ohne Zutun von Gewalt, der Virus ist ein Freund der Reichen!  Wenn der Typ nicht in die Psychiatrie eingewiesen wird, dann sollte doch jeder erkennen, wie die \"Elite\" tickt, die ballen doch alle längst die Faust in der Tasche, vor Ärger, dass sie das Ganze nicht besser gemanagt haben.  Beim nächsten \"Neuvirus\" wird ihnen das nicht mehr passieren.\\n',\n",
       " 'Firmen im Baugewerbe? Nach dem Bauboom der letzten Jahre? Wie schnell man doch um seine Existenz fürchten kann, wenn Geld vom Staat ins Blickfeld rückt. Veräppelt bitte jemand anderen...\\n',\n",
       " 'Wenn Merkel dafür sorgt, das Patente freigegeben werden, wäre das eine echte Hilfe gewesen. Die Idee das man eine Milliarde Einwohner irgendwie materiell helfen kann, wird am Ende nur ein Tropfen auf den heißen Stein sein.\\n',\n",
       " 'Möchte mal sehen, wie Alk-Verbot rund um die Rigaer Straße durchsetzbar ist.  In anderen Stadtteilen wird es nicht viel besser sein, zumal die Polizei - die das ja überwachen muss -seitens der Landesregierung keinerlei Rückhalt besitzt. Seitens der Bundesregierung auch nicht viel mehr.\\n',\n",
       " 'Dir Bundesregierung muss umgehend die Freigabe der AZ Impfungen verfügen! Umgehend heißt in diesem Fall: Vor zwei Stunden! Dazu würde ich als Gesundheitsminister auch ganz eigenmächtig die bevorzugte Verwendung bei älteren Menschen anordnen, weil in dieser Gruppe niemand mit Nebnewirkungen aufgefallen war, bisher zumindest.\\n',\n",
       " 'Ich halte die Freigabe trotz allem für vertretbar, wenn auf das Risiko hingewiesen wird.  Man sollte aber auch Informationen herausgeben ab welchem Alter diese Trombosen bei den Patienten aufgetreten sind um unnötige Risiken zu vermeiden.\\n',\n",
       " 'Ich würde gerne mal ein paar mehr Zahlen haben, damit man das einsortieren kann. Beispielsweise mal die Alterstruktur der Kranken (alle positiv getestete), die Alterststuktur der Kranken, die im KH behandelt werden müssen und die Alterstruktur der Gestorbenen.  Bei den Jüngern gerne auch mal genauere Informationen über die Vorerkrankungen. Ich kann mir nicht vorstellen, dass die Zahlen nicht existieren. Trotzdem hört man immer nur von dem Durchschnittsalter.\\n',\n",
       " 'Das Problem ist, dass Merkel nur die Welle brechen, aber nicht die Inzidenz massiv senken will, um Öffnungen zu ermöglichen. Die Notbremse war in vielen Regionen vor Wochen schon umgesetzt worden. Oftmals strenger, als im Gesetz verankert. Dennoch sinken die Neuinfektionen nicht. Ganz im Gegenteil: es zieht wieder leicht an. Diese halbgaren Maßnahmen ohne Perspektive sind absolut ermüdend. \\n',\n",
       " 'Über alles wird berichtet im Zusammenhang mit Corona. Aber der seit gestern vorliegende Sicherheitsbericht des PEI einfach ignoriert ?!?\\n',\n",
       " 'Unfassbar. Das wird die Pseudoinfektionzahlen explodieren lassen. Die Inzidenz wird dann dementsprechend erhöht oder soll die etwa immer noch bei 0.05% bleiben? \\n',\n",
       " '\"Eurostaaten wollen weiter Geld in die Wirtschaft pumpen\"  Und wer zahlt am Ende alles? Natürlich der deutsche Steuerzahler und Sparer!  Es wird endlich Zeit für den \"Dexit\"! GB hat davon in der Pandemie profitiert.  Deutschland wird, wenn die deutsche Bevölkerung seine Innovationskraft wiedergefunden hat die sie mit dem Beitritt zur \"EU\" und Euro verloren hat, nach einer kurzen Durststrecke auch wieder profitieren und  weltweit, natürlich auch mit der \"EU\" wenn diese möchte, mit anderen Staaten Handel treiben.\\n',\n",
       " 'Ich sehe richtig, dass Möbelgeschäfte, Klamottenläden, Friseur, Massage und Co offen bleiben?  Disclaimer: Dürfen sie von mir aus gerne. Ich hätte aber mit erneuter Schließung gerechnet\\n',\n",
       " 'Widerwärtig selbst - und geschichtsvergessen, diese malerische Beschreibung eines traulichen touristischen Ausflugs. Besserverdienendenjournalismus für die weltferne Insel im Speckgürtel. Für mich ist solcher \"Journalismus\" die gefährliche Manifestation eines Coabhängigkeitssyndroms im Vollbild. Und ich weiss ziemlich genau, wovon ich rede, wenn ich so etwas sage... \\n',\n",
       " 'Die Schritte sind zu klein, die Disziplin und Geduld der Bevölkerung schwindet rasch. Vorallem innerhalb der Familie werden die Großeltern nicht lange auf Enkelkontakt verzichten wollen. Wenn die Schulen alle öffnen werden wir eine schnelle Verbreitung und Immunisierung der Familienmitglieder haben, und nach erfolgtem Antikörper Test kann Oma dann auch wieder zu Besuch kommen. Die Durchseuchung muss schnell erfolgen damit die Leute greifbare Ziele haben, DAS wird unsere Schwächeren und älteren schützen. Und nicht: ach das dauert alles noch ewig so lange warte ich nicht. Zack hat Oma dann Corona. Der größte Akt der Solidarität gegenüber Großeltern ist das schnelle immun werden. \\n',\n",
       " 'Kann mal jemand diesem Schönredner das Wort entziehen. Ich habe nicht vergessen, wie genau dieser Herr am Anfang der Infektionen, diesen Virus verharmlost hat. Daher auch die zu späte Reaktion darauf. Und sich jetzt als großer Retter aufspielen. \\n',\n",
       " 'Wichtig: Bei der Dienstbesprechung war das Virus ganz brav, erst bei dem privaten Teil ist es über die Menschen hergefallen!\\n',\n",
       " 'Es wird jeden Tag klarer. Die einzige Partei, die in den letzten 8 Jahren etwas für das Land, Arbeitnehmer, Familie und Rentner vorwärts bewegt und nicht verhindert hat, ist die SPD.\\n',\n",
       " 'Ein Problem sind die Öffnungszeiten. Wenn die, die gutes Geld verdienen, Zeit zum Einkaufen haben, sind die Läden oft schon zu. Völlig unlogisch, daß die Ladenöffnungszeiten ziemlich identisch mit den Arbeitszeiten sind.   Nächstes Problem die restriktiven Maßnahmen gegen den Individualverkehr. Als Deutschland noch halbwegs normal war, stoppte ich auf dem Weg von der Baustelle nach Hause mal an dem Laden, mal an dem...oder hab noch schnell mit Bekannten einen Kaffe geschlürft. Da gingen schnell mal 50..100 DM über den Ladentisch. Jetzt drohen überall die Politessen mit Knöllchen. Also kaufen wir im sicheren Supermarkt ein und meine Frau bestellt alles Andere ...nach einem anstrengenden Arbeitstag auf der Couch entspannend... mit dem Tablett.   Die Politik will es doch nicht anders.\\n',\n",
       " 'Wir sollten lieber nicht zu überheblich werden, wie wir mit unserer tollen Impfbereitschaft bald alle anderen abhängen. In dieser Woche hatten wir den größten Zugewinn an verfügbarem Impfstoff. Aber am Montag und Dienstag wurden jeweils deutlich weniger Spritzen gesetzt als in den Vorwochen. In Deutschland haben wir die dynamischste Phase schon hinter uns - und das bei knapp über 50% Quote bei den Erstimpfungen. Es flacht bedenklich früh ab und wird über den Sommer hinweg noch mühsam werden, in die Nähe der 70% zu kommen.\\n',\n",
       " 'Bei uns liegt der inzidenzwert bei 50 warum müssen unsere Kitakinder und Schulkinder weiter zu Hause bleiben ? Solidarität ist ja gut aber die meisten Eltern sind berufstätig und haben keine freien Tage mehr.  Regionale Unterschiede müssen berücksichtigt werden .\\n',\n",
       " 'Ich halte die titelgebende Frage für korrekt gestellt. Wenn man denn davon ausgeht, dass der Artikel auch bis zum letzten Satz gelesen wird. Denn Frau Höflingers letzter Satz gibt eine Art Antwort. Man kann natürlich auch den Umstand, dass nur 5% der Inder älter als 65 Jahre sind (werden?), in die Waagschale werfen. Ich übersetze das mal folgendermaßen (bei aktuell rund 21% Bevölkerungsanteil über 65 Jahhre in Deutschland):  75% der momentan über 65-Jährigen in Deutschland (gemessen an der Zahl der Gesamtbevölkerung) wäre aktuell nach indischen Maßstäben „naturgemäß“ nicht mehr am Leben. Wäre das ein erstrebenswerter Zustand, um die Corona-Todesrate zu relativieren? \\n',\n",
       " 'Laut aktuellem Wochenbericht des RKI hatten wir in der KW 12 ca. 350 SARI-Fälle, davon die Hälfte mit Covid-19. Im gleichen Zeitraum des Jahres 2019 hatten wir über 700 SARI-Fälle. Im aktuellen Bericht heißt es u. A.: \"Wegen zum Teil sehr geringer Fallzahlen kann keine Aussage zu einzelnen Altersgruppen getroffen werden.\" oder auch: \"Die ARE-Rate liegt weiterhin unter den Werten der Vorsaisons auf einem extrem niedrigen Niveau.\". Das passt doch alles nicht zusammen. Kann mir jemand den Widerspruch erklären?\\n',\n",
       " 'Viele verstehen nicht, dass es noch nicht mal Halbzeit ist. Und dass Halbzeitergebnisse am Ende nicht zählen. Schweden, jedenfalls Stockholm, wird mit einem entscheidenden Vorteil in die zweite Halbzeit (zweite Welle) im Herbst/Winter gehen. Wenn es Verlängerung gibt (d.h. Keinen Impfstoff) werden sie dann locker vorbeiziehen.\\n',\n",
       " 'Wenn man die Mehrwertsteuer um \"dramatische\" 3% senkt und gleichzeitig Corona Soforthilfen im Milliardenbereich wieder zurück fordert , obwohl man öffentlich das genau Gegenteil behauptet hat, dann geht die Bazooka nach hinten los. Wo leben die Jungs nur ? Im Wolkenkuckucksheim ? \\n',\n",
       " 'Bis wir in Deutschland endlich die Maskenpflicht abgeschafft haben, steht die nächste Pandemie vor der Tür.   Die Deutschen lieben Sicherheit und Bevormundung, also kann es munter so weitergehen.   Ich platze vor Wut: Unter 1.000 neue Infizierte heute und 83 Millionen Menschen werden weiterhin unter Masken gezwungen. \\n',\n",
       " 'Jetzt müssen alle für die Unfähigkeit der für die Impfstoffbeschaffung Verantwortlichen in Brüssel und Berlin büssen.\\n',\n",
       " 'Also man braucht für die Aktion lauf vdL 40 Mrd. Euro, etwa 10% des Bundeshalts. Vorsichtshalber mal etwas mehr verlangen. Wahrscheinlich ist man sich schon Bill Gates darüber einig, dass 7 Mrd. Menschen geimpft werden. Warum und gegen was - das steht in den Sternen. Hoffentlich wird Widerstand2020 einen frischen Wind in die Politik bringen.\\n',\n",
       " 'Die WHO ist massgeblich von China finanziert und beeinflusst. Insofern sollte man deren Untersuchung nicht allzu abschliessend akzeptieren. Auch der Umstand, das Trump stets China für die Freisetzung des Virus unter Verdacht stellen wollte, muss nicht heissen, das das Gegenteil der Fall war. Klar ist auch, das Cina, sofern sie wirklich der Urheber des Virus wären, dies garantiert niemals zugeben könnten. Man stelle sich die enormen Schadensersatzforderungen vor, die auf sie zukommen würden. Unterm Strich bleibt nach wie vor ein wenig Raunen und der merkwürdige Umstand, das am Ursprungsort des Ausbruchs der Pandemie ein wichtiges virologisches Institut steht, an dem nachweislich an fledermausviren geforscht wurde. \\n',\n",
       " 'Alles alter Hut. Das interessanteste Medikament ist Ivermectin. In Vitro tötet 99.8% dieser Viren. Dabei ist das Medikament altbekannt... gegen Krätze, Läuse und Würmer. Wird benutzt als spot-on Tropfen, Salben, Tabletten... für Hunde, Katzen und Pferde. Ist immer noch zu kaufen! 8-D\\n',\n",
       " 'Mich würde ja brennend interessieren, wo die 250 \"Feiernden\" nach der Auflösung der Party hingegangen sind.  Dass die alle brav nach Hause sind glaubt doch wohl niemand ernsthaft, oder?\\n',\n",
       " 'Auch Nationalsozialisten sind völlig verfassungskonform an die Regierung gekommen. Und haben dann sie Lücken in der Verfassung genutzt um mit Verordnungen Ihr katastrophales Werk zu beginnen. War öffnen wir wieder diese Tore? Solche Gesetze können in Zukunft auch von Extremen verwendet werden. Irgendein Virus wird sich schon finden.  Und die Mehrheit applaudiert auch nur, wie 1937. Danke Herr Lindner. \\n',\n",
       " 'Hätte man sich darum gekümmert heraus zu finden wo denn tatsächlich die Infektionen herkommen  müsste man jetzt nicht panisch alles schließen.  Oder gibt es gar nicht DEN infektionsherd und es kommt von überall ein bisschen was dann zu einem großen ganzen wird?\\n',\n",
       " 'Es wäre genauer, wenn man nicht „Coronakrise“ sagen würde, um damit zu unterstellen, ein kleiner Virus hätte das ausgelöst. Auch wenn die Politiker und ihre Hofberichterstatter es so darstellen, um alle Verantwortung abzuschieben, ist diese Krise menschengemacht. Es gibt unzählige Gründe, die eine Rezession unumgänglich machten. Selbst das i-Tüpfelchen, der Shutdown, war eine bewusste Entscheidung der Politik, gegen alle Argumente der Epidemiologen. Ein Staatsvirologe als Feigenblatt reicht da nicht, um zu behaupten, es wäre, wie immer, „alternativlos“ gewesen.\\n',\n",
       " 'Krass, unsere Kinder sitzen mit Maske in der Schule, aber im Stadion sitzen die Zuschauer dicht an dicht ohne Abstandsregeln. Unglaublich, dass die Gesundheitsminister das auf EU-Ebene nicht stärker reglementiert haben. \\n',\n",
       " 'Namhafte Virologen wie Streeck haben schon immer schon gesagt, dass Corona - trotz Impfung - endemisch werden wird und wir mit dem Virus leben müssen.  Wenn die ganze Bevölkerung geimpft ist, who cares, ob man sich noch ansteckt. Jede Ansteckung und jeden Tod kann man nicht verhindern - das muss man auch gar nicht.\\n',\n",
       " 'Interessant wäre zu wissen, ob an dem Abend in Restaurant gesungen wurde (kommt ja vor mit Happy Birthday). Sehr viele große Ausbrüche haben mit Singen und Schreien zu tun.\\n',\n",
       " 'Zitat:  \"Johnson hat Klarheit versprochen, einstweilen aber nur Konfusion geschürt.\"  Für die Coronakrise gilt also das gleiche Rezept wie für den Brexit: Hauptsache raus, egal wie. Ein Plan kommt nachher.\\n',\n",
       " 'Im Restaurant? Heisst ich darf kein restaurant mehr besuchen wenn ich kein Mobiltelefon hab? Und wenn muss ich Fremde auf mein Display glotzen lassen um nachzuweisen dass ich die app aktiv nutze? langsam wirds albern....\\n',\n",
       " 'Könnt ihr diesen Blödsinn in Anbetracht der Ernsthaftigkeit der Situation mal lassen? Es gibt offensichtlich harte Auseinandersetzungen um die richtigen/notwendigen Maßnahmen zwischen den 16 Landesregierungen; die Bundesregierung versucht zu moderieren. Hier konstruieren Lydia, Veit und Christoph einen Machtkampf, wo keiner ist. Appell an das Verantwortungsbewusstsein eines Leitmediums!\\n',\n",
       " 'Es ist aus wirtschaftlicher und hygienischer Sicht falsch die Geschäfte zu schließen. In den verbliebenen offenen Geschäften werden sich mehr Menschen tummeln.  So schwer die Situation auch ist, man kann nicht das ganze Leben allein Corona unterwerfen. Bildungstechnisch ist es ein Verbrechen die Kinder wieder in den Distanzunterricht zu schicken. \\n',\n",
       " 'In der überregionalen Berichterstattung wird kaum bzw. wenig darüber geschrieben, dass in Hamburg die Kitas im Regelbetrieb sind und bleiben werden. Nachzulesen auf der Behörden Homepage. Von daher ist auch keine Notbetreuung notwendig, es kann ja jedes Kind kommen. Es wird lediglich an die Eltern appelliert.. Und wie weit man damit kommt, haben wir in den letzten Monaten gesehen.. \\n',\n",
       " 'Solange das Vereinsheim mit Bar zubleibt wäre es ja ok. Ich hatte micht schon gefragt, warum niemand mehr Golf spielt und zur gleichen Zeit sich die Menschen in München auf die Füße treten.\\n',\n",
       " 'SPON macht mit bei der Hetze der Covid19 Leugner. Damit schließt ihr inhaltlich auf zu BLÖD und LOCUS. Wenn sich bewahrheitet was Experten prognostizieren und Kliniker immer mehr und immer öfter Folgeschäden diagnostizieren werdet Ihr nichts mehr von Eurer dummen und kurzsichtigen Haltung wissen wollen. Wetten das? Für mich seid Ihr gestorben. \\n',\n",
       " 'Genau richtig so. Erst mal richtig die vorhandenen Daten auswerten bevor man  AZ weiter verimpft. Wenn man weiter verimpft und es treten dann noch mehr Fälle auf ist das gejammere wieder groß. \\n',\n",
       " \"Macht nichts. Die Bayern haben noch ganz viele andere Bereiche und viel Lebensfreude die Menschen aus aller Welt jedes Jahr anzieht. Zwischen IAA und Oktoberfest gibt's noch viele Gründe Bayern zu besuchen. \\n\",\n",
       " 'Ich denke, die förderale Struktur im Bildungsbereich darf gerne hinsichtlich ihres Sinnes und Zweckes auf den Prüfstand. Aber ich denke auch, dass der politische Wille nicht allzu groß sein wird.\\n',\n",
       " 'Hallo zusammen, hat sich eigentlich mal einer darüber Gedanken gemacht wie man mit der neuen Herrengesellschaft (geimpfte) umgehen soll gerade bei öffentlichen Veranstaltungen? Sollte man dann nicht geimpfte mit einem Zeichen an der Kleidung kennzeichnen um andere davor zu schützen? Um eventuelle schnelle Aussortierungen bei Fußballspielen zu Gewährleisten! Ich denke das ist nicht machbar und man sollte auch einmal die andere Seite der Medaille betrachte was daraus entstehen könnte.  Schließlich sind unsere Grundrechte doch ganz klar definiert und man sollte auch alle Menschen gleich behandeln egal ob weiß, schwarz  welche Glaubensrichtung oder ob geimpft oder nicht! Das ist die Entscheidung jedes einzelnen in unserer Gesellschaft. Bin mal gespannt ob ich, sollte ich mich nicht impfen lassen, beim nächsten Urlaubsflug nur noch einen Platz auf einer Tragfläche bekomme. Freue mich schon auf die Reaktionen für eine offene Diskussion.\\n',\n",
       " 'Laut \"Our World in Data\", zitiert in Guardian 31.1.2021 werden, bei der gegenwaertigen Impfrate, Ende September 15% der EU-Bevoelkerung geimpft sein. Es handelt sich also nicht um die \"kommenden Wochen\", sondern um die kommenden Jahre.  Wieviele Tote haben Merkel, Spahn, vdLeyen & Co. verschuldet?\\n',\n",
       " 'In unserer Region sind wesentlich kleinere Veranstaltungen abgesagt worden, um den 11. März herum. Absolut unverständlich, dass die CDU Frankenberg diese Merz-Veranstaltung durchlaufen ließ. \\n',\n",
       " 'Merkel: \"Ein Virus, das uns alle trifft, lässt sich von keinem Land allein besiegen.\"  Das ist schlicht falsch. Sind alle Bürger in einem Land geimpft, sind eben auch alle Bürger genau dieses Landes sicher vor dem Virus. Die geimpften Bürger können sich nicht mehr anstecken, weder von Touristen die ins Land kommen noch als Touristen bei Auslandsreisen! Wenn dem nicht so wäre könnte man sich die Impfungen sparen. \\n',\n",
       " 'Eigentlich ist es doch ganz einfach: Ich bleibe zu Hause, außer ich muss zur Arbeit, zum Arzt oder einkaufen. Man darf den Hund ausführen, joggen - nur sollte man grundsätzlich Abstand zu anderen Personen halten. Niemand will die Demokratie, die Vielfalt oder sonstiges abschaffen - wir sollten möglichst nur gesund bleiben. Ganz einfach!\\n',\n",
       " 'Da man als Geimpfter nicht davor gefeit ist positiv getestet zu werden, sehr wohl aber ein schwerer Krankheitsverlauf (fast) ausgeschlossen werden kann, halte ich die Abschaffung der Inzidenz als aussschließlichen Richtwert für Maßnahmen für sehr sinnvoll.\\n',\n",
       " 'Erstens will ich was von dem Zeug  haben, dass die Beamten im Ministerium bekommen, um so drauf zu kommen. Und zweitens möchte ich bei dem Quatsch den die da treiben mitmachen. Im Home-Office lustige Anregungen zu der Realsatire der DFL zu machen klingt nach einer spaßIgen Angelegenheit. Sonst gibt es da gerade nichts zu tun? Vielleicht Arbeitsschutz und Arbeitssicherheit für Erntehelfer verbessern? Oder wie steht es um die Arbeitnehmer in Supermärkten oder bald in zahlreichen Ladengeschäften?\\n',\n",
       " 'Japan handelt und kommt endlich in die Pötte\\n',\n",
       " 'Die älteren Schüler:innen könnte man auch jetzt schon impfen, zumal gerade für die Abschlussjahrgänge Präsenzunterricht unabhängig von der Inzidenz besteht. \\n',\n",
       " \"Ungeachtet dessen,was man von den Querdenkern zu halten pflegt ist es schon erschreckend ,wie geifernd die Masse hier nach härtester Repressalie von Staatsseite lechzt.  Gab's schonmal in diesem Land,kam international nicht so gut an, Mal vom arabischen Raum abgesehen...die pflegen noch heut ähnliche Phantasien,bei uns haben sich scheinbar auch nur die Opfer geändert\\n\",\n",
       " 'Ich denke, dass man angesichts der steigenden Zahlern in Deutschland auch hier wieder mehr Klopapier und Konserven einkaufen sollte, bevor erneut Panik ausbricht. Kein Mensch weiß, was Herbst und Winter unter den dann veränderten Lebensbedingungen bringen und man sollte auch nicht die Dummheit und Borniertheit vieler unbelehrbarer und selbst ernannter Schlaumeier unterschätzen.\\n',\n",
       " 'die Leute mit ihren mega super drakonischen lockdown Fantasien machen mir langsam wirklich Angst..\\n',\n",
       " 'Tja dann hat hat Corona doch was gutes .... die Grippe wurde auch ohne Impfung bekämpft ... Dann wissen wir ja was wir ab jedem Herbst bis Frühjahr tun müssen ..... Lockdown !!!! \\n',\n",
       " 'Ich möchte niemals das beste Deutschland aller Zeiten mit der autoritären Ländern wie der DDr vergleichen, da brauchte es zum bespitzeln moch nen Staatsapparat, hier nen netten Nachbarn und 3 Apps. Aber hier polemisch darauf hinweisen, dass man in der DDR im Inland Reisen und Essen gehen konnte ist fies, denn der Virus zwingt uns alle Ventile zu schließen und sich dann wundern, dass 20 jahrige nicht 14 Monate daheim bleiben, ist schon wohlwollend als naiv zu bezeichnen. Aber es wird niemand zum impfen gezwungen, dann bleibt halt der ungeimpfte im Berufsverbot und daheim. Dies ist kein Zwang, sondern Motivation, wie damals halt. Wenn du was dagegen hattest, musste man halt motiviert werden.\\n',\n",
       " \"Wer an Demonstrationen ohne Maske teilnimmt, silliest unterschreiben, I'm Falle einer Infektion auf intensivmedizinische Behandlung zu verzichten.\\n\",\n",
       " 'ist doch ganz einfach. Wer negativ getestet ist und die App verwendet darf wieder raus. Alle anderen haben Ausgangssperre...\\n',\n",
       " 'Abstand zu halten und eine Maske zu tragen ist nun wirklich kein Problem und dies zu einem allgemeinen Gebot zu machen auch nicht. Ein solches abzuschaffen setzt ein absolut falsches Signal. \\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 800.00 MiB (GPU 0; 4.00 GiB total capacity; 1.90 GiB already allocated; 317.91 MiB free; 2.53 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5528/1323956124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhello\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mid_to_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mall\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\germansentiment\\sentimentmodel.py\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mlabel_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1525\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         )\n\u001b[1;32m--> 990\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 )\n\u001b[0;32m    581\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     ):\n\u001b[1;32m--> 401\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 800.00 MiB (GPU 0; 4.00 GiB total capacity; 1.90 GiB already allocated; 317.91 MiB free; 2.53 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = SentimentModel()\n",
    "all = 0\n",
    "correct = 0\n",
    "\n",
    "hello = [id_to_label[x] for x in train_dict[\"labels\"][:150]]\n",
    "\n",
    "for idx, word in enumerate(model.predict_sentiment(train_dict[\"text\"][:150])):\n",
    "    print(word, idx)\n",
    "    all += 1\n",
    "    if hello[idx] == word:\n",
    "        correct+= 1\n",
    "\n",
    "print(correct/all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb0ed09b01ac7e66b2ee8fd1b727dbc61e234ad6836f9832d0e5faf71aa1bb7a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
