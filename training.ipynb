{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a6ddffa6c384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.getcwd()\n",
    "#os.chdir('c:\\\\Users\\\\Kirchner\\\\Desktop\\\\Masterarbeit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 50\n",
    "# def read_annotations(txt_name, mode):\n",
    "#     texts = []\n",
    "#     labels = []\n",
    "\n",
    "#     with open (txt_name, encoding = \"utf-8\", mode = \"r+\") as f:\n",
    "#         for line in f.readlines():\n",
    "#             texts.append(line.split(\"\\t\")[8])\n",
    "#             if mode == \"opinion\":\n",
    "#                 labels.append(line.split(\"\\t\")[5])\n",
    "#             elif mode == \"sentiment\":\n",
    "#                 labels.append(line.split(\"\\t\")[6])\n",
    "#             else:\n",
    "#                 print(f\"There is no label for {mode}\")\n",
    "\n",
    "#     return texts,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meine_texte, meine_labels  = read_annotations(\"cleaned_annotated_data_training.txt\", \"sentiment\")\n",
    "\n",
    "# texts_train = meine_texte[:train_size]\n",
    "# texts_test = meine_texte[train_size:]\n",
    "# labels_train = meine_labels[:train_size]\n",
    "# labels_test = meine_labels[train_size:]\n",
    "\n",
    "# print(len(labels_train), len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here we import the tokenizer that we already trained if we change the flag to False, otherwise we take the default\n",
    "### model\n",
    "default = True\n",
    "if os.path.isdir(\"meine_tokenizer\") and not default:\n",
    "    print(\"Loading finetuned tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meine_tokenizer_10E_sentiment_500\")\n",
    "else:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "if os.path.isdir(\"Sentiment_Bert_mit_spiegel\") and not default:\n",
    "    print(\"Loading finetuned model...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"Sentiment_Bert_mit_spiegel_10E_sentiment_500\")\n",
    "else:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'negative', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'positive', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'positive', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'positive', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'positive', 'neutral', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'positive', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'positive', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'positive', 'neutral', 'negative', 'negative', 'positive', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'neutral', 'negative', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'neutral', 'negative', 'negative', 'negative', 'negative', 'neutral', 'negative', 'neutral', 'neutral', 'negative', 'neutral']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809aa30c5fc548cb851c9787b578d5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23ac1a8d02a4de98ca63bf99aa01c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.632600</td>\n",
       "      <td>0.707747</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>9.786900</td>\n",
       "      <td>31.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>0.769817</td>\n",
       "      <td>0.668852</td>\n",
       "      <td>9.790200</td>\n",
       "      <td>31.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.382000</td>\n",
       "      <td>1.031478</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>9.831000</td>\n",
       "      <td>31.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>1.484996</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>9.823500</td>\n",
       "      <td>31.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>1.884604</td>\n",
       "      <td>0.659016</td>\n",
       "      <td>9.893600</td>\n",
       "      <td>30.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>1.986675</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.813900</td>\n",
       "      <td>31.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.302400</td>\n",
       "      <td>2.206053</td>\n",
       "      <td>0.681967</td>\n",
       "      <td>9.803400</td>\n",
       "      <td>31.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>2.267210</td>\n",
       "      <td>0.678689</td>\n",
       "      <td>9.803700</td>\n",
       "      <td>31.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>2.320161</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.798400</td>\n",
       "      <td>31.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>2.387798</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>9.887400</td>\n",
       "      <td>30.847000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 2 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 2\n",
      " 1 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 2 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 1 1 1 2 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 1\n",
      " 1 2 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 0 1 1 2 2 2 1 1\n",
      " 1 2 2 2 1 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [1 1 0 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 2 1 2 1 1 1 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 0 1 1 1 1 1 1 2\n",
      " 1 2 0 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 0 1 2 1 1 1 1 2 1 1\n",
      " 0 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 0 1 2 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 1 1 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 1 2 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 0 1 1 2 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [1 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 0 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 1 0 1 2 1 1 1 1 2 2 2\n",
      " 0 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1\n",
      " 0 2 2 2 2 2 1 2 1 2 2 2 2 2 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2 2 2 1 2 1 1 1 1\n",
      " 1 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 1 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 2 2 2 1 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 1 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 1 1 1 2 2 1 2 1 2 1 1 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 0 1 2 1 1 1 1 2 1 2\n",
      " 0 1 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 2 2 1 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 1 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 0\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 0 1 1 2 1 1 1 1\n",
      " 1 2 2 2 1 1 1 1 1] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 1 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 2 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 1 1 1 1 1 2 1 1 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 0 1 2 1 1 1 1 2 2 2\n",
      " 0 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 1 2 1 2 1 0 2 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 1 2\n",
      " 2 2 1 2 1 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 2 1 2 2 1 1 1 0 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 0 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n",
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 0 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 2 2 2 2 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 2 2 1 2 1 2 1 2 2 2 1 2 2 1 2 2 1\n",
      " 1 2 1 2 2 2 1 2 2 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 1 2\n",
      " 1 2 2 1 1 0 1 2 1 1 2 2 1 1 2 2 1 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 2\n",
      " 2 2 1 1 2 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 2 1 2 1 2 1 1 1 1 2 2 2 2 1 1 1\n",
      " 2 2 2 2 2 2 1 2 1 2 2 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 2 1 2 1 0 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 1 2 1 1 2 2 1 2 1 0 1 1 2 1 2\n",
      " 2 2 1 2 2 2 1 2 1 2 2 1 1 1 2 1 2 1 2 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 0 1 1 2 2 2 1 2\n",
      " 1 2 2 2 2 1 2 1 2] Labels [1 1 0 2 1 1 1 2 1 1 1 1 2 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 2 1\n",
      " 1 2 2 2 2 1 1 0 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1 1 2\n",
      " 1 2 1 1 1 1 1 2 1 1 2 0 1 1 1 2 1 1 2 1 0 2 2 2 1 1 1 2 1 2 1 1 1 1 2 2 1\n",
      " 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 1 2 1 1 2 2 1 2 1 2 1 1 2 2 1 1 2 1 1 1 1\n",
      " 2 2 1 2 2 1 1 2 1 2 1 2 1 1 1 0 1 1 2 1 1 2 2 1 1 2 1 1 2 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 2 0 2 1 1 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2\n",
      " 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 2 1 2 2 1 2 1 1 1 1 1 1 0 2 2 1 1 1 1 1\n",
      " 2 1 1 2 1 2 1 2 1 1 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 2 2 1 2 1 2 1 1 1 2 1 1\n",
      " 1 2 1 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a68ecee5ece470ab8f8b77f440ed755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fde903d47e4a6f943bce0ad4bb172f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.740900</td>\n",
       "      <td>0.660094</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>9.839400</td>\n",
       "      <td>30.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508700</td>\n",
       "      <td>0.728909</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>9.750900</td>\n",
       "      <td>31.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>1.141877</td>\n",
       "      <td>0.691803</td>\n",
       "      <td>9.899800</td>\n",
       "      <td>30.809000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>1.551630</td>\n",
       "      <td>0.695082</td>\n",
       "      <td>9.824600</td>\n",
       "      <td>31.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>1.897262</td>\n",
       "      <td>0.662295</td>\n",
       "      <td>9.834300</td>\n",
       "      <td>31.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>1.901902</td>\n",
       "      <td>0.675410</td>\n",
       "      <td>9.756200</td>\n",
       "      <td>31.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>2.076849</td>\n",
       "      <td>0.652459</td>\n",
       "      <td>9.896900</td>\n",
       "      <td>30.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>2.204491</td>\n",
       "      <td>0.665574</td>\n",
       "      <td>9.905500</td>\n",
       "      <td>30.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>2.335374</td>\n",
       "      <td>0.655738</td>\n",
       "      <td>9.918300</td>\n",
       "      <td>30.751000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>2.357194</td>\n",
       "      <td>0.662295</td>\n",
       "      <td>9.839000</td>\n",
       "      <td>30.999000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 0 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 2 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 2 1 1 1 2 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 0 2 1 1 2 2 2 1 1 1 1 2 1 0 2 2 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 1 2 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 0 2 1 2 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 0 1 2 2 1 1 1 2\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 1 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 2 2 1 2 1 1 2 2 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 0 1 2 2 1 1 1 2\n",
      " 2 2 1 1 1 1 1 1 0 1 1 1 2 2 2 1 2 1 2 2 2 1 2 1 1 1 1 1 2 2 1 2 2 1 2 1 2\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 2 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 2 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 1 2 2 0 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 0 1 1 1 2 1 2 1 2 1 2 2 2 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [1 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 2 1 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 1 2 2 1 1 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 2 2 2 1 1 1 2\n",
      " 2 2 1 1 1 1 1 1 0 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 1 1 1 1 2 2 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 1 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 1 1 1 1 0 1 1 1 2 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 2 1 1 2 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 2\n",
      " 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 1 2 1 0 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 1 1 0 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 0 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 2 2 1 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 0 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 1 1 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 0 2\n",
      " 2 2 1 1 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 1 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n",
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 2 1 1 2 1 2 2 2 2 2 1 1\n",
      " 2 2 1 1 1 1 1 2 2 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 2 1 2 1 1 2 1 2 2 1 2 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 2 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 2 1 2 1 2 1 1 1 1 1 1 1 1 2 2 1 1 2 2 2 1 1 1 1 2 1 2 1 2 2 2 1 1\n",
      " 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 2 2 1\n",
      " 2 2 2 1 2 2 1 2 2 2 1 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 1 2 1 2 1 2 1 1 2 1\n",
      " 2 1 1 2 2 2 2 1 2 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 2 1 2 1 1 2 2 1 1 1 2 1 1\n",
      " 2 2 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 0 2 2 2 1 1 1 2\n",
      " 0 2 1 2 2 1 1 1 0 1 1 1 2 2 2 1 1 1 2 2 1 1 2 1 1 2 1 1 2 2 1 2 2 1 2 1 1\n",
      " 1 1 2 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 1 0 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1\n",
      " 1 1 1 2 2 2 1 1 1] Labels [2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 1 2 2 2 1 1 2 1 1 2 2 1 1 2 2 2 1 2 2 1 1 1\n",
      " 2 1 2 1 2 1 1 0 2 1 2 1 2 1 1 2 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 1\n",
      " 2 0 1 1 1 2 2 2 2 1 2 1 1 1 1 1 2 2 2 1 2 2 2 1 1 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 1 2 1 1 2 1 1 1 1 1 1 2\n",
      " 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2\n",
      " 1 1 2 1 1 2 1 1 0 2 2 1 2 2 2 2 2 1 2 1 2 1 1 1 1 2 2 1 1 2 2 2 2 2 1 1 1\n",
      " 2 1 2 1 1 1 1 1 1 2 1 1 2 2 2 1 1 2 1 2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 0 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c714c2b617fe44e8a7414f84408ebb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153a243b0ba84d7c837388fee2577b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.716900</td>\n",
       "      <td>0.694590</td>\n",
       "      <td>0.685246</td>\n",
       "      <td>10.011400</td>\n",
       "      <td>30.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.807873</td>\n",
       "      <td>0.665574</td>\n",
       "      <td>9.951600</td>\n",
       "      <td>30.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>1.140784</td>\n",
       "      <td>0.645902</td>\n",
       "      <td>9.953100</td>\n",
       "      <td>30.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>1.661156</td>\n",
       "      <td>0.632787</td>\n",
       "      <td>10.023300</td>\n",
       "      <td>30.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>2.039891</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>10.001100</td>\n",
       "      <td>30.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>2.158947</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>10.004500</td>\n",
       "      <td>30.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>2.279195</td>\n",
       "      <td>0.642623</td>\n",
       "      <td>10.017400</td>\n",
       "      <td>30.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.427160</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>9.941900</td>\n",
       "      <td>30.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>2.470231</td>\n",
       "      <td>0.652459</td>\n",
       "      <td>10.001800</td>\n",
       "      <td>30.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>2.566108</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>10.121600</td>\n",
       "      <td>30.133000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 2 1 1 1 2 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2\n",
      " 1 2 2 2 1 2 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 1 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 2 2 1 2 2 1 1 1 1 1 1 1 2 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 2 2 1 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 1 2 0 1 1 1 2 1 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 2 1 2 1 1 1 2 1 1 1 1 1 2 2 1 1 1 0 1 1 1\n",
      " 0 1 2 1 1 2 0 1 2 2 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 1 2 2 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1\n",
      " 1 2 1 2 1 1 2 1 1] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [1 1 1 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 0 1 2 1 2 1 1 1 1 1 2\n",
      " 1 2 2 2 2 2 1 2 2 1 1 1 2 2 1 1 1 0 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 1 2 2 2\n",
      " 1 1 1 2 1 1 1 2 1 1 1 0 1 1 1 1 1 1 2 1 1 1 1 2 0 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 0 1 2 1 1 1 0 1 1 2 1 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1\n",
      " 1 1 2 1 2 1 0 1 2 2 1 2 1 0 1 1 2 1 1 1 1 2 2 1 1 1 1 2 2 1 1 1 1 2 0 1 1\n",
      " 1 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 2 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 2 1 1 1 2 2 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 2 1 2 1 1 1 2 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 2 1 1 1 2 2 1 2 1 2 0 2 1 1 1 2 1 1 2 2 1 2 2 1 1 1 0 2 1 2\n",
      " 2 1 2 1 1 2 0 1 1 2 2 2 1 1 2 2 2 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 2 2 1 1 1 2 2 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 2 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 0 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 0 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 2 0 1 2 2 2 2 1 1 2 2 2 0 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 0 1 2 2 1 1 2 1 0 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 1 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 2 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 1 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 2 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 0 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 0 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 2 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 0 1 2 2 1 1 2 1 0 2 1 1 2 1 2 2 1 1 2 1 2 0 2 1\n",
      " 2 2 1 2 1 2 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 2 2 2 1 1 1 2 2 1 1 1 2 2 2 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 2 2 2 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 2 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 2 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 2 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 2 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 2 2 2 2 1 1 2 1 2 2 1 1 1 1 2 0 2 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 1 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 1 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 1 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 1 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 0 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n",
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 2 2 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 2 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 2 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [0 2 2 1 1 2 1 2 2 2 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 0 2 2 1 2 1 2 1 1 1 2\n",
      " 1 2 2 2 1 2 1 2 2 1 1 1 2 2 1 1 1 2 2 1 1 2 1 2 1 2 1 2 1 1 2 2 2 1 2 1 2\n",
      " 2 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 2 1 2 1 2 1 2 2 2 1 1 1 2 2 1 2 1 1 2 1\n",
      " 1 1 1 2 0 1 1 2 2 1 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2 2\n",
      " 1 2 1 2 1 1 1 2 1 1 1 0 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 1 1 2 1\n",
      " 1 1 1 1 1 1 2 2 1 1 1 2 2 1 1 1 2 0 2 1 1 1 2 1 1 0 2 1 2 2 1 1 1 0 1 1 2\n",
      " 1 1 2 1 1 1 0 1 1 2 2 2 1 1 2 2 2 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1\n",
      " 2 1 2 1 2 2 0 1 2 2 1 2 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 2 2 1 1 1 1 2 0 1 1\n",
      " 2 2 1 2 1 1 2 1 2] Labels [2 2 2 2 2 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 2 2\n",
      " 1 2 2 2 1 2 2 2 1 2 1 1 2 2 1 1 1 2 2 1 1 2 1 1 1 2 2 2 1 1 2 1 2 1 2 1 2\n",
      " 2 2 1 1 1 1 2 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 2 1 2 1 2 2 1\n",
      " 1 1 2 1 1 1 2 1 2 1 2 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 2 2 2\n",
      " 2 1 1 2 1 2 2 1 1 2 2 1 2 1 0 2 1 1 2 1 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 1 2\n",
      " 1 1 2 1 2 1 1 2 1 0 1 2 2 1 2 2 1 0 2 1 1 1 2 1 1 1 1 2 2 2 2 1 1 2 2 2 1\n",
      " 0 1 2 1 1 2 0 2 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 1 2 1 1 2 1 2 1 1 1 1 2 1 1\n",
      " 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 2 1 1 2 2 0 1 1 1 2 1 1 1 2 2 2 1 1 2 1 1\n",
      " 1 2 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba6f5ae85f847868213bfe7bbbd4bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21963b1c3e9541b5a892c19361e91255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.745369</td>\n",
       "      <td>0.634868</td>\n",
       "      <td>10.223300</td>\n",
       "      <td>29.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.793736</td>\n",
       "      <td>0.638158</td>\n",
       "      <td>10.166500</td>\n",
       "      <td>29.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>1.057242</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.224800</td>\n",
       "      <td>29.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>1.513468</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.323400</td>\n",
       "      <td>29.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>1.772506</td>\n",
       "      <td>0.641447</td>\n",
       "      <td>10.154800</td>\n",
       "      <td>29.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>2.146400</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10.157700</td>\n",
       "      <td>29.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>2.136032</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10.207800</td>\n",
       "      <td>29.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>2.245049</td>\n",
       "      <td>0.621711</td>\n",
       "      <td>10.226800</td>\n",
       "      <td>29.726000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>2.434262</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>10.238200</td>\n",
       "      <td>29.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>2.476676</td>\n",
       "      <td>0.634868</td>\n",
       "      <td>10.320700</td>\n",
       "      <td>29.455000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 1 1 1 2 1 2 1 2 2 1 1 1 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1\n",
      " 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 1 1 2 2 1\n",
      " 2 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 1 1 1 2\n",
      " 1 1 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 1 1 1 2 2 1 2 1 1 1 1 1\n",
      " 1 1 1 2 2 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 2 1 1 1 2 1 1\n",
      " 2 1 1 1 1 1 2 1] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 1 2 1 2 1 1 1 2 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2\n",
      " 1 2 2 2 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 1 2 1 1 2 2 1 1 1 1 2 2 1\n",
      " 2 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 1 1 1 2 1 2\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 2 1 1 1 2\n",
      " 1 1 1 0 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 0 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 1 1 1 1\n",
      " 1 1 1 2 2 1 1 1 1 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 1 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 1] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 2 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 2 1 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 1 1 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 0 1 2 1 1 2 1 2\n",
      " 1 1 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 2 0 2 2 1 2 1 1 1 1 2 1 2 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 1 1 1 1 2 2 1 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 1 1 1 2 1 0 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 1 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 1 2 2 2 1 1 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 1 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 2 2 2 2 2 1 2 2 2 2 1 2 2 1 1 0 2 2 2 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 2 1 2 1 1 1 2 1 2 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 2 1 2 2 2 2 1 2 1 1 1 2 2 1 0 2 1 2 2 1 1 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 2 2 1 2 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 2 1 0 2 1 2 1 1 1 2 2 1 2 1 2 1 1 2 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 2 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 2 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 1\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 2 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 1 2 1 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 2 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 2 1 1 1 2 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 2 1 1 0 2 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 2 2 1 1 1 2 1 2 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 0 1 1 1\n",
      " 1 1 2 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n",
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 2 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 2 2 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 1 1 2 1 1 0 2 2 1 1 2 1 2\n",
      " 1 2 2 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 2 1 2 2 1 1 2 1 1 2 2\n",
      " 2 2 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 2 1 0 2 1 1 2 1 2 2 1 2 1 1 1 1 1 2 1 2\n",
      " 2 2 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 0 1 2 1 1 2 2 2\n",
      " 1 1 1 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 2 1 2 1 1 1 2 2 1 2 1 1 2 1 2 1 1 1 2\n",
      " 1 2 1 0 2 2 1 2 1 1 1 2 2 1 2 1 1 1 2 1 0 1 2 1 1 1 1 1 2 1 1 1 2 0 1 2 2\n",
      " 2 2 2 1 1 1 1 1 1 1 0 2 1 2 2 1 1 2 1 1 2 1 2 2 2 2 1 2 2 2 2 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 1 1 2 2 1 1 1 1 2 1 1 2 1 1 1 2 1 2 2 2 1 2 1 2 2 1 2 1 2 1 1\n",
      " 2 1 1 1 1 1 2 2] Labels [1 1 1 1 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 1 1 1 1 2 0 1 1 2 1 2 2 1\n",
      " 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 0 2 1 2 2 1 2 1 2 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 1 2 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 1 2 1 1 2 1 2 1 1 1 1 2 1 2 1 1 2 1 1 1 1 2 1 2 1 2 1 1 2 2 1\n",
      " 1 1 1 1 2 1 2 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 2 1 1 1 1 2 2 1 1 2\n",
      " 2 2 2 0 2 2 2 1 1 1 1 1 1 2 1 1 2 2 0 1 0 1 1 2 1 1 1 1 2 1 2 2 2 1 2 2 2\n",
      " 1 1 2 1 1 1 2 1 1 2 1 1 1 1 2 2 1 1 2 1 1 1 2 1 1 0 1 1 2 2 2 1 1 2 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 1 1 2 1 1\n",
      " 2 2 2 2 2 2 2 2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12f8cb3d99a4706b030bd27edb5796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ad267b43f948138319301a136e13d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 11:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>0.803334</td>\n",
       "      <td>0.641447</td>\n",
       "      <td>9.999100</td>\n",
       "      <td>30.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.553400</td>\n",
       "      <td>0.836447</td>\n",
       "      <td>0.654605</td>\n",
       "      <td>10.002300</td>\n",
       "      <td>30.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>1.390960</td>\n",
       "      <td>0.572368</td>\n",
       "      <td>9.999800</td>\n",
       "      <td>30.401000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>1.543026</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>10.017400</td>\n",
       "      <td>30.347000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>1.986813</td>\n",
       "      <td>0.601974</td>\n",
       "      <td>10.032600</td>\n",
       "      <td>30.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>2.164478</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>9.927600</td>\n",
       "      <td>30.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>2.321298</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>10.039400</td>\n",
       "      <td>30.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>2.476327</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>10.091400</td>\n",
       "      <td>30.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.243400</td>\n",
       "      <td>2.412344</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>10.102600</td>\n",
       "      <td>30.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>2.613653</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>9.959000</td>\n",
       "      <td>30.525000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 1 2 1 2 1 2 1 2 1\n",
      " 1 1 1 2 1 1 2 1 2 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 1 2 1\n",
      " 1 2 1 2 2 2 1 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 2 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 1 1 1 2 2 0 1 1 1 1 1 1 0 1 2 1 1 1 1 2 2 1 1 2 2 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 2 1 1 2 1 2 1 1 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 2 1 1 2 1 2 1 2 1 1 2 2 1 1 2 2 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 1 2 2 2 1 1 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 1 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 1\n",
      " 1 1 1 1 1 2 2 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 2 1 1 1 1 1 2 1 1 2 1\n",
      " 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 1 1 1 2 2 0 1 1 1 1 1 1 0 1 1 1 1 1 2 2 2 1 1 2 2 2 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 1 1 1 2 2 2 1 1 1 2 1 2 1 1\n",
      " 2 1 1 1 2 1 2 1 2 1 1 2 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 2 1 1 2 2 1 1 1 2 2 2 1 1 1 2 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2\n",
      " 2 1 1 1 2 2 1 1 2 2 1 1 1 1 2 2 1 1 1 1 1 1 1 1 2 1 0 2 1 1 1 2 1 1 1 1 1\n",
      " 2 1 2 1 1 2 1 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 2 2 1 2 2 1 2 1 2 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 1 2 1 2 2 2 2 1 2 2 1 1 2 2 1 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 2 2 2 2 2 2\n",
      " 2 2 1 2 2 2 2 2 2 1 2 1 1 2 1 1 2 2 1 1 2 1 2 2 2 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 2 2 2 0 2 2 2 1 1 1 0 2 2 2 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 2 2 2 2 2 1 1 1 2 1 1 2 1 2 2 2 2 1 2 2 1 2 2 1 2 2 2 1 1 1 2 2 2 2 2\n",
      " 2 2 1 1 2 2 2 1 2 2 2 2 1 2 2 2 2 2 1 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 1 2 2 2 2 2 0 1 1 2\n",
      " 2 1 2 1 2 2 2 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 1 2 1 2 2 1 1 1 2 1 1 1 2 1 1 1 2 2 1 1 1 2 1 1 1 2 2 2 1 1 2 2\n",
      " 1 2 1 1 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 1 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 1 2 2 0 1\n",
      " 1 2 1 1 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 1 2 2 1 1 2 2 2 2 1 1 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 1 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 0 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 0 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 2 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 1 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n",
      "Predictions [2 1 1 0 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 1 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 1 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 1\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 1 1 2 1 1 1 0 2 2 1 1 1 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 1 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 1 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 1 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 1 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 1 1 2 2 2 1 1 0 1 1 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 2 1 2 1\n",
      " 1 1 1 2 2 2 2 1 2 2 1 1 2 2 1 1 1 2 2 1 1 2 2 1 1 1 2 1 2 1 2 2 2 1 2 2 2\n",
      " 1 2 1 2 2 2 2 1 2 1 2 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 2 2 2 2 1 1 1 2\n",
      " 1 1 1 2 1 1 2 0 2 1 2 1 1 2 2 0 2 1 2 1 1 1 0 2 2 1 1 2 2 2 2 2 2 2 2 0 2\n",
      " 1 2 0 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 1 2 2 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1\n",
      " 2 2 1 1 2 2 2 1 2 2 1 2 1 2 2 2 2 1 1 2 2 1 1 2 2 1 1 2 2 1 1 1 1 1 2 2 1\n",
      " 2 1 1 2 2 2 2 1 1 2 2 2 2 1 2 1 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 1 2 1 1 1 2\n",
      " 2 1 2 1 2 2 1 1 2 2 2 1 2 1 2 2 2 1 1 0 1 2 1 1 2 2 0 1 1 1 1 2 1 1 2 1 1\n",
      " 2 1 2 1 2 2 2 2] Labels [0 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 2 2 2 2 1 2 2 1 1 1 1 1 2 2 2 2 1 2 2 1 1\n",
      " 2 2 1 1 1 1 2 1 1 2 1 1 1 1 1 2 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 2 1 1 2 1\n",
      " 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 2 2 0 2 1 1 2 1 1 1 2 1 2 1 2 2 1 2 1 0\n",
      " 2 1 1 2 2 1 2 2 2 1 2 1 1 1 2 1 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 2 1 1 2 2 1\n",
      " 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 2 0 2 2 1 2 2 1 1 1 2 2 2 2 1 1 1 2 2 2 1 1\n",
      " 2 1 2 2 1 1 2 1 0 1 2 1 2 1 1 2 2 2 1 1 2 1 1 2 2 1 1 1 2 1 1 1 2 1 1 2 2\n",
      " 2 2 1 1 2 1 1 0 2 2 2 2 2 2 2 1 2 1 1 1 0 2 1 1 0 1 1 2 1 1 2 1 1 1 2 1 2\n",
      " 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 2 1 1 1 1 2 1 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1\n",
      " 1 1 2 1 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "data_text = []\n",
    "data_labels = []\n",
    "text_train = []\n",
    "labels_train = []\n",
    "text_test = np.array([])\n",
    "labels_test = np.array([])\n",
    "\n",
    "\n",
    "label_to_id = {\"positive\" : 0, \"negative\" : 1, \"neutral\" : 2}\n",
    "id_to_label = {0:\"positive\", 1:\"negative\", 2:\"neutral\"}\n",
    "\n",
    "### Here we create a training set that can be used to compare across different sizes of training data\n",
    "\n",
    "mein_dataframe1 = pd.read_csv(\"annotated_data_with_users_automatic.csv\", header=None)\n",
    "mein_dataframe1.columns = [\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\",\n",
    "                          \"topic_comment\", \"Topic_article\", \"Comment\", \"Method\"]\n",
    "\n",
    "display(len(mein_dataframe1))\n",
    "# split_index = int(len(mein_dataframe1)*0.8)\n",
    "for index, row in mein_dataframe1.iterrows():\n",
    "    data_text.append(row[\"Comment\"])\n",
    "    data_labels.append(row[\"Sentiment\"])\n",
    "\n",
    "print(data_labels)   \n",
    "# ### Define test and train set\n",
    "# text_test = text_train[split_index+1:]\n",
    "# text_train = text_train[:split_index]\n",
    "# labels_test = labels_train[split_index+1:]\n",
    "# labels_train = labels_train[:split_index]\n",
    "\n",
    "\n",
    "### Replace label as int\n",
    "for idx, labels in enumerate(data_labels):\n",
    "    data_labels[idx] = label_to_id[labels]\n",
    "\n",
    "\n",
    "# for idx, labels in enumerate(labels_test):\n",
    "#     labels_test[idx] = label_to_id[labels]\n",
    "    \n",
    "    \n",
    "\n",
    "# with open (\"cleaned_annotated_data_training.txt\", encoding=\"utf-8\", mode=\"r+\") as f:\n",
    "#     training_data = f.readlines()\n",
    "#     split_index = int(len(mein_dataframe1)*0.8)\n",
    "    \n",
    "#     ### The split on index 6 gives us Sentiment, split on 5 Opinion\n",
    "    \n",
    "#     ### The first 88 annotations had been annotated without a article topic\n",
    "#     for line in training_data[:88]:\n",
    "#         text_train.append(line.split(\"\\t\")[8])\n",
    "#         labels_train.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "#     for line in training_data[89:split_index]:\n",
    "#         text_train.append(line.split(\"\\t\")[9])\n",
    "#         labels_train.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "#     for line in training_data[split_index+1:]:\n",
    "#         text_test.append(line.split(\"\\t\")[9])\n",
    "#         labels_test.append(label_to_id[line.split(\"\\t\")[6]])\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding = True, truncation=True)\n",
    "\n",
    "def calculate_entropy(logits):\n",
    "    probas = torch.nn.Softmax(dim=1)(torch.from_numpy(logits))\n",
    "    samples_entropy = entropy(probas.transpose(0, 1).cpu())\n",
    "    samples_entropy = torch.from_numpy(samples_entropy)\n",
    "    return samples_entropy\n",
    "\n",
    "def compute_metrics_accuracy(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        print(\"Predictions\", predictions, \"Labels\", labels)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "### Define splits for k fold cross validation\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "### Convert to numpy array\n",
    "data_text = np.array([i for i in data_text])\n",
    "data_labels = np.array([i for i in data_labels])\n",
    "\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "metric = load_metric(\"accuracy\")\n",
    "hello = []\n",
    "for train_index, test_index in folds.split(data_text, data_labels):\n",
    "    text_train, labels_train  = data_text[train_index], data_labels[train_index]\n",
    "    text_test, labels_test  = data_text[test_index], data_labels[test_index]\n",
    "\n",
    "    train_dict = {\"texts\": text_train, \"labels\" : labels_train}\n",
    "    test_dict = {\"texts\": text_test, \"labels\" : labels_test}\n",
    "\n",
    "    # print([len(z) for z in [text_train, text_test]])\n",
    "\n",
    "\n",
    "    ### Remove newline characters\n",
    "    for idx, text in enumerate(train_dict[\"texts\"]):\n",
    "        train_dict[\"texts\"][idx] = text.rstrip(\"\\n\")\n",
    "\n",
    "    for idx2, text2 in enumerate(test_dict[\"texts\"]):\n",
    "        test_dict[\"texts\"][idx2] = text2.rstrip(\"\\n\")\n",
    "        \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    meine_dataset_train = Dataset.from_dict(train_dict)\n",
    "\n",
    "    mein_dataset_test = Dataset.from_dict(test_dict)\n",
    "\n",
    "    tokenized_dataset_train = meine_dataset_train.map(preprocess_function, batched= True)\n",
    "    tokenized_dataset_test = mein_dataset_test.map(preprocess_function, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model= AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\"),\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset_train,\n",
    "        eval_dataset=tokenized_dataset_test,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics = compute_metrics_accuracy\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "#     index_topk = torch.topk(calculate_entropy(trainer.predict(tokenized_dataset_test).predictions), 20).indices\n",
    "#     print(index_topk)\n",
    "#     for x in index_topk:\n",
    "#         print(meine_dataset_train[\"texts\"][x], \"SATZ\")\n",
    "    accuracies.append(trainer.evaluate()['eval_accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6401488352027609"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Cross validated accuracy\n",
    "print(len(text_train))\n",
    "sum(accuracies)/len(accuracies)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_text_tokenized = tokenizer(text_train, truncation=True, padding=True)\n",
    "\n",
    "# test_text_tokenized = tokenizer(text_test, truncation=True, padding=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding = True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b87b2cbca73061b8\n",
      "Reusing dataset text (C:\\Users\\Kirchner\\.cache\\huggingface\\datasets\\text\\default-b87b2cbca73061b8\\0.0.0\\e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "100%|| 2/2 [00:00<00:00, 795.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# spiegel = SpiegelDataset(\"cleaned_annotated_data_training.txt\")\n",
    "\n",
    "# spiegel_data = load_dataset(\"text\", data_files={\"train\": \"Spiegel_train.txt\", \"test\" : \"Spiegel_test.txt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c72160823f460793d6a558ba67693b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bf08d370394d8287aee2c48336df4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dict = {\"texts\" : text_test,\n",
    "            \"labels\" : labels_test}\n",
    "            \n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(\"Predictions\", predictions, \"Labels\", labels)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "meine_dataset_train = Dataset.from_dict(train_dict)\n",
    "\n",
    "mein_dataset_test = Dataset.from_dict(test_dict)\n",
    "\n",
    "\n",
    "tokenized_dataset_train = meine_dataset_train.map(preprocess_function, batched= True)\n",
    "tokenized_dataset_test = mein_dataset_test.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "158\n",
      "514\n",
      "149\n",
      "285\n",
      "228\n",
      "379\n",
      "197\n",
      "373\n",
      "242\n",
      "399\n",
      "547\n",
      "252\n",
      "669\n",
      "105\n",
      "601\n",
      "944\n",
      "301\n",
      "353\n",
      "329\n",
      "216\n",
      "315\n",
      "149\n",
      "244\n",
      "423\n",
      "589\n",
      "369\n",
      "434\n",
      "392\n",
      "594\n",
      "137\n",
      "457\n",
      "417\n",
      "147\n",
      "298\n",
      "117\n",
      "561\n",
      "62\n",
      "389\n",
      "312\n",
      "180\n",
      "661\n",
      "160\n",
      "173\n",
      "132\n",
      "85\n",
      "650\n",
      "174\n",
      "398\n",
      "703\n",
      "891\n",
      "454\n",
      "120\n",
      "220\n",
      "1074\n",
      "159\n",
      "238\n",
      "534\n",
      "451\n",
      "431\n",
      "181\n",
      "308\n",
      "117\n",
      "146\n",
      "84\n",
      "468\n",
      "100\n",
      "306\n",
      "193\n",
      "167\n",
      "554\n",
      "79\n",
      "771\n",
      "409\n",
      "846\n",
      "403\n",
      "350\n",
      "477\n",
      "193\n",
      "296\n",
      "635\n",
      "274\n",
      "201\n",
      "191\n",
      "347\n",
      "124\n",
      "796\n",
      "173\n",
      "550\n",
      "109\n",
      "318\n",
      "211\n",
      "81\n",
      "537\n",
      "781\n",
      "459\n",
      "513\n",
      "106\n",
      "374\n",
      "156\n",
      "312\n",
      "156\n",
      "168\n",
      "310\n",
      "97\n",
      "250\n",
      "131\n",
      "93\n",
      "323\n",
      "136\n",
      "214\n",
      "339\n",
      "188\n",
      "545\n",
      "391\n",
      "375\n",
      "313\n",
      "691\n",
      "424\n",
      "333\n",
      "510\n",
      "253\n",
      "480\n",
      "178\n",
      "126\n",
      "203\n",
      "130\n",
      "270\n",
      "436\n",
      "376\n",
      "360\n",
      "263\n",
      "539\n",
      "547\n",
      "174\n",
      "222\n",
      "254\n",
      "226\n",
      "328\n",
      "660\n",
      "263\n",
      "238\n",
      "562\n",
      "70\n",
      "821\n",
      "328\n",
      "378\n",
      "702\n",
      "190\n",
      "509\n",
      "294\n",
      "449\n",
      "409\n",
      "151\n",
      "406\n",
      "675\n",
      "345\n",
      "414\n",
      "313\n",
      "297\n",
      "233\n",
      "101\n",
      "275\n",
      "428\n",
      "494\n",
      "466\n",
      "70\n",
      "510\n",
      "1376\n",
      "326\n",
      "287\n",
      "455\n",
      "241\n",
      "983\n",
      "345\n",
      "278\n",
      "292\n",
      "264\n",
      "138\n",
      "135\n",
      "105\n",
      "236\n",
      "468\n",
      "359\n",
      "364\n",
      "433\n",
      "300\n",
      "741\n",
      "352\n",
      "137\n",
      "124\n",
      "197\n",
      "929\n",
      "188\n",
      "844\n",
      "206\n",
      "181\n",
      "132\n",
      "144\n",
      "91\n",
      "207\n",
      "104\n",
      "439\n",
      "289\n",
      "306\n",
      "104\n",
      "873\n",
      "459\n",
      "397\n",
      "252\n",
      "576\n",
      "471\n",
      "121\n",
      "386\n",
      "257\n",
      "97\n",
      "118\n",
      "234\n",
      "444\n",
      "648\n",
      "572\n",
      "281\n",
      "288\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_dataset_test[\"texts\"]:\n",
    "    print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1130' max='1130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1130/1130 15:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.787600</td>\n",
       "      <td>0.751194</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>12.594500</td>\n",
       "      <td>17.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.883527</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>10.334500</td>\n",
       "      <td>21.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>1.501034</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>10.227100</td>\n",
       "      <td>21.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>2.193896</td>\n",
       "      <td>0.602679</td>\n",
       "      <td>10.247200</td>\n",
       "      <td>21.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>2.759660</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>10.233900</td>\n",
       "      <td>21.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>3.217661</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>12.104400</td>\n",
       "      <td>18.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.350807</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>11.324300</td>\n",
       "      <td>19.781000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>3.392122</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>10.154500</td>\n",
       "      <td>22.059000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>3.372744</td>\n",
       "      <td>0.616071</td>\n",
       "      <td>10.282700</td>\n",
       "      <td>21.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>3.416090</td>\n",
       "      <td>0.620536</td>\n",
       "      <td>10.338800</td>\n",
       "      <td>21.666000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 1 1 1 2 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 1 1 2 1 0 1\n",
      " 2 1 0 1 1 2 2 2 1 1 2 1 1 1 2 2 1 1 2 2 1 2 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 2 1 1 1 1 1 1 1 1 1 2 2 1 1 1 2 1 1 1 1 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 1 2 1 1 1 0 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 1 2 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 2 1 2 2 1 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 1 1 2 2 1 1 1 1 1 2 1 1 2 1 1 1 1 2 1 1 1 2 1 2 1 1 2 1 1 1 1 1 1\n",
      " 1 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 1 2 1 1 2 2 2 1 2 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 2 2 2 2 1 1 2 1 1 1 2 2 1 2 2 1 1 1 2 2 1 2 2 1 2 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 1 1 1 2 1 1 2 1 2 2 2 2 1 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 2 2 1 1 1 2 1 2 2 2 2 1 2 1 2 1 2 2 1 1 2\n",
      " 2 2 1 2 2 1 2 2 1 2 2 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 2 2 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 1 1 2 1 1 1 2 1 2 1 1 2 1 0 1 1 1 2 1 2 1 1 2 1 2 2 1 1 2 1 2 1\n",
      " 2 1 0 1 1 2 1 2 1 2 2 1 1 1 1 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 1 1\n",
      " 2 1 1 1 1 1 0 2 1 1 2 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 1 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 1 1 1 0 1 1 2 1 1 1 2 2 1 1 2 1\n",
      " 1 1 1 2 1 2 1 2 2 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 1 1 2 1 1 2 1 1 1 1 1 1 2 1 1 2 1 2 1 1 2 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1\n",
      " 1 1] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 2 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 2 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 2 1 1 1\n",
      " 2 1 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 1 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 0 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 0 1 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 1 1 0 2 0 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 1 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 2 2 2 2 1 1 2 2 2 2 1 1 2 2 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 2 2 2\n",
      " 2 2 1 2 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 2 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 2 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 2 1 2 2 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 2 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 2 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 2 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 1 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/username/anaconda3/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:64: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 1 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 0 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 1 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 1 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n",
      "Predictions [2 1 2 2 0 2 1 2 1 1 2 0 2 2 1 1 2 1 2 1 1 1 2 1 2 1 1 2 1 2 2 1 2 2 1 2 1\n",
      " 2 1 0 1 1 2 2 2 1 2 2 2 1 1 2 2 1 2 2 2 1 2 2 1 1 2 2 1 1 1 1 2 1 1 1 2 2\n",
      " 2 1 1 2 1 2 0 2 1 1 2 1 1 1 2 1 1 2 2 1 2 1 1 1 1 1 2 1 1 0 2 2 2 2 1 2 1\n",
      " 2 2 2 1 1 1 1 1 1 1 2 1 2 1 2 2 2 2 2 2 2 2 1 1 0 1 1 2 1 2 2 2 2 2 1 2 1\n",
      " 2 1 1 2 1 2 2 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 1 2 2 2 2 1 1 1 2 1 2 1 1 1 1\n",
      " 2 0 1 2 1 1 2 2 1 2 1 1 1 2 1 1 2 2 2 1 1 2 2 1 1 2 1 2 2 1 1 2 1 1 1 2 2\n",
      " 2 2] Labels [1 1 1 2 2 1 1 2 2 1 1 0 1 2 2 1 2 2 1 2 1 1 2 1 2 2 1 2 2 2 2 1 1 2 1 1 1\n",
      " 0 1 2 1 1 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 1 2 2 2 1 2 1 1 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 2 0 1 0 2 1 1 2 1 1 2 2 1 2 2 2 2 1 1 0 1 1 1 1 1 1 1 1 0 2 1 1 2 2\n",
      " 1 2 2 1 1 1 1 2 1 1 2 1 2 2 1 2 2 1 1 2 1 2 1 1 1 2 1 2 1 2 1 2 1 1 2 1 1\n",
      " 2 1 1 1 2 2 2 2 2 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 2 1 0 1 2 2 2 1 1 2 1 1 2\n",
      " 2 1 2 2 1 1 2 2 1 1 1 1 1 2 1 2 1 1 1 1 2 2 1 1 2 2 1 2 2 2 2 2 1 2 2 2 1\n",
      " 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1130, training_loss=0.25791671365639607, metrics={'train_runtime': 913.8611, 'train_samples_per_second': 1.237, 'total_flos': 2339215992120240, 'epoch': 10.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics = compute_metrics_accuracy\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX TITAN X'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('meine_tokenizer_10E_sentiment_1000_2e-5/tokenizer_config.json',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/special_tokens_map.json',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/vocab.txt',\n",
       " 'meine_tokenizer_10E_sentiment_1000_2e-5/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save_pretrained(\"Sentiment_Bert_mit_spiegel_10E_sentiment_1000_2e-5\")\n",
    "tokenizer.save_pretrained(\"meine_tokenizer_10E_sentiment_1000_2e-5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "len(train_text_tokenized[\"attention_mask\"])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14828/730226842.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1258\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\data\\data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         batch = self.tokenizer.pad(\n\u001b[0m\u001b[0;32m    222\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_input_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m             raise ValueError(\n\u001b[1;32m-> 2693\u001b[1;33m                 \u001b[1;34m\"You should supply an encoding or a list of encodings to this method \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2694\u001b[0m                 \u001b[1;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m             )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# training_args = TrainingArguments(output_dir=\"./results\",\n",
    "#                     learning_rate=2e-5,\n",
    "#                     per_device_eval_batch_size=4,\n",
    "#                     per_device_train_batch_size=4,\n",
    "#                     num_train_epochs=3,\n",
    "#                     weight_decay=0.01\n",
    "#                     )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#             model=model,\n",
    "#             args=training_args,\n",
    "#             train_dataset=train_text_tokenized,\n",
    "#             eval_dataset=test_text_tokenized,\n",
    "#             tokenizer = tokenizer,\n",
    "#             data_collator= data_collator\n",
    "# )\n",
    "\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from germansentiment import SentimentModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nachtrag: Dieser Artikel ist wirklich enttuschend. Dass es manchem Leser vielleicht schwerfllt, sich an den Ablauf der Ereignisse zu erinnern, oder diese in einen Kontext zu setzen, okay. Aber der Spiegel? Da knnte man ja wirklich vermuten, das sei Click-Baiting, um Seitenaufrufe zu generieren, oder vom US-Auenministerium abgeschrieben. Wahrscheinlich aber doch einfach nur Naivitt und leichte Beeinflussbarkeit der Autoren.\\n',\n",
       " 'Ein Flugzeug aus China macht noch keinen Frhling. Die Kritik dieses Artikels ist vllig unangebracht. Die EU hat gesundheitspolitisch fast keine Befugnisse. Das ist so gewollt und an sich auch sehr vorteilhaft. Koordinierte politische Aktionen auf europischer Ebene wrden hier gar nicht weiterhelfen. Jede Region in Europa trifft die fr sie und der Lage angemessenen Entscheidungen. Das gibt dann kein einheitliches Bild ab, aber der Virus tritt auch nicht berall einheitlich auf. Die einzige Ebene auf der ein Austausch wirklich erforderlich ist, ist die wissenschaftliche Ebene. Und da findet ein Austausch sehr wohl und sehr gut ber die WHO statt. Der Artikel ist nur papperlapapp. \\n',\n",
       " 'Ganz Belgien hatte einen Wert von 1750 ber 14 Tage. Wollten die Protestierer vielleicht den belgischen Rekord brechen?\\n',\n",
       " 'Ganz ehrlich als ich da war gestern, war nur etwas Stau in der Innenstadt, aber sonst freie Fahrt,,,,,, auf den Bergen fanden sich Menschen mit aus eigenem Interesse, Abstand und joar ansich sehr transparent , das Foto beweist doch nur geparkte Autos stehen ordentlich in der Reihe!! Und ein Auto ist unterwegs. Hut ab! Leute geniesst eure Freiheit!,,,,,\\n',\n",
       " '\"Der Anstieg der Sterblichkeit knnte mit der seit Oktober steigenden Zahl der Corona-Toten in Deutschland zusammenhngen.\" - Da war offensichtlich Sherlock Holmes am Werk.\\n',\n",
       " 'Es scheint so, als wrden durch das Virus allgemein viele Abgrnde oder unschne Eigenschaften ans Licht kommen, die bisher nicht auffielen. Nach der Krise wird man sich viele grundliegende Fragen stellen mssen.\\n',\n",
       " 'Die Anzahl der Tests in KW52 lag 1/3 geringer als in der Woche davor. In BW und Bayern haben wir am Mittwoch einen Feiertag. Erst danach werden alle Laborkapazitten wieder voll zur Verfgung.im Moment irgendwelche Entwicklungen aus den gemeldeten Zahlen abzulesen, ist wohl eher der Blick in eine Glaskugel aus Milchglas.  Kann mit allerdings schon vorstellen, dass Nebeneffekte wie Schulschlieungen und geringere Nutzung der ffentlichen Verkehrsmittel einen Einfluss haben.\\n',\n",
       " 'SPON: Die \"Industrie\" ist keine Branche sondern ein Sektor\\n',\n",
       " 'SPON: Die \"Industrie\" ist keine Branche sondern ein Sektor\\n',\n",
       " 'Wer oder was hindert Sder denn, in Bayern zu tun was er fr richtig hlt. Auerhalb Bayerns hat ihn jedenfalls keiner zum Mitbestimmer ernannt. (Gilt selbstverstndlich jeweils auch fr alle anderen MPs.)\\n',\n",
       " 'Herr Gassen wei aber auch nicht was er will, erst hat er im Oktober alles fr bertrieben erklrt und jetzt ist bei ihm sogar ein lockdown keine geeignete Massnahme. Was qualifiziert ihn eigentlich, sich die ganze Zeit zu der Sache zu uern? Er ist weder Virologe noch hat er Erfahrungen mit Pandemien. Evtl sollte man auch Mal aufhren ihm auch immer zu Wort kommen lassen. Dafr gibt es auerhalb von Telegramm Fachleute.\\n',\n",
       " 'Man knnte fast vermuten dass die ganze Veranstaltung ein vorgezogener Aprilscherz war. Wirklich ernst nehmen kann man die Ergebnisse der Ministerprsidenten Konferenzen nicht mehr wenn selbst die Teilnehmer 2 Tage danach noch immer nicht konkret erklren knnen, was sie da eigentlich beschlossen haben. Es ist hchste Zeit fr einen Wechsel in Berlin. Eine gute Idee wre, fr jeden Tag sinnlosen Lockdowns minus 1% im Wahlergebnis beider Regierungsparteien. \\n',\n",
       " 'Nicht nur dass der Impfstoff der effektivste und wirksamste ist, nein, er kann auch am besten gelagert werden.   Deutsche und Amerikaner. Wer sonst. \\n',\n",
       " 'Millionen von auslndischen Arbeitskrften sind nach den Feiertagen wieder eingereist. Da hie es: registrieren, 5 Tage Quarantne, dann Test. (also fr diejenigen, die sich dran gehalten haben, versteht sich)  wer testet, der findet. \\n',\n",
       " 'Alle reden nur von Vorteilen/Rckgabe der Grundrechte fr Geimpfte!  Wie wrs mal, wenn wir ber Lockerungen fr alle reden, jetzt wo die Durchimpfung der Risikogruppe in den nchsten Wochen abgeschlossen ist?\\n',\n",
       " 'In der medialen Darstellung sind die Neuinfektionen irrelevant (da Dunkelziffer vorhanden). Die wirklich wichtigen Zahlen sollten sein: von den 18.000 positiv Getesteten sind X in Behandlung, davon Y intensiv, die Auslastung der Betten ist Z. Und dazu einen Vergleich / Trend zur Vorwoche.\\n',\n",
       " 'Wenn sich der Einzelhandel nicht gegen die Aufhebung der Maskenpflicht wehrt, gibts halt die Sontagsbrtchen auch noch von Amazon. Spahn hat genug verbockt um ihn endlich abzusgen.\\n',\n",
       " 'Im Mrz/April wurde zumindest noch argumentiert, dass harte Manahmen auch wirtschaftlich besser seien, weil man so schneller zur Normalitt zurck kommen knnte. Diese These kann man inzwischen verwerfen. Was allerdings schon lange besttigt ist: Die positive Korrelation zwischen Wirtschaftskraft und Lebenserwartung . Zu glauben, dass ein wirtschaftlicher Einbruch nicht auch zu Todesopfern fhrt ist reichlich naiv. Allerdings sind die Zusammenhnge komplexer.\\n',\n",
       " 'Die Reaktion von Tschechien, keine Hilfe von Deutschland anzunehmen, ist tragisch und d.umm zugleich. Da geht man vor lauter Stolz offensichtlich ber Leichen.\\n',\n",
       " 'Ich wrde da den Biotech -Impfstoff vorziehen, als mich auf Daten einer womglich von Trump-Genossen  unterwanderten Zulassungsbehrde zu verlassen\\n',\n",
       " 'Auch wenn das RKI den Anteil der Geimpften an der Gesamtbevlkerung noch nicht angibt, ist es doch ziemlich leicht, dieses selbst zu ermitteln, da die Einwohnerzahlen sowohl fr ganz Deutschland als auch die Bundeslnder bekannt ist. Fr die Faulen: momentan (01.01.2021, Zahlen von 12:30 Uhr) hat Deutschland bei 83,166 Millionen Einwohnern eine Erst-Impfquote von bersichtlichen 0,199 %. Da ist noch Luft nach oben.\\n',\n",
       " 'Was wird passieren:  Ein guter Teil des Volkes hat bisher die Manahmen der Regierung akzeptiert und mitgetragen  Nur: Immer mehr stellt man fest, dass die Bundeslnder durch die Bank durch es in 7 Monaten Cororna nicht geschafft haben, irgendetwas substantiell zu ndern Nur der Status Quo vom Mrz wurde besser verwaltet  Frtschritte: Fehlanzeige Manahmen, die weiterbringen: Fehlanzeige oder im Streit der Landesfrsten steckengeblieben  Und was passiert jetzt: Nun droht man auch den Rckhalt des Volkes zu verlieren, denn das was nun vorgeschlagen wird, das reicht nicht aus, um fr die Zukunft zu planen, sondern es ist nur ein Spiel auf Zeit  Das agieren planloser und mutloser Landesfrsten, die die Gromutter evrscherbeln wrden , um die Macht zu erhalten  Zukunftsplanung ist was anderes\\n',\n",
       " '\"60 Prozent der Krankenhausflle bei komplett Geimpften\"  Und jetzt? Wir werden hier doch komplett v. a r. sch.t inzwischen!  Vielmehr scheinen die unterdrckten Studien und Warnungen recht zu haben, die sagen, dass es so nicht funktionieren und das Virus doppelt und dreifach zurckschlagen wird.\\n',\n",
       " 'Vllig unausgegoren, eigensinnig, unberlegt und einsichtsresistent! Die Regierung hat sich in eine Sackgasse manviert und findet mit ihren Mitteln nicht mehr heraus!\\n',\n",
       " 'Irgendwie hat man hier den Eindruck - die Masse der LockDowner - gehrt bereits der Risikogruppe an. Und befindet sich in Todesangst.  Das ist nur konditioniert, mchte man den Verzweifelten entgegen rufen. Die Chance an Krebs zu sterben ist rund 50 Mal hher.\\n',\n",
       " 'Super Idee, da kann Spahn wieder mal tchtig einkaufen. Babys sollten auch nicht vergessen werden.\\n',\n",
       " 'Diese malose Selbstberhhung ist Teil des Narrativs der sogenannten Querdenker. Da ist kein Vergleich zu peinlich. Sich unterdrckt und verfolgt zu fhlen, whrend man in aller ffentlichkeit unter den Augen der Polizei Reden schwingt, dazu gehrt schon ein gigantisches Ma an Realittsverweigerung. Dieses Gefhl der eigenen Unterdrckung und des Nicht-Teilhaben-Drfens am Wissen der Mchten ist wohl der Kitt, welcher Esoteriker, kos, Wutbrger und Neonazis in ihrem Ungeist miteinander verbindet. \\n',\n",
       " 'Fr seinen  Satz sollte Herr Scheele den Bundesverdienstorden bekommen.Solche Menschen braucht unser Land!\\n',\n",
       " '\"CDU-Politiker Rudolf Henke spricht sich fr schrittweise Lockerungen aus.\" Ich will einfach nicht begreifen, dass die klare Vorgabe, die von der Politik von Anfang gemacht wurde, immer noch diskutiert werden muss und unterschiedlich ausgelegt wird.  Wenn alle ein Impfangebot bekommen haben, fallen alle Einschrnkungen weg. Das war von Anfang klar. Vor allem das Maskentragen. So und nicht anders wird es gehen. Ob das Maskentragen fr mich eine Beeintrchtigung ist, entscheide ich noch immer selbst. Fr mich ist es ein schwerer Eingriff in meine Freiheitsrechte. Das mag jeder fr sich entscheiden. Maskentragen ist nach wie vor zu bestimmten Gelegenheit vom Ordnungsamt durchsetzbar und kann bei Zuwiderhandlung mit Bugeldern belegt werden. Das passt nicht mehr in unsere aktuelle Situation. Die Risikogruppen sind geimpft und wer sich bemht bekommt auch einen Impftermin. Es muss endlich Schluss sein, mit jeder Art von Bevormundung. Wir sind bereits jetzt in einer Situation, in der jeder selbst entscheiden kann, wie er mit dem Virus umgehen will. FFP2 Masken schtzen auch den Trger. Die kann jeder der mchte weiter tragen und wer nicht mehr will, der soll sie endlich selbst bestimmt ablegen knnen.\\n',\n",
       " 'Wir sollten aber diejenigen Manahmen zurcknehmen, die ganz offensichtlich keine Schutzwirkung entfalten. Revolutionrer Ansatz, die Manahmen sollen auf Effektivitt berprft werden. Dann mal los, da geht noch einiges.  Und beim nchsten Mal vielleicht vorher berlegen? Ist ja nicht unser erster Lockdown. \\n',\n",
       " 'Leider trifft es bei pauschaler Kritik immer auch die Falschen. Fakt ist: Das System hat vollkommen versagt; von oben bis unten. Lassen wir die wenigen engagierten Schulen und Lehrer/innen mal auen vor. In meinem Bekanntenkreis gibt es niemanden, der auch nur etwas Positives erkennen kann; Ausnahmen wie vor. In der Privatwirtschaft htte es keine Hilfen gegeben, weil das System schon vor dem Lockdown insolvent war. Und die Mitarbeiter? Ein Drittel war krank und die anderen beim Brckentag. Es macht mich wtend, weil ich gegen Privatschulen bin, gegen Ungleichbehandlung und fr mehr Anerkennung der Arbeit der Lehrer/innen. Das System und die handelnden Akteure haben sich selbst ausgeknockt. \\n',\n",
       " '\"Die Herausforderung ist, dass auf der ganzen Welt alle Lnder Schutzausrstung suchen, bestellen und sich gegenseitig auch weg kaufen. Wir mssen uns auf eine Knappheit einstellen.\"  Genau deshalb haette es sich empfohlen, das bereits vor vier Wochen zu tun. Das naemlich meint man mit VORbereitung. Seit mindestens zwei Monaten weiss man um den Ernst der Lage. In dieser Zeit haette man schon laengst automatische Waermekameras an Flughaefen installieren koennen, sich mit Schutzausruestung eindecken, die Absage von Grossveranstaltungen pruefen, den internationalen Reiseverkehr einschraenken. Man haette auch damals schon die Pandemieplaene aktualisieren koennen. Was haette es geschadet? Selbst wenn man von der Seuche verschont worden waere, waere man auf ein zukuenftiges Ereignis im Sinne einer Uebung besser vorbereitet gewesen. JETZT muesste man in allen Krankenhaeusern nicht notwendige Operationen verschieben, und nicht zu kranke Leute nach Hause schicken. JETZT muesste man in Altenheimen den Zugang einschraenken. JETZT muessten Hausaerzte ihre chronisch kranken Patienten mit Medikamenten fuer drei Monate eindecken. Aber nichts von alledem ist geschehen oder geschieht. Man tut einfach...NICHTS. Es ist absurd.\\n',\n",
       " 'Hrt sich an wie eine Auftragsstudie des Herrn Laschet, die seine Vorgehensweise sttzen soll.\\n',\n",
       " 'Herr Spahn whlt Formulierungen als wre er Aussenstehender. Der Typ ist nicht ganz dicht - meine Meinung.\\n',\n",
       " 'Auf die durchaus naheliegende Idee, dass die Zunahme nachgewiesener Infektionen (oder vielmehr Virenbestandteile) etwas mit der drastischen Erhhung der Tests (inzwischen sogar privat mglich) zu tun haben knnte, kommt man medial offenbar nicht.\\n',\n",
       " 'Dass es den britischen Gesundheitsminister trifft scheint im gewissermaen multivalenten Sinn \"kein Zufall\"... Es ist bekannt, dass die Wirksamkeit gegen den leichten Verlauf 64 Prozent betrgt. Das heit doch, ca. 4 von 10 Personen, die ohne Impfung den leichten bekommen htten, bekommen ihn auch danach - nicht richtig? Und wird brigens der quizzige mittlere Verlauf zum ganz schwachen ge-kirkt, meistens?\\n',\n",
       " 'Kommt der von Trump befohlene gewaltige  Aufschwung auch in Deutschland???           Ja-----weil die groe Mehrheit keine Einkommenseinbussen haben, aber monatelang weniger Mglichkeiten zu Geldausgeben.                                                      Weil viel echter Bedarf oder shoping-Lust.       zu einem Sturm auf die Lden fhrt.              Weil enorm Staatskohle reingebuttert wird.             NEIN-----weil sehr viele gewaltige Einkommenseinbussen haben.                        Weil sehr viele aus Zukunftsangst ihre Kohle zusammenhalten.                                               Weil sehr viele aus medizinischen Grnden eher selten shoppen gehen, und die blde Maske ne echte Spabremse ist.                    Ich denke, dass die negativen Faktoren berwiegen....   \\n',\n",
       " 'Wenn man bedenkt, das mit einem Schnelltest so ziemlich alles gemacht werden darf. Habe mir mal so ein Ding auf meinem Handy genauer angeschaut. So einfach das Datum zu ndern, selbst das Negativ Ergebnis ist ohne groe Kenntnise zu ndern ( also wenn man positiv wre) Das heit, wenn man nur ein wenig Aufwand betreibt, ohne groe Gefahr erwischt zu werden, braucht man keine Test mehr zu machen. Wieviel das wohl machen ? Bin mal gespannt wie das mit den Impfpssen weiter luft\\n',\n",
       " 'Was nutz es, wenn wir jeden Tag neue Gruppen definieren, die bitte schn als Erste geimpft werden sollen/mssen? Garnichts - solange kein Impfstoff vorhanden ist\\n',\n",
       " 'War nicht vorher die Rede von einer historischen Debatte der MP, also mit diesen Ergebnissen haben diese das Jalta Abkommen komplett in Vergessenheit gebracht. \\n',\n",
       " 'Zitat RKI< Wir wssten nicht, ob es der Beginn einer zweiten Welle sei, aber er knnte es sein. >  Mit dem was das RKI nicht wei liesen sich ganze Bibliotheken fllen.   Unvorbereitet in eine Pandemie gestolpert, planlose Aussagen zu Masken, keine Konzepte, keine Medikamente, das RKI ist ein total Ausfall. \\n',\n",
       " 'Dsseldorf ist wegen seiner 120 prozentigen Anglopalaberie bei Britischen Besfnistouristen sehr beliebt gewesen, aber der Zusammenhang scheint abwegig...\\n',\n",
       " 'In unserer Stadt gibt es gerade das Advents-Gratisparken in allen stdtischen Parkhusern, um dem Einzelhandel zu helfen. Die Grnen beschweren sich nun darber, weil das ein Schlag ins Gesicht der zahlenden PNV-Nutzer sei.  Ich habe in Anbetracht der ganzjhrig samstags vollen Parkhuser und Parkpltze Bedenken, ob berhaupt so viele Leute aus dem Umland per PNV zum Shoppen in die Stadt kommen.   Wenn sich die Grnen am Gratisparken stren, sollen sie halt die PNV-Tickets im Advent kostenlos machen... ;-)\\n',\n",
       " 'Also wenn man sich die Breite des NASDAQ und die Marktkapitalisierung der darin liegenden Firmen anschaut, dann steht die USA im Vergleich zum DAX nicht schlechter da. Selbst wenn Delivery Hero also die Nummer 30 der deutschen Firmengren im DAX auftauchen sollte, kann der NASDAQ dem noch etwas entgegen setzen. Auch europaweit. Und wenn die Infektionswelle in den USA vorbei ist, steht sie Europa noch bevor. Falls man wirklich Europa/USA vergleichen mchte, was auch immer das fr einen Sinn frs persnliche Ego macht, den relativ pauschalen Titel \"Euopa macht es besser\" wrde ich so gesehen in einem halben Jahr nochmal getstet sehen wollen.\\n',\n",
       " 'Das htte doch schon lange gemacht werden mssen. So kann es nicht gehen. Auf der einen Seite alles zu und von der anderen Seite alles offen. Typischer Irrsinn von den Spezialisten.\\n',\n",
       " 'Also ich bin fr einen harten lockdown und schnell tests fr jeden. Weil sich ja eh die meisten bicht an die regeln halten \\n',\n",
       " 'Es ist ein Unding dass im Gesundheitswesen (nicht nur bei Coronatests) die Dienstleister:innen ohne jegliche Kontrolle mit den Kassen und staatlichen Stellen abrechnen. Kontrolle wre so einfach; die Patienten mssen die erbrachten Leistungen unterschreiben. Warum gibt es das nicht?\\n',\n",
       " 'Pandemie ist ein weltweites Problem, da sollten sich Vertreter aller Kontinente an einen Tisch setzen und nach Strategien und Lsungen suchen. Wenn es um wirtschaftliche Vorteile geht, haben es die Akteure auch geschafft die Globalisierung aus der Taufe zu heben, geht es aber um humanitre Aufgaben - Fehlanzeige. Da herrscht dann eine Ellenbogen-Mentalitt.  Das ist immerwieder ernchternd und traurig. Eine weltweit verbreitetes Virus macht keinen Unterschied, ob es einen armen oder reichen Menschen ansteckt.\\n',\n",
       " 'Der ehemalige Bundesverkehrtminister Dobrindt bietet eine CSU- Variante des Nationalismus an und macht damit klar, dass er den Sinn der Europischen Union immer noch nicht verstanden hat. Der Meister soll sich um den bayerischen Landkreis mit der hchsten Inzidenzzahl in Deutschland kmmern!!\\n',\n",
       " 'Die Meldung kommt etwas spt. Im Forum der Onlineausgabe eines Blattes aus dem Hause Springer wird das Thema schon seit 14 Stunden diskutiert. Zur Sache: Wer nach Verstaatlichung von CureVac ruft, sollte zunchst einen Blick ins Grundgesetz werfen. Das lsst Verstaatlichungen nur gegen Entschdigung zu und ber die Hhe der Entschdigung entscheiden die Zivilgerichte. Wenn die Entwicklung des Impfstoffs gegen Covid-19 gelingt, dann drfte der Wert von CureVac durch die Decke gehen. Dennoch sollte es Mglichkeiten geben, zu verhindern, dass sich die USA den Impfstoff exklusiv unter den Nagel reien, zumal das bundeseigene Paul-Ehrlich-Institut, das zum Geschftsbereich des Bundesministeriums fr Gesundheit gehrt, an der Entwicklung des Impfstoffs beteiligt sein soll. Vor allem sollte man seitens der Bundesregierung die Sache publik machen und den Konflikt mit den USA offen austragen. Schlielich lsst Mr. Trump keine Gelegenheit aus, der EU und Deutschland ffentlich ans Bein zu pinkeln.  \\n',\n",
       " 'Jetzt ist es erst mal wichtig, die pandemische Notlage und das 4. Bevlkerungsschutzgesetz zu verlngern. Am besten gleich bis zum Herbst, damit man immer schnell reagieren kann.  Dann knnen wir wenigstens in aller Ruhe auf neue Mutationen warten und sie analysieren und sind immer geschtzt. Auch die Einreiseblockade gegen UK muss verlngert werden. Vielleicht stimmt das dann doch nicht so, dass unsere Impfungen helfen, man wei ja nie.  Und mit den Lockerungen sollten wir wirklich noch 1-2 Monate warten. Das kann nach sieben Monaten ja nicht mehr zu viel verlangt sein. Wir drfen das Erreichte um keinen Preis verspielen.\\n',\n",
       " 'Die Restriktionen gelten wohl eher den tausenden Demonstranten, die am WE in London auf der Strae waren, denn anders als mit Bestrafung bekommt man sie nie gebndigt. So glaubt man zumindest. Nicht nur in GB, sondern in ganz Europa rumort es krftig auf den Straen. Aber darber berichten die gleichgeschalteten Medioten nicht, sondern verlieren sich lieber weiter angstvoll emsig in den Zahlenspekulationen des RKI. Zumindest solange bis die Kartenhuser einstrzen.\\n',\n",
       " 'Schulen, Restaurants, ffis, Geschfte, Bros, Werksttten... Es gibt kein Patentrezept auer dem eigenen Verhalten. Die Vorsicht und Achtsamkeit - also die Distanz zueinander - hat die erste Welle bereits gebrochen, bevor die Manahmen im Mrz und April starteten. hnlich sieht es jetzt aus... Wir sollten weniger auf die Politik warten (und dann jammern), sondern selbstverantwortlich Abstand halten - auch MIT Maske! \\n',\n",
       " 'Das ist das bliche Spiel mit absoluten Zahlen - die natrlich drastisch aussehen - oGottoGottoGott ber eine Million - und relativen Zahlen: 1Mio von 330 Mio Einwohnern sind: 0,3%, d.h. aktuell als infiziert nachgewiesen sind 0,3% der Bevlkerung der USA. Das soll nicht die Bedeutung des Sachverhalts herunterspielen - auf jeden Fall MUSS die Intensitt der Infektion durch Corona Viren gewrdigt und entsprechend agiert werden. Wichtig ist nur den Sachverhalt korrekt darzustellen.\\n',\n",
       " 'Die Todesrate... Die Intensivkapazitten.... Die Zahl der Neuinfektionen pro 100.000 Einwohner...  Der R-Wert... Die Verdopplungszeit ... die absolute Anzahl der Infizierten ....  Willkommen beim lustigen Referenzroulette. \\n',\n",
       " 'Wer jetzt zur Vorsicht aufruft, will ja grade nicht, dass es zu Manahmen wie hin zu Lockdowns kommt. Wir sind ja alle bald geimpft. Lasst uns bis dahin doch ein einziges Mal klug sein, und die Freiheiten, die wir im Vergleich zu sonst grade in recht hohem Ma haben, weitgehend bewahren, statt wieder in so stressige Lockdownsituationen zu kommen, wo man wieder nicht in die Auengastro kann.\\n',\n",
       " '--   , Ist also noch ein sehr langer Weg bis wir bundesweit unter 20 und landesweit unter 35 sind. Auch ist die Positivrate weiterhin viel zu hoch, bei unter 3% haben wir die Lage wieder unter Kontrolle. Noch kontrolliert die Pandemie uns.\\n',\n",
       " 'Schn und gut was die WHO rt, allerdings sollte dann auch flchendeckend getestet werden, was allerdings auch wieder nicht mglich ist. \\n',\n",
       " ' Es geht also unter Biden genauso weiter wie bei Trump   Hier sind einige Floristen unterwegs, warum auch immer, jedoch recht einfach China an den Pranger stellen. Zeitschiene sagt aber etwas anderes, die ersten sichtbaren Lungenerkrankungen Traten 2018 in die USA. Von dort sind sie nach Italien und Frankreich gewandert. 2019 war die Militr der USA in Wuhan\\n',\n",
       " 'Europa hat 2 Monate wirklich nichts getan, um das Risiko zu erkranken sinnvoll zu minimieren. Jetzt mu es fr seine Politiker halt auch den Preis zahlen. Vielleicht wird es in ein paar Jahren auch wieder besser. Erst mssen wir mal durch die Krise durch, einige Millionen knnten sterben, aber viele Politiker sind ja auch ber 30.\\n',\n",
       " \"Ich halte es fr extrem fahrlssig, die Kontaktnachverfolgung bei jngeren Menschen aufzugeben und sich dabei auf die 'Risikogruppen' zu konzentrieren.  Beipiel: 20-Jhriger feiert mit 20 Freunden beiderlei Geschlechts. 15 sind danach infiziert, aber keiner lsst sich testen (aus welchen Grnden auch immer). Zehn fahren am Wochenende zu den Eltern und stecken jeweils ein Elternteil an. Die haben aber keine Ahnung davon. Also 10 weitere Infizierte, die in der kommenden Woche weitere ggfs. ungeschtzte Kontakte haben - Freunde, Kollegen, die Groeltern der Studenten. Und schwupps ist ein Pflegeheim betroffen.   Es schlagen ja manche vor, bei jngeren Infizierten die Kontaktverfolgung aufzugeben und nennen das 'neue Strategie'. Ich rechne die, die das vorschlagen zu den 'Durchseuchungsbefrworten', die sich nur vorgeblich um den Schutz von Risikogruppen bemhen.\\n\",\n",
       " 'Es ist fr mich nicht nachvollziehbar, dass es immer noch Politiker gibt, die mit dem \"Weichsplprogramm\" Erfolge erzielen wollen. Welche persnlichen Ziele wollen sie damit ereichen? Dem Wohl von Brgern und Wirtschaft ist damit nicht gedient. Mehr Infizierte und Sterbende, mehr Verluste in der Wirtschaft, weil dadurch die Corona Krise verlngert wird und viele Kleinunternehmen es nicht mehr schaffen. Das die zugesagten Hilfen nicht ankommen ist bekannt, wird auf die Software der mter geschoben. Einfach mal Brokratie beiseite legen, einfach mal wirklich etwas fr den Staat, fr die Brger und die vielen Kleinunternehmen tun. Diesen unbrokratischen Willen zur Lsung sehe ich nirgendwo!\\n',\n",
       " 'Die Unverletzlichkeit der Wohnung ist auch ohne Durchsetzung der entsprechenden Paragraphen des Infektionsschutzgesetzrs ein ziemlich lcheriges Grundrecht.  Wer das nicht glaubt, kann ja mal versuchen dem Schornsteinfeger abzuweisen, nur weil der keine gerichtliche Anordnung dabei hat. Zahllose mter haben de jure Zugang zu Privatwohnungen.  Ganz arg ist es, wenn man ganz unten angekommen ist. Gerichtsvollzieher, Mitarbeiter des Jobcenters, des Sozialamts , des Wohnungsamts etc haben jederzeit Zutritt und drfen sich auch mittels Einblick in Schrnke etc. einen berblick ber Wohnungsbelegung oder Vermgenswerte beschaffen.  Coronakontrollen wren bezglich Unverletzlichkeit der Wohnung nur noch ein weiteres Loch im Sieb gewesen. \\n',\n",
       " 'Das ist in Deutschland jetzt nur noch Theater. Frankreich ist da schon weiter. Deutschland will weiter mit dem Kopf durch die Wand. Unsere Regierung(en) sollten sich darber im klaren sein, dass  wir zwar geduldiger und  folgsamer, als die Franzosen sind aber auch Grenzen haben. Alles auf dieses Inzidenzzahlen abzustellen, ist doch Quatsch. Wer sind die Toten? Wo sind die Toten?  Ich kenne persnlich keinen bisher, der dran gestorben ist. Die, von denen ich gehrt habe, waren alle an der Altersgrenze. So wot?\\n',\n",
       " 'Prognose: 60-70 % der Deutschen werden sich anstecken. Bei der Mehrheit wird es als Erkltung vorberziehen. Bleibt noch die Risikogruppe, fr die es nicht so rosig aussieht. Die Leute hamstern gerade Nudeln und Klopapier. Gemse- und Obstregale sind weniger frequentiert. Wobei das einzig sinnvolle gerade wre, das Immunsystem zu strken (sofern man es aus medizinischer Sicht kann). Ich stehe vllig hinter allen Manahmen, die gerade getroffen werden, um die Risikogruppen zu schtzen. Aber gerade kam der Kommentar auf ZDF, dass die Einnahme von Vitamin D3 nichts bringt. Ernsthaft? \\n',\n",
       " 'Dann geht der Hamster fr mich arbeiten und einkaufen:) \\n',\n",
       " 'Da mal wieder jemand den absolut nicht relativierenden UK-Impglory -Kommentar hierher kopiert hat: MEINE Geschftsfreunde im UK bibbern vor Sorge ob der Brexitfolgen. Und sie kalkulieren bereits eine baldige Verschrfung dieser Folgen aufgrund des solidarischen Verhaltens des UK hinsichtlich der Impfstoffexporte ein. Was nun?\\n',\n",
       " 'Die Bundeswehr zur Untersttzung wollten die ja nicht. Jetzt fngt das Gejammer an. War ja gar nicht absehbar...wer RRG whlt, whlt seinen eigenen Untergang, aber damit hat Deutschland und insbesondere Berlin ja Erfahrung\\n',\n",
       " '\"Daher wnsche er sich, dass der Frhling warm und frhzeitig beginne.\"  Ei  gucke da! Wer htte je so einen Satz in Zeiten des Klimawandels erwartet. :-) Es fragt sich nur, ob das Wetter wirklich so einen Einfluss hat. In Sdafrika und Brasilien steigen und steigen die Zahlen und dort ist jetzt Sommer.\\n',\n",
       " 'Wir sehen hier in Echtzeit ein Versagen des Frderalismus. Traurig, aber wahr. Die Bereichtschaft zum treffen von unpopulren, jedoch notwendigen Entscheidungen ist leider bei vielen Landeschefs nicht vorhanden.\\n',\n",
       " 'Einen Monat noch, dann sollten verwertbare Ergebnisse aus den Phase 3 Studien vorliegen und wir wissen in welche Richtung es geht. Drcken wir die Daumen.\\n',\n",
       " 'Diese konomen. Anstatt nichts zu sagen. Wie immer stimmen diese Kaffeesatzlesereien sowieso nicht. Warum gehen diese konomen nicht auf den Jahrmarkt zur Hellseherin. Die hat eine dicke Glaskugel. \\n',\n",
       " 'die uni der bundeswehr hat im sommer eine umfangeiche studie dazu gemacht und hat auch eines der gerte klar empfohlen ... das umweltbundesamt hat es besttigt\\n',\n",
       " 'Der Streit spitzt sich zu. Ein Trke droht mit einer Reise nach Berlin! :-)\\n',\n",
       " 'Das ist schon Kunst die kommenden Schritte als Lockerungen zu verkaufen, obwohl es eigentlich keine sind.\\n',\n",
       " 'Ohne Rcksicht auf die Alten und die Pflegekrfte beiden htte ich gegngelt. Allerdings den Pflegekrften fr die Zeit das 3 fache bezahlt. Fr die Alten wre das keine Vernderung zu der jetzigen Situation, fr den Rest schon..... \\n',\n",
       " 'Ist Indien eigentlich im Totallockdown, da deren Inzidenz bei 7 liegt oder wie machen die das?\\n',\n",
       " 'Freie Fahrt fr freie Brger - Die Richter urteilten im Sinne Kohls.\\n',\n",
       " 'Demnchst muss die Bundesregierung dann wohl auch eine Reisewarnung fr einige Regionen des eigenen Landes aussprechen. Die Zahl der Neuinfektionen steigt weiter an, es ist kein Ende in Sicht.\\n',\n",
       " 'Sders Dauer-Alarmismus nutzt sich ab. Viele Brger sind es leid, dass politische Vorgaben (wie z.B. die Empfehlung zu Urlaub innerhalb Deutschlands) nur noch eine Halbwertszeit von wenigen Tagen oder maximal Wochen haben, gefhlt fast tglich von ihm und anderen eine neue Verbots-Sau durchs Dorf gejagt wird, inzwischen an jedem Briefkasten andere Regeln gelten und keiner mehr durchsieht. Mit der Forderung nach Einheitlichkeit hat Sder recht. Aber untrennbar damit verbunden sein mssen Einfachheit, Klarheit, Nachvollziehbarkeit und Konsistenz! Bei Maskenzwang auf offenen Straen, temporren oder lokalen Alkoholverboten, Sperrstunden oder Beherbergungsverboten ist das alles nicht erkennbar!\\n',\n",
       " 'Das htte vielleicht am Anfang geholfen. Aber bezglich Grenzkontrolle scheinen von ihren \"Erfolgen\" bei der Flchtlingskrise abgeschaut zu haben. Sprich wir kontrollieren erst, wenn der Virus schon zehntausende Menschen angesteckt hat.\\n',\n",
       " 'Immerhin scheint das Impfen Fortschritte zu machen. Jetzt wre eine bersicht ber die bereits gelieferten und die in den nchsten Wochen erwarteten Impfdosen hilfreich. Dann liesse sich abschtzen wie es weiter geht. Dabei erwarte ich nicht, dass alle Produktions und Nutzungserweiterungen vllig reibungslos funktionieren aber die Zulassung von Marburg, die absehbare Zulassung des Asta Zeneca Impfstoffe Ende Januar und das leichtere Handling stimmen zuversichtlich. Wichtig wre jetzt, dass sich die Lnder auf ein en best prchtige Prozess verstndigen und den umsetzen. Die massiven Differenzen zwischen den Bundeslndern sind nicht nur unverstndlich sondern kosten Menschenleben \\n',\n",
       " 'Aus dem Jahr 2015 gibt es Zahlen zu Verstorbenen in Krankenhusern an Infektionen mit multiresistenten Keimen. Deutschland ca. 2400, Italien gut 10.000. Unabhngig von Covid 19 luft in Italien etwas unglaublich schief.\\n',\n",
       " 'Kitas und Schule ffnen, je frher je besser. Dann sind in wenigen Wochen alle Kinder und Jugendlichen immunisiert und knnen dann wieder zu ihren Groeltern. Bis dahin natrlich, wie jetzt auch, Kontakt zu Risikogruppen meiden.  Bin eigentlich kein Laschet-Freund, aber fr mich momentan der einzige Politiker, der die Lage im gesamten betrachtet und vernnftige Lsungen bietet. Ein lngerer Lock-down hat keinen Mehrwert, die Krankenhuser sind vorbereitet, also worauf noch warten? Doch wohl kaum auf den Impfstoff.\\n',\n",
       " 'Lockdown verlaengern - OK. Dann aber auch konsequent ueberwachen und nicht bei jeder Demo deeskalierend zuschauen. Dann haben wir den Lockdiwn noch 12 Monate \\n',\n",
       " 'Warum sagt uns eigentlich niemand was vor den Verhandlungen die Wissenschaft gesagt hat. Oder ist es nur wichtig was die einzelnen Landesfrsten wollen. Es sollte durchweg nur das gemacht werden was die Fachleute sagen. Auerdem hat die ffentlichkeit ein Anrecht auf Information. \\n',\n",
       " 'Ich kann in den Filmchen keine Konstruktive Kritik finden! Oder ging es nur um Provokation und Knalleffekt?\\n',\n",
       " 'Man  stelle sich nur mal vor, alle Deutschen wren Querlenker - was wre in diesem Land jetzt los ...\\n',\n",
       " 'In einer dieser Maschinen vom DXB sitze ich morgen, mit allen Papieren sauber in der Tasche.  Negativer Covid-Test von gestern ( gestern abend 23 Uhr Probennahme, 8:34 Uhr heute morgen das Negativ-Resultat-Zertifikat bekommen), sauber die Einreiseanmeldung gemacht und Besttigung ausgedruckt. Emirates sollte eigentlich niemanden in den Flieger lassen, der kein Negativ-Zertifikat hat. Heute morgen habe ich eine SMS bekommen, dass man das Negativ-Resultat zum Check-In mitbringen muss.  Ich war 2 Monate hier (Familie + Doktorbesuche hier, in DE ging ja gar nichts terminmssig,  selbst fr chronisch Kranke, grausam... bin also aus hauptschlich aus Familiengrnden hier, meine Frau arbeitet hier)  Wer morgen ohne Negativ-Test am Gate in DXB angewiesen wird, hat es nicht anders verdient, sorry. Mir ist auch sehr daran gelegen, nicht mit ungetesteten Petrischalen 7 Std in einem Flieger zu sitzen. Als ob es zuviel verlangt wre,  kurz bei den dutzenden Doktoren hier einen Test 48std vor Abflug zu nehmen... hier konnte man sogar fr 55 Euro einen Test direkt an seiner Wohnadresse (egal wo) machen lassen, die Test-teams waren jederzeit verfgbar. Direkt in einem der Testzentren wre es 30 Euro gewesen, mit 24std Resultat Garantie.  Ich seh das Problem also wirklich nicht. Dass man 10 Tage in Quarantne muss wenn man zurck kommt, das wusste man schon vorher, schon seit November war das bekannt. Also, auch easy. Wer morgen in Trouble kommt, der hat es nicht anders verdient, sorry. \\n',\n",
       " 'Das Gefhl es ist jetzt gnstiger spielt eine viel wichtigere Rolle als das wieviel es gnstiger ist. Ein Feuer frei Signal fr alle, die viel Geld gespart haben, weil sie nicht ins Restaurant, ins Kino, in den Biergarten, ins Theater, usw. gehen konnten. Die Zielgruppe, die sich ber 20 gespartes Geld im Monat freut, kurbelt die Wirtschaft wohl kaum an. Das Ziel ist, die Konsumstimmung derer zu heben, die auch konsumieren knnen. \\n',\n",
       " 'Der zweite Mann im Staat (Pence) ist Anhnger des\\xa0Prosperity Gospelund somit der Auffassung, dass entsprechend der Vorstellungen zur\\xa0Prdestination\\xa0Gottes materieller Reichtum und persnlicher Erfolg (oder aber Misserfolg) ein Beweis fr die Gunst (oder Ungunst) Gottes seien, eine bei Anhngern fundamentalistischer Freikirchen verbreitete Ansicht. (Quelle Wikipedia)  Damit ist wohl klar, was die Herren im weien Haus ber die Armensiedlungen denken.\\n',\n",
       " 'Es muss einfach geimpft werden.....alles andere macht keinen Sinn!!!  Lockdown ist eine begrenzte Lsung.....wenn ich 6 Wochen auf Schokolade verzichte; hau ich mir danach umso mehr rein und danach gehen die Pfunde wieder hoch \\n',\n",
       " 'Es ist gekommen wie ich es geahnt habe, das Thema ist durch. Keiner der Experten redet mehr von Corona, aktuell ist es natrlich das Unwetter und danach wird Klima allgemein das bestimmende Wahlkampfthema werden. Wenn man die tglichen Medien verfolgt, kann man schon erkennen, wie die Prioritt ganz bewusst verschoben wird.\\n',\n",
       " \"Mir fllt auf, dass hier kaum ber die 'Sparsamen Vier' diskutiert wird. Ausgerechnet sterreich, ohne deren besinnungsloses Apres-Ski Feiern in Ischgl wir gar nicht in der Misere stecken wrden, weigert sich zu helfen. Und Schweden, die bislang ungefhr alles falsch gemacht haben in der Bekmpfung von Corona.   \\n\",\n",
       " 'Vielen Dank Herr Sder, fr Ihr umsichtiges Handeln! Corona ist -  wenns inzwischen auch jede Menge Verharmloser gibt - ein gefhrliches Virus, obs uns nun gefllt oder nicht. Ein wie es vorher mal war, wird es nicht mehr geben.\\n',\n",
       " 'Sport, Leute, Ostern soll es regnen. Regenschirme sind leider gerade aus, rausgehen ohne Schutz wre unverantwortlich: Wir brauchen Ausgangssperren! (Vor einem Jahr hat man in einer hnlichen Situation Corona-Behandlungszentren gebaut und Reserve-Intentensivbetten eingerichtet. Und den Einzelhandel geffnet. Ohne Tests ohne Impfungen. Und mit der Folge, dass die Inzidenzen gesunken sind. Weil sich die Menschen drinnen anstecken und nicht draussen.)\\n',\n",
       " 'Die CDU koennte auf ein Online-Format umstellen - wie viele Schulen, Unternehmen und Universitaeten es tun. Allerdings gaebe es dann keinen Grund mehr, die Entscheidung auf 1001 Delegierte zu beschraenken...\\n',\n",
       " 'schne Arbeit der CDU, verhindert seit Jahren eine Reform in diesem Sektor. und sollte durch diesen Hotspot in der Umgebung neue Infektionen aufpoppen sollte der trge Laschet langsam einpacken.  ich denke in der Gegend sind die Brger leicht angespannt.\\n',\n",
       " 'Was fr eine Geschichte! Folgt eine Fortsetzung? Oder ein Buch? \"Babylon Berlin - der Tanz auf dem Vulkan\".\\n',\n",
       " 'Habe so das Gefhl, als wenn man in Mnchen wie eine Maus vor einer Schlange sitzt. Die Zahlen werden grer, aber man tut nichts, weil wenn man die Augen zumacht es verschwindet. Wann will man einschreiten? Wenn die Zahlen ber 100 sind? 1000?\\n',\n",
       " 'Wie soll das Abstandhalten nach Bordell-Hygienekonzept funktionieren? Vielleicht kann das jemand erklren...\\n',\n",
       " 'Was interessiert mich in dem Zusammenhang Friedrich Merz? Will man uns damit sagen, der ist zwar infiziert, lebt aber noch?\\n',\n",
       " 'Hier wird wieder der Sozialismus herbei gewnscht. Weil die Notenpresse und klassische Verteilmechanismen (wie Kurzarbeitergeld) angeblich nicht ausreichen, soll jetzt das Geld pauschal pro Nase verteilt werden. Das fhrt vor allem dazu, dass die Geldmenge weiter erhht wird und Sparer noch strker enteignet werden. Auch die Aktienkurse wrden noch weiter steigen und Konzerne noch reicher werden. Italien und Spanien haben strukturelle Probleme, weil sie schon vor Corona ber ihre Verhltnisse gelebt haben.\\n',\n",
       " 'Dieses Scheinfaktengeschwurbel der Coronaverherrlicher hier im Forum um die Lockdowns zu rechtfertigen und diese als notwendig und Alternativlos darzustellen ist kaum mehr zu ertragen. Der Realittsverlust verursacht durch die Politik und die Leitmedien ist leider irreversibel.\\n',\n",
       " 'Steuersenkungen nach der Krise sind sehr sinnvoll. Einmalzahlungen an Krankenhausmitarbeiterung, okay zur Motivation, aber unwichtig weil eher Selbststndige und Mitarbeiter anderer kleiner Unternehmen nach Entlassungen in Not sind. Nicht entlassene Mitarbeiter haben noch nie so wenig Geld ausgegeben wie jetzt und knnten eher fr die an der Front etwas abgeben. Aber groes Geschrei: natrlich nicht durchsetzbar, weil, ja weil wir Menschen sind, die alles brauchen.  Sder hat endlich eine pragmatische gute Idee, die sinnvoller ist als Billionen in europische Fsser ohne Bden zu schtten. \\n',\n",
       " 'Und ich werde angeraunzt wenn ich etwas mehr Abstand will beim Einkauf. ... War an der Flaschenrckgabe.\\n',\n",
       " 'Im Grund hat man doch Angst davor, das fr die zweite Impfung nicht genug Impfstoff da ist weil man keine Rckstellungen bilden will. Ist zumindest mein Eindruck. \\n',\n",
       " 'Ja, ist echt Schade dass die FDP keine Mglichkeit zur Regierungsbeteiligung hatte. Was htten sie nicht alles besser machen knnen... Oder war es doch so, dass sie drauf verzichtet haben um gute Ratschlge ohne Verantwortung geben zu knnen? Ich erinnere mich grad so schlecht... \\n',\n",
       " 'Ob die App funktioniert spielt doch sowieso keine Rolle. Bringt es was, wenn ich eine Meldung bekomme, dass ich mich zu lange in der Nhe eines der aktuell 0,025% falsch positiv getesteten aufgehalten habe. Ich muss statistisch gesehen ber 3000 Menschen treffen, damit dies der Fall ist. \\n',\n",
       " 'Das Kartenhaus der naiven Einfalt reprsentiert von Merkel und Sder wird in dieser Woche umfallen. Merkel mag wieder weinerlich mit falschen Zahlen argumentieren, Sder mag weiter fr die Kfighaltung der Brger eintreten - der Rest der Republik wird lieber auf Vernunft setzen und einen Ausgleich aller Interessen suchen. Die bedingungslose Hysterie ist endlich vorbei.\\n',\n",
       " 'Die Pandemie wtet weltweit und von Tag zu Tag finde ich viele Kommentare  erschreckender. Hallo!? Es gibt noch 194 weitere Staaten und alle wollen einen Impfstoff gegen dieses ver.damm.te Virus. Wir sollten froh und dankbar sein, dass es berhaupt schon Impfstoffe gibt. Das htte durchaus noch sehr viel lnger dauern knnen. \\n',\n",
       " 'Gut das wir nach fast genau beginnen, Experten zu nutzen und qualifizierte Plne zu entwerfen. Schade das es sich lediglich um einen Vorschlag handelt\\n',\n",
       " 'Facebook, Twitter und all die anderen (a)sozialen Medien liessen nicht nur alle Trumpluegen 4 Jahre lang ungefiltert zu, nein, sie verstaerkten sie durch ihre Algorithmen, welche Gleichgesinnte zusammen fuehren.   Sie sind die Architekten der Echokammern, in denen sich die Trumpleute, ausserhalb der realen Welt, treffen und austauschen.   Nun stehen sie wie die Zauberlehrlinge da, denen die Besen entglltten. Zu spaet! Allfaellige Werbeverbote fuer Waffenbestandteile helfen auch nicht weiter. mfG Beat Adler\\n',\n",
       " 'Ideale Grundposition fr einen typischen GroKo-Kompromiss: die Leute sollen ihre Raketen und Bller kaufen, drfen sie aber nicht benutzen. :)\\n',\n",
       " 'Da es sich um eine einmalige Sache handelt kann man die paar Euros gerne mal zahlen. Das sind Peanuts. Wenn man das Geld spter unbedingt einsparen will kann man gerne mal im Etat der Bundeswehr nachsehen. Da wird genug Geld sinnlos verpulvert. \\n',\n",
       " 'Das ist halt alles was er kann. Warnen, mahnen und bergriffig sein.  Fhlt sich halt gut an, wenn man endlich mal wer ist und \\n',\n",
       " 'Krzlich gab es rund 130 Positive in Euskirchen. War das ein Testfall fr Laschet? Sder hat vieles besser gemacht als der CDU-NRW-Chef. So auch diesmal, denn der Obsthof in Euskirchen wurde nicht abgeriegelt. Und, oh Wunder, Dutzende sind aus der Quarantne auf nimmer Wiedersehen verschwunden.\\n',\n",
       " 'Wenn Corona so harmlos ist,  wie vielfach behauptet,  warum dreht dann langsam die ganze Welt durch ? Warum gibt es in vielen Lndern auf der ganzen Welt einen Lockdown ? Warum riskieren viele Lnder ( egal ob Demokratie, Diktatur, etc. )  auf der ganzen Welt durch einen Lockdown den wirtschaftlichen Kollaps ? Sind die Bilder von Leichenbergen ( Sdamerika, USA , etc. ) nur Flschungen? Meines Erachtens ist auch weiterhin uerste Vorsicht angebracht. Insofern ist Sder im Recht.\\n',\n",
       " 'DANKE fr die Entscheidung! Habe die ganze Zeit in einem Wohnheim gearbeitet und meinen Job gemacht. Und auch Karfreitag bin ich 13 Stunden vor Ort. Danach endlich mal 3 Tage frei und die dann auch noch in den eigenen 4 Wnden?! Leute, geht raus und haltet Abstand! Und alles ist gut. Kann so einfach sein\\n',\n",
       " 'Ganz bse. Da sind doch tatschlich Menschen in einem Hotel abgestiegen. Wie knnen sie nur. Ganz schlimme Superspreader, das.\\n',\n",
       " 'Was bitte hat Seehofer mit Friseuren am Haar hm am Hut? Der Innenminister hat hier gar nichts ... das ist Lndersache.\\n',\n",
       " 'Auch wenn ich keine Hoffnung hab, dass dieser Virus-Typ nicht schon bei uns ist, so mu man sich mal der Tragweite dieser sehr kurzfristig anberaumten Manahme vor Augen halten auf beiden Seite des rmelkanals in einer Phase wo genug Unruhe durch den mglichen harten Brexit besteht Zutiefst beunruhigt kann es jetzt nur noch schlimmer werden und erwarte alsbald die ersten Flle hier dokumentiert sind heftigste Einschrnkungen fr uns alle, die wir bislang noch nicht erleben muten.  \\n',\n",
       " 'Wieviel brauchen die franzsischen Banken fr die Ablsung des italienischen Kreditgeschfts?\\n',\n",
       " 'Es gibt bei der offiziellen Inflationsrate neben dem Problem der unzureichend erfassten Immobilienpreissteigerungen, des wohl nicht mehr reprsentativen  Warenkorbes, auch das Problem mit den hedonischen  Bewertungsmethoden, die in die Berechnung der Inflation im gewissen Umfang auch willkrliche anmutende Korrekturfaktoren einflieen lassen. So weist die alternative Inflationsberechnung der Webseite Shadowstats.com schon seit Jahren eine \"wahre\" Inflationsrate von ber 6% aus wie Dirk Mller und Max Otte in einem Artikel des Focus schon 2014 verdeutlichten.\\n',\n",
       " 'Junge,Junge,ist das nicht\"Singen im dunklen Walde\"? Zum einen ist doch der Inzidenzwert schon immer willkrlich gewesen,selbst das Argument der \"Kontaktnachverfolgung\"ist-im Grunde- Unsinn, denn wenn nicht nachverfolgt wird ,wie wir derzeit sehen, ist es auch nicht tragisch. Man kann sich gut wichtigere Einsatzmglichkeiten fr Gesundheitsamtsmitarbeiter vorstellen! Und nun die MUTANTE!!!!Uih! Sollen wir uns nun im Keller verstecken?Fast das einzige,was als unsinnige Massnahme noch fehlt? Nein,wirklich, nur weil die Politik in der Pandemiebekmpfung mit ihrer Klaviatur unsinniger Massnahmen versagt,und versagt,und versagt, muss der Brger\"bluten\"? NIEMAND! kann belegen, welche Einzelmassnahme welche-wenn berhaupt- Wirkung hat. NIEMAND! kann eindeutig sagen, ob und wieviel gefhrlicher die neuen Mutationen sind. NIEMAND!kann genau beziffern,wieviele Insolvenzen,wieviele Selbstttungen,wieviele psychischen Strungen auf das Konto der Pandemiebekmpfung gehen. NIEMAND! kann sagen, welche Alternativen zu den bisherigen Massnahmen erfolgversprechend wren, weil man sie nicht ge-und versucht hat! Was man allerdings genau sagen kann ist,wieviele Menschen sterben mussten,weil sie nicht rechtzeitig geimpft wurden. Insofern ist ein\"weiter-so\" keinesfalls der richtige Weg.\\n',\n",
       " 'Vielleicht macht BG einfach den Anfang - die Kohle sollte er ja haben. Dann htte er vielleicht wenigstens biologische Viren mal erfolgreich bekmpft :-).\\n',\n",
       " 'Warum hat man sich seit 2013 nicht darum gekmmert? Bundestagsdrucksache 1712051  Nicht nur da Totalausfall. \\n',\n",
       " '\"Erstmals seit Januar ber 30.000 Neuinfektionen in Grobritannien\"  Uiuiui - und das mitten im Hochsommer, bei warmen Temperaturen und viel UV-Strahlung. Da werden jetzt einige der \"Corona ist ein saisonales Virus\" Fans aber Kopfschmerzen bekommen und neue Ausreden gegen Corona-Manahmen im Sommer finden mssen ...\\n',\n",
       " 'Daumen hoch dafr Frau Lambrecht, in diese Richtung muss es jetzt in groen Schritten weiter gehen... Zurck zur Normalitt fr geimpfte Mitbrger,- vollkommen egal ob die Medien jetzt eine Neid-Debatte herbeireden wollen oder nicht.\\n',\n",
       " 'Wie erwartet! : 170 Tote mehr zum Vergleichs-Wichentag 23.12.20 !! - auch unter Lockdown-Bedinigung! Das wird die beiden letzten Tage so weiter gehen wie auch im Jan.21!! Frohes Neues!!\\n',\n",
       " 'Also - von der \"Deutsche Gesellschaft fr Krankenhaushygiene\" zum Beispiel, htte ich eher ein Update erwartet, wie der aktuelle Stand der Dinge in Sachen multiresistente Keime in Krankenhusern ist, sprich wird jetzt endlich grndlich genug geputzt oder sollte man planbare OPs doch vorzugsweise im angrenzenden Ausland durchfhren lassen, ich denke da an NL, wo es dieses vermeidbare Problem nicht gibt. Zur ffnung der Schulen - ich wrde sagen, Ende Mai wissen wir Bescheid, z.B. aus sterreich, Dnemark oder auch Sachsen, welche Auswirkungen das hat und ob es ein gangbarer Weg, wobei man auf die jeweils durchgefhrten Hygienemanahmen und Ablufe schauen muss und dann kann man entscheiden. Die 2 Wochen stehen wir auch noch durch.  \\n',\n",
       " 'So langsam ist die Zeit reif. Wie kann ich einfach und schnell testen, ob die Menschen, die etwas betreten wollen, geimpft sind ? Na, indem die geimpften gechipt werden und an einem Scanner vorbeilaufen sobald sie z. B. in ein Fuballstadion oder Flugzeug wollen. Es wre die sicherste, zuverlssigste Methode. ( Satire aus )\\n',\n",
       " 'Inkubationszeit 14-28 Tage.....also ist die heutige Situation ein Abbild der Infektionsrate vom 1. - 15. Februar. Die italienische Regierung hat vor 10 Tagen drastische Massnahmen getroffen und Ende Januar den Notstand ausgerufen und Chinaflge verboten. Auch dort basieren sich die Zahlen von heute auf die Zeit vor dem 15. Februar und vor den Massnahmen...die Massnahmen werden erst in 10 Tagen beginnen zu greiffen....und dann sollte sich die Kurve abflachen.....die WHO lobte das Land. Unverstndlich dass Deutschland nichts tut und nicht auf die Erfahrungen Italiens baut, das ein umfassendes hervorragendes staatliches Gesundheitswesen hat, das NICHT am Limit arbeitet. Das Fehlen von Massnahmen wird dramatische Folgen haben in Deutschland. Man lsst Messetermine stehen, den Karneval laufen und Fussballspiele....\\n',\n",
       " 'Impfstoff nicht verfallen lassen ist o. k. und das man  80 am Abend nicht zusammentrommeln kann, ist mir auch klar, aber ich glaube nicht, da alles medizinische und Pflegepersonal vor Ort schon geimpft war, damit wre man auch regelkonform gewesen. Trotzdem finde ich die Emprung bis hin zu Rcktrittsforderungen reichlich bertrieben.\\n',\n",
       " 'ber die Kirchen habe ich nichts gelesen. Bleiben die offen, macht der Virus aus Achtung vor den Glubigen an der Kirchentr halt? In Sachsen hie es, die entscheiden in eigener Verantwortung. Das geht doch wohl berhaupt nicht.  Die Regeln mssen fr alle gltig sein.\\n',\n",
       " 'Na kein Wunder, dass die Pandemiemanahmen so populr sind. Nei Kurzarbeiterheld zu Hause die Garage und den Keller aufrumen, mal runterkommen vom Stre... nur hoffentlich sind die Arbeitspltze dann nach anderthalb Jahren wirklich noch da...\\n',\n",
       " 'Warum kommt er eigentlich erst jetzt mit dieser Selbstverstndlichkeit um die Ecke???\\n',\n",
       " 'Ach, in den USA geht das? Bei Amazon-Deutschland nehmen mittlerweile manche Leute Preise fr die bliche Handdesinfektionsbrhe, die das 2,5...3 fache des bisher blichen betragen. In der Apotheken ist das kaum mehr zu kriegen, also kochen einige da wohl ihr Sppchen. Ich warte eigentlich nur drauf, dass da welche das Zeug obendrein schlicht mit Wasser verstrecken.\\n',\n",
       " 'Ein interessanter Artikel, der die Grenzen der Wissenschaft, przise Aussagen zu machen, verdeutlicht. Es gibt keinen weder theortisch begrndbaren geschweige denn exakt umsetzbaren Grenzwert fr einen sicheren Abstand. Der Soll-Abstand muss ein sinnvoller Kompromiss zwischen Ansteckungsschutz und anderen berechtigten Interessen sein. Wenn die Infektionszahlen wieder steigen, war der wohl zu kurz und Lokalittten, an denen sich der Abstand nicht einhalten lt, mssen wieder geschlossen werden. \\n',\n",
       " 'Klartext: Corona ist eine schne Gelegenheit, gratis marginalisierte Menschen zeitnah verschwinden zu lassen. Die Reichen begeben sich auf die Azoren zum Golfen, die Armen sind ein Makel im Straenbild. Wenn die Reichen zurckkommen, sind vielleicht weniger Arme unterwegs, die das Bild beeintrchtigen, ganz automatisch, ganz ohne Zutun von Gewalt, der Virus ist ein Freund der Reichen!  Wenn der Typ nicht in die Psychiatrie eingewiesen wird, dann sollte doch jeder erkennen, wie die \"Elite\" tickt, die ballen doch alle lngst die Faust in der Tasche, vor rger, dass sie das Ganze nicht besser gemanagt haben.  Beim nchsten \"Neuvirus\" wird ihnen das nicht mehr passieren.\\n',\n",
       " 'Firmen im Baugewerbe? Nach dem Bauboom der letzten Jahre? Wie schnell man doch um seine Existenz frchten kann, wenn Geld vom Staat ins Blickfeld rckt. Verppelt bitte jemand anderen...\\n',\n",
       " 'Wenn Merkel dafr sorgt, das Patente freigegeben werden, wre das eine echte Hilfe gewesen. Die Idee das man eine Milliarde Einwohner irgendwie materiell helfen kann, wird am Ende nur ein Tropfen auf den heien Stein sein.\\n',\n",
       " 'Mchte mal sehen, wie Alk-Verbot rund um die Rigaer Strae durchsetzbar ist.  In anderen Stadtteilen wird es nicht viel besser sein, zumal die Polizei - die das ja berwachen muss -seitens der Landesregierung keinerlei Rckhalt besitzt. Seitens der Bundesregierung auch nicht viel mehr.\\n',\n",
       " 'Dir Bundesregierung muss umgehend die Freigabe der AZ Impfungen verfgen! Umgehend heit in diesem Fall: Vor zwei Stunden! Dazu wrde ich als Gesundheitsminister auch ganz eigenmchtig die bevorzugte Verwendung bei lteren Menschen anordnen, weil in dieser Gruppe niemand mit Nebnewirkungen aufgefallen war, bisher zumindest.\\n',\n",
       " 'Ich halte die Freigabe trotz allem fr vertretbar, wenn auf das Risiko hingewiesen wird.  Man sollte aber auch Informationen herausgeben ab welchem Alter diese Trombosen bei den Patienten aufgetreten sind um unntige Risiken zu vermeiden.\\n',\n",
       " 'Ich wrde gerne mal ein paar mehr Zahlen haben, damit man das einsortieren kann. Beispielsweise mal die Alterstruktur der Kranken (alle positiv getestete), die Alterststuktur der Kranken, die im KH behandelt werden mssen und die Alterstruktur der Gestorbenen.  Bei den Jngern gerne auch mal genauere Informationen ber die Vorerkrankungen. Ich kann mir nicht vorstellen, dass die Zahlen nicht existieren. Trotzdem hrt man immer nur von dem Durchschnittsalter.\\n',\n",
       " 'Das Problem ist, dass Merkel nur die Welle brechen, aber nicht die Inzidenz massiv senken will, um ffnungen zu ermglichen. Die Notbremse war in vielen Regionen vor Wochen schon umgesetzt worden. Oftmals strenger, als im Gesetz verankert. Dennoch sinken die Neuinfektionen nicht. Ganz im Gegenteil: es zieht wieder leicht an. Diese halbgaren Manahmen ohne Perspektive sind absolut ermdend. \\n',\n",
       " 'ber alles wird berichtet im Zusammenhang mit Corona. Aber der seit gestern vorliegende Sicherheitsbericht des PEI einfach ignoriert ?!?\\n',\n",
       " 'Unfassbar. Das wird die Pseudoinfektionzahlen explodieren lassen. Die Inzidenz wird dann dementsprechend erhht oder soll die etwa immer noch bei 0.05% bleiben? \\n',\n",
       " '\"Eurostaaten wollen weiter Geld in die Wirtschaft pumpen\"  Und wer zahlt am Ende alles? Natrlich der deutsche Steuerzahler und Sparer!  Es wird endlich Zeit fr den \"Dexit\"! GB hat davon in der Pandemie profitiert.  Deutschland wird, wenn die deutsche Bevlkerung seine Innovationskraft wiedergefunden hat die sie mit dem Beitritt zur \"EU\" und Euro verloren hat, nach einer kurzen Durststrecke auch wieder profitieren und  weltweit, natrlich auch mit der \"EU\" wenn diese mchte, mit anderen Staaten Handel treiben.\\n',\n",
       " 'Ich sehe richtig, dass Mbelgeschfte, Klamottenlden, Friseur, Massage und Co offen bleiben?  Disclaimer: Drfen sie von mir aus gerne. Ich htte aber mit erneuter Schlieung gerechnet\\n',\n",
       " 'Widerwrtig selbst - und geschichtsvergessen, diese malerische Beschreibung eines traulichen touristischen Ausflugs. Besserverdienendenjournalismus fr die weltferne Insel im Speckgrtel. Fr mich ist solcher \"Journalismus\" die gefhrliche Manifestation eines Coabhngigkeitssyndroms im Vollbild. Und ich weiss ziemlich genau, wovon ich rede, wenn ich so etwas sage... \\n',\n",
       " 'Die Schritte sind zu klein, die Disziplin und Geduld der Bevlkerung schwindet rasch. Vorallem innerhalb der Familie werden die Groeltern nicht lange auf Enkelkontakt verzichten wollen. Wenn die Schulen alle ffnen werden wir eine schnelle Verbreitung und Immunisierung der Familienmitglieder haben, und nach erfolgtem Antikrper Test kann Oma dann auch wieder zu Besuch kommen. Die Durchseuchung muss schnell erfolgen damit die Leute greifbare Ziele haben, DAS wird unsere Schwcheren und lteren schtzen. Und nicht: ach das dauert alles noch ewig so lange warte ich nicht. Zack hat Oma dann Corona. Der grte Akt der Solidaritt gegenber Groeltern ist das schnelle immun werden. \\n',\n",
       " 'Kann mal jemand diesem Schnredner das Wort entziehen. Ich habe nicht vergessen, wie genau dieser Herr am Anfang der Infektionen, diesen Virus verharmlost hat. Daher auch die zu spte Reaktion darauf. Und sich jetzt als groer Retter aufspielen. \\n',\n",
       " 'Wichtig: Bei der Dienstbesprechung war das Virus ganz brav, erst bei dem privaten Teil ist es ber die Menschen hergefallen!\\n',\n",
       " 'Es wird jeden Tag klarer. Die einzige Partei, die in den letzten 8 Jahren etwas fr das Land, Arbeitnehmer, Familie und Rentner vorwrts bewegt und nicht verhindert hat, ist die SPD.\\n',\n",
       " 'Ein Problem sind die ffnungszeiten. Wenn die, die gutes Geld verdienen, Zeit zum Einkaufen haben, sind die Lden oft schon zu. Vllig unlogisch, da die Ladenffnungszeiten ziemlich identisch mit den Arbeitszeiten sind.   Nchstes Problem die restriktiven Manahmen gegen den Individualverkehr. Als Deutschland noch halbwegs normal war, stoppte ich auf dem Weg von der Baustelle nach Hause mal an dem Laden, mal an dem...oder hab noch schnell mit Bekannten einen Kaffe geschlrft. Da gingen schnell mal 50..100 DM ber den Ladentisch. Jetzt drohen berall die Politessen mit Knllchen. Also kaufen wir im sicheren Supermarkt ein und meine Frau bestellt alles Andere ...nach einem anstrengenden Arbeitstag auf der Couch entspannend... mit dem Tablett.   Die Politik will es doch nicht anders.\\n',\n",
       " 'Wir sollten lieber nicht zu berheblich werden, wie wir mit unserer tollen Impfbereitschaft bald alle anderen abhngen. In dieser Woche hatten wir den grten Zugewinn an verfgbarem Impfstoff. Aber am Montag und Dienstag wurden jeweils deutlich weniger Spritzen gesetzt als in den Vorwochen. In Deutschland haben wir die dynamischste Phase schon hinter uns - und das bei knapp ber 50% Quote bei den Erstimpfungen. Es flacht bedenklich frh ab und wird ber den Sommer hinweg noch mhsam werden, in die Nhe der 70% zu kommen.\\n',\n",
       " 'Bei uns liegt der inzidenzwert bei 50 warum mssen unsere Kitakinder und Schulkinder weiter zu Hause bleiben ? Solidaritt ist ja gut aber die meisten Eltern sind berufsttig und haben keine freien Tage mehr.  Regionale Unterschiede mssen bercksichtigt werden .\\n',\n",
       " 'Ich halte die titelgebende Frage fr korrekt gestellt. Wenn man denn davon ausgeht, dass der Artikel auch bis zum letzten Satz gelesen wird. Denn Frau Hflingers letzter Satz gibt eine Art Antwort. Man kann natrlich auch den Umstand, dass nur 5% der Inder lter als 65 Jahre sind (werden?), in die Waagschale werfen. Ich bersetze das mal folgendermaen (bei aktuell rund 21% Bevlkerungsanteil ber 65 Jahhre in Deutschland):  75% der momentan ber 65-Jhrigen in Deutschland (gemessen an der Zahl der Gesamtbevlkerung) wre aktuell nach indischen Mastben naturgem nicht mehr am Leben. Wre das ein erstrebenswerter Zustand, um die Corona-Todesrate zu relativieren? \\n',\n",
       " 'Laut aktuellem Wochenbericht des RKI hatten wir in der KW 12 ca. 350 SARI-Flle, davon die Hlfte mit Covid-19. Im gleichen Zeitraum des Jahres 2019 hatten wir ber 700 SARI-Flle. Im aktuellen Bericht heit es u. A.: \"Wegen zum Teil sehr geringer Fallzahlen kann keine Aussage zu einzelnen Altersgruppen getroffen werden.\" oder auch: \"Die ARE-Rate liegt weiterhin unter den Werten der Vorsaisons auf einem extrem niedrigen Niveau.\". Das passt doch alles nicht zusammen. Kann mir jemand den Widerspruch erklren?\\n',\n",
       " 'Viele verstehen nicht, dass es noch nicht mal Halbzeit ist. Und dass Halbzeitergebnisse am Ende nicht zhlen. Schweden, jedenfalls Stockholm, wird mit einem entscheidenden Vorteil in die zweite Halbzeit (zweite Welle) im Herbst/Winter gehen. Wenn es Verlngerung gibt (d.h. Keinen Impfstoff) werden sie dann locker vorbeiziehen.\\n',\n",
       " 'Wenn man die Mehrwertsteuer um \"dramatische\" 3% senkt und gleichzeitig Corona Soforthilfen im Milliardenbereich wieder zurck fordert , obwohl man ffentlich das genau Gegenteil behauptet hat, dann geht die Bazooka nach hinten los. Wo leben die Jungs nur ? Im Wolkenkuckucksheim ? \\n',\n",
       " 'Bis wir in Deutschland endlich die Maskenpflicht abgeschafft haben, steht die nchste Pandemie vor der Tr.   Die Deutschen lieben Sicherheit und Bevormundung, also kann es munter so weitergehen.   Ich platze vor Wut: Unter 1.000 neue Infizierte heute und 83 Millionen Menschen werden weiterhin unter Masken gezwungen. \\n',\n",
       " 'Jetzt mssen alle fr die Unfhigkeit der fr die Impfstoffbeschaffung Verantwortlichen in Brssel und Berlin bssen.\\n',\n",
       " 'Also man braucht fr die Aktion lauf vdL 40 Mrd. Euro, etwa 10% des Bundeshalts. Vorsichtshalber mal etwas mehr verlangen. Wahrscheinlich ist man sich schon Bill Gates darber einig, dass 7 Mrd. Menschen geimpft werden. Warum und gegen was - das steht in den Sternen. Hoffentlich wird Widerstand2020 einen frischen Wind in die Politik bringen.\\n',\n",
       " 'Die WHO ist massgeblich von China finanziert und beeinflusst. Insofern sollte man deren Untersuchung nicht allzu abschliessend akzeptieren. Auch der Umstand, das Trump stets China fr die Freisetzung des Virus unter Verdacht stellen wollte, muss nicht heissen, das das Gegenteil der Fall war. Klar ist auch, das Cina, sofern sie wirklich der Urheber des Virus wren, dies garantiert niemals zugeben knnten. Man stelle sich die enormen Schadensersatzforderungen vor, die auf sie zukommen wrden. Unterm Strich bleibt nach wie vor ein wenig Raunen und der merkwrdige Umstand, das am Ursprungsort des Ausbruchs der Pandemie ein wichtiges virologisches Institut steht, an dem nachweislich an fledermausviren geforscht wurde. \\n',\n",
       " 'Alles alter Hut. Das interessanteste Medikament ist Ivermectin. In Vitro ttet 99.8% dieser Viren. Dabei ist das Medikament altbekannt... gegen Krtze, Luse und Wrmer. Wird benutzt als spot-on Tropfen, Salben, Tabletten... fr Hunde, Katzen und Pferde. Ist immer noch zu kaufen! 8-D\\n',\n",
       " 'Mich wrde ja brennend interessieren, wo die 250 \"Feiernden\" nach der Auflsung der Party hingegangen sind.  Dass die alle brav nach Hause sind glaubt doch wohl niemand ernsthaft, oder?\\n',\n",
       " 'Auch Nationalsozialisten sind vllig verfassungskonform an die Regierung gekommen. Und haben dann sie Lcken in der Verfassung genutzt um mit Verordnungen Ihr katastrophales Werk zu beginnen. War ffnen wir wieder diese Tore? Solche Gesetze knnen in Zukunft auch von Extremen verwendet werden. Irgendein Virus wird sich schon finden.  Und die Mehrheit applaudiert auch nur, wie 1937. Danke Herr Lindner. \\n',\n",
       " 'Htte man sich darum gekmmert heraus zu finden wo denn tatschlich die Infektionen herkommen  msste man jetzt nicht panisch alles schlieen.  Oder gibt es gar nicht DEN infektionsherd und es kommt von berall ein bisschen was dann zu einem groen ganzen wird?\\n',\n",
       " 'Es wre genauer, wenn man nicht Coronakrise sagen wrde, um damit zu unterstellen, ein kleiner Virus htte das ausgelst. Auch wenn die Politiker und ihre Hofberichterstatter es so darstellen, um alle Verantwortung abzuschieben, ist diese Krise menschengemacht. Es gibt unzhlige Grnde, die eine Rezession unumgnglich machten. Selbst das i-Tpfelchen, der Shutdown, war eine bewusste Entscheidung der Politik, gegen alle Argumente der Epidemiologen. Ein Staatsvirologe als Feigenblatt reicht da nicht, um zu behaupten, es wre, wie immer, alternativlos gewesen.\\n',\n",
       " 'Krass, unsere Kinder sitzen mit Maske in der Schule, aber im Stadion sitzen die Zuschauer dicht an dicht ohne Abstandsregeln. Unglaublich, dass die Gesundheitsminister das auf EU-Ebene nicht strker reglementiert haben. \\n',\n",
       " 'Namhafte Virologen wie Streeck haben schon immer schon gesagt, dass Corona - trotz Impfung - endemisch werden wird und wir mit dem Virus leben mssen.  Wenn die ganze Bevlkerung geimpft ist, who cares, ob man sich noch ansteckt. Jede Ansteckung und jeden Tod kann man nicht verhindern - das muss man auch gar nicht.\\n',\n",
       " 'Interessant wre zu wissen, ob an dem Abend in Restaurant gesungen wurde (kommt ja vor mit Happy Birthday). Sehr viele groe Ausbrche haben mit Singen und Schreien zu tun.\\n',\n",
       " 'Zitat:  \"Johnson hat Klarheit versprochen, einstweilen aber nur Konfusion geschrt.\"  Fr die Coronakrise gilt also das gleiche Rezept wie fr den Brexit: Hauptsache raus, egal wie. Ein Plan kommt nachher.\\n',\n",
       " 'Im Restaurant? Heisst ich darf kein restaurant mehr besuchen wenn ich kein Mobiltelefon hab? Und wenn muss ich Fremde auf mein Display glotzen lassen um nachzuweisen dass ich die app aktiv nutze? langsam wirds albern....\\n',\n",
       " 'Knnt ihr diesen Bldsinn in Anbetracht der Ernsthaftigkeit der Situation mal lassen? Es gibt offensichtlich harte Auseinandersetzungen um die richtigen/notwendigen Manahmen zwischen den 16 Landesregierungen; die Bundesregierung versucht zu moderieren. Hier konstruieren Lydia, Veit und Christoph einen Machtkampf, wo keiner ist. Appell an das Verantwortungsbewusstsein eines Leitmediums!\\n',\n",
       " 'Es ist aus wirtschaftlicher und hygienischer Sicht falsch die Geschfte zu schlieen. In den verbliebenen offenen Geschften werden sich mehr Menschen tummeln.  So schwer die Situation auch ist, man kann nicht das ganze Leben allein Corona unterwerfen. Bildungstechnisch ist es ein Verbrechen die Kinder wieder in den Distanzunterricht zu schicken. \\n',\n",
       " 'In der berregionalen Berichterstattung wird kaum bzw. wenig darber geschrieben, dass in Hamburg die Kitas im Regelbetrieb sind und bleiben werden. Nachzulesen auf der Behrden Homepage. Von daher ist auch keine Notbetreuung notwendig, es kann ja jedes Kind kommen. Es wird lediglich an die Eltern appelliert.. Und wie weit man damit kommt, haben wir in den letzten Monaten gesehen.. \\n',\n",
       " 'Solange das Vereinsheim mit Bar zubleibt wre es ja ok. Ich hatte micht schon gefragt, warum niemand mehr Golf spielt und zur gleichen Zeit sich die Menschen in Mnchen auf die Fe treten.\\n',\n",
       " 'SPON macht mit bei der Hetze der Covid19 Leugner. Damit schliet ihr inhaltlich auf zu BLD und LOCUS. Wenn sich bewahrheitet was Experten prognostizieren und Kliniker immer mehr und immer fter Folgeschden diagnostizieren werdet Ihr nichts mehr von Eurer dummen und kurzsichtigen Haltung wissen wollen. Wetten das? Fr mich seid Ihr gestorben. \\n',\n",
       " 'Genau richtig so. Erst mal richtig die vorhandenen Daten auswerten bevor man  AZ weiter verimpft. Wenn man weiter verimpft und es treten dann noch mehr Flle auf ist das gejammere wieder gro. \\n',\n",
       " \"Macht nichts. Die Bayern haben noch ganz viele andere Bereiche und viel Lebensfreude die Menschen aus aller Welt jedes Jahr anzieht. Zwischen IAA und Oktoberfest gibt's noch viele Grnde Bayern zu besuchen. \\n\",\n",
       " 'Ich denke, die frderale Struktur im Bildungsbereich darf gerne hinsichtlich ihres Sinnes und Zweckes auf den Prfstand. Aber ich denke auch, dass der politische Wille nicht allzu gro sein wird.\\n',\n",
       " 'Hallo zusammen, hat sich eigentlich mal einer darber Gedanken gemacht wie man mit der neuen Herrengesellschaft (geimpfte) umgehen soll gerade bei ffentlichen Veranstaltungen? Sollte man dann nicht geimpfte mit einem Zeichen an der Kleidung kennzeichnen um andere davor zu schtzen? Um eventuelle schnelle Aussortierungen bei Fuballspielen zu Gewhrleisten! Ich denke das ist nicht machbar und man sollte auch einmal die andere Seite der Medaille betrachte was daraus entstehen knnte.  Schlielich sind unsere Grundrechte doch ganz klar definiert und man sollte auch alle Menschen gleich behandeln egal ob wei, schwarz  welche Glaubensrichtung oder ob geimpft oder nicht! Das ist die Entscheidung jedes einzelnen in unserer Gesellschaft. Bin mal gespannt ob ich, sollte ich mich nicht impfen lassen, beim nchsten Urlaubsflug nur noch einen Platz auf einer Tragflche bekomme. Freue mich schon auf die Reaktionen fr eine offene Diskussion.\\n',\n",
       " 'Laut \"Our World in Data\", zitiert in Guardian 31.1.2021 werden, bei der gegenwaertigen Impfrate, Ende September 15% der EU-Bevoelkerung geimpft sein. Es handelt sich also nicht um die \"kommenden Wochen\", sondern um die kommenden Jahre.  Wieviele Tote haben Merkel, Spahn, vdLeyen & Co. verschuldet?\\n',\n",
       " 'In unserer Region sind wesentlich kleinere Veranstaltungen abgesagt worden, um den 11. Mrz herum. Absolut unverstndlich, dass die CDU Frankenberg diese Merz-Veranstaltung durchlaufen lie. \\n',\n",
       " 'Merkel: \"Ein Virus, das uns alle trifft, lsst sich von keinem Land allein besiegen.\"  Das ist schlicht falsch. Sind alle Brger in einem Land geimpft, sind eben auch alle Brger genau dieses Landes sicher vor dem Virus. Die geimpften Brger knnen sich nicht mehr anstecken, weder von Touristen die ins Land kommen noch als Touristen bei Auslandsreisen! Wenn dem nicht so wre knnte man sich die Impfungen sparen. \\n',\n",
       " 'Eigentlich ist es doch ganz einfach: Ich bleibe zu Hause, auer ich muss zur Arbeit, zum Arzt oder einkaufen. Man darf den Hund ausfhren, joggen - nur sollte man grundstzlich Abstand zu anderen Personen halten. Niemand will die Demokratie, die Vielfalt oder sonstiges abschaffen - wir sollten mglichst nur gesund bleiben. Ganz einfach!\\n',\n",
       " 'Da man als Geimpfter nicht davor gefeit ist positiv getestet zu werden, sehr wohl aber ein schwerer Krankheitsverlauf (fast) ausgeschlossen werden kann, halte ich die Abschaffung der Inzidenz als aussschlielichen Richtwert fr Manahmen fr sehr sinnvoll.\\n',\n",
       " 'Erstens will ich was von dem Zeug  haben, dass die Beamten im Ministerium bekommen, um so drauf zu kommen. Und zweitens mchte ich bei dem Quatsch den die da treiben mitmachen. Im Home-Office lustige Anregungen zu der Realsatire der DFL zu machen klingt nach einer spaIgen Angelegenheit. Sonst gibt es da gerade nichts zu tun? Vielleicht Arbeitsschutz und Arbeitssicherheit fr Erntehelfer verbessern? Oder wie steht es um die Arbeitnehmer in Supermrkten oder bald in zahlreichen Ladengeschften?\\n',\n",
       " 'Japan handelt und kommt endlich in die Ptte\\n',\n",
       " 'Die lteren Schler:innen knnte man auch jetzt schon impfen, zumal gerade fr die Abschlussjahrgnge Prsenzunterricht unabhngig von der Inzidenz besteht. \\n',\n",
       " \"Ungeachtet dessen,was man von den Querdenkern zu halten pflegt ist es schon erschreckend ,wie geifernd die Masse hier nach hrtester Repressalie von Staatsseite lechzt.  Gab's schonmal in diesem Land,kam international nicht so gut an, Mal vom arabischen Raum abgesehen...die pflegen noch heut hnliche Phantasien,bei uns haben sich scheinbar auch nur die Opfer gendert\\n\",\n",
       " 'Ich denke, dass man angesichts der steigenden Zahlern in Deutschland auch hier wieder mehr Klopapier und Konserven einkaufen sollte, bevor erneut Panik ausbricht. Kein Mensch wei, was Herbst und Winter unter den dann vernderten Lebensbedingungen bringen und man sollte auch nicht die Dummheit und Borniertheit vieler unbelehrbarer und selbst ernannter Schlaumeier unterschtzen.\\n',\n",
       " 'die Leute mit ihren mega super drakonischen lockdown Fantasien machen mir langsam wirklich Angst..\\n',\n",
       " 'Tja dann hat hat Corona doch was gutes .... die Grippe wurde auch ohne Impfung bekmpft ... Dann wissen wir ja was wir ab jedem Herbst bis Frhjahr tun mssen ..... Lockdown !!!! \\n',\n",
       " 'Ich mchte niemals das beste Deutschland aller Zeiten mit der autoritren Lndern wie der DDr vergleichen, da brauchte es zum bespitzeln moch nen Staatsapparat, hier nen netten Nachbarn und 3 Apps. Aber hier polemisch darauf hinweisen, dass man in der DDR im Inland Reisen und Essen gehen konnte ist fies, denn der Virus zwingt uns alle Ventile zu schlieen und sich dann wundern, dass 20 jahrige nicht 14 Monate daheim bleiben, ist schon wohlwollend als naiv zu bezeichnen. Aber es wird niemand zum impfen gezwungen, dann bleibt halt der ungeimpfte im Berufsverbot und daheim. Dies ist kein Zwang, sondern Motivation, wie damals halt. Wenn du was dagegen hattest, musste man halt motiviert werden.\\n',\n",
       " \"Wer an Demonstrationen ohne Maske teilnimmt, silliest unterschreiben, I'm Falle einer Infektion auf intensivmedizinische Behandlung zu verzichten.\\n\",\n",
       " 'ist doch ganz einfach. Wer negativ getestet ist und die App verwendet darf wieder raus. Alle anderen haben Ausgangssperre...\\n',\n",
       " 'Abstand zu halten und eine Maske zu tragen ist nun wirklich kein Problem und dies zu einem allgemeinen Gebot zu machen auch nicht. Ein solches abzuschaffen setzt ein absolut falsches Signal. \\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 800.00 MiB (GPU 0; 4.00 GiB total capacity; 1.90 GiB already allocated; 317.91 MiB free; 2.53 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5528/1323956124.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhello\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mid_to_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mall\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\germansentiment\\sentimentmodel.py\u001b[0m in \u001b[0;36mpredict_sentiment\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mlabel_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m         outputs = self.bert(\n\u001b[0m\u001b[0;32m   1525\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    988\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         )\n\u001b[1;32m--> 990\u001b[1;33m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[0;32m    991\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    580\u001b[0m                 )\n\u001b[0;32m    581\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                 layer_outputs = layer_module(\n\u001b[0m\u001b[0;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[0;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     ):\n\u001b[1;32m--> 401\u001b[1;33m         self_outputs = self.self(\n\u001b[0m\u001b[0;32m    402\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_query\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrelative_position_scores_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 800.00 MiB (GPU 0; 4.00 GiB total capacity; 1.90 GiB already allocated; 317.91 MiB free; 2.53 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = SentimentModel()\n",
    "all = 0\n",
    "correct = 0\n",
    "\n",
    "hello = [id_to_label[x] for x in train_dict[\"labels\"][:150]]\n",
    "\n",
    "for idx, word in enumerate(model.predict_sentiment(train_dict[\"text\"][:150])):\n",
    "    print(word, idx)\n",
    "    all += 1\n",
    "    if hello[idx] == word:\n",
    "        correct+= 1\n",
    "\n",
    "print(correct/all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_imdb = imdb.map(preprocess_function, batched=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb0ed09b01ac7e66b2ee8fd1b727dbc61e234ad6836f9832d0e5faf71aa1bb7a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
