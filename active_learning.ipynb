{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from scipy.stats import entropy\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=20,\n",
    "    evaluation_strategy=\"epoch\"\n",
    "    )\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_accuracy(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        print(\"Predictions\", predictions, \"Labels\", labels)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "        \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "trainer = Trainer(model= AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\"),\n",
    "                args=training_args,\n",
    "                train_dataset=None,\n",
    "                eval_dataset=None,\n",
    "                tokenizer=tokenizer,\n",
    "                data_collator=None,\n",
    "                compute_metrics = compute_metrics_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trainer = Trainer(model= AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\"),\n",
    "#                 args=training_args,\n",
    "#                 train_dataset=None,\n",
    "#                 eval_dataset=tokenized_dataset_test,\n",
    "#                 tokenizer=tokenizer,\n",
    "#                 data_collator=data_collator,\n",
    "#                 compute_metrics = compute_metrics_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(logits):\n",
    "    probas = torch.nn.Softmax(dim=1)(torch.from_numpy(logits))\n",
    "    samples_entropy = entropy(probas.transpose(0, 1).cpu())\n",
    "    samples_entropy = torch.from_numpy(samples_entropy)\n",
    "    return samples_entropy\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"texts\"], padding = True, truncation=True)\n",
    "\n",
    "def get_new_sample_active_learning(number_of_comments):\n",
    "\n",
    "    ### We read in the csv that stores all of our already annotated data\n",
    "    df = pd.read_csv(\"annotated_data/annotated_data_with_users.csv\", names=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\",\n",
    "                     \"topic_comment\", \"Topic_article\", \"Comment\", \"Method\"])\n",
    "\n",
    "\n",
    "    ### Check if we already have active learned comments that we annotated\n",
    "    if os.path.isfile('annotated_data/active_learning_comments.csv'):\n",
    "        progress_csv =pd.read_csv(\"annotated_data/active_learning_comments.csv\",names=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\", \"topic_comment\", \"Topic_article\", \"Comment\"], encoding=\"utf-8-sig\", header=None)\n",
    "\n",
    "\n",
    "    ### Stores comments as string that we already have in active learning csv\n",
    "    bereits_comments = []\n",
    "    for comment in progress_csv.Comment:\n",
    "        bereits_comments.append(comment)\n",
    "\n",
    "    ### Int which shows how many comments (manual random sampled + active learn sampled) we already have annotated\n",
    "    progress = len(df) + len(bereits_comments)\n",
    "\n",
    "\n",
    "    ### Load in all scraped comments from web in csv, sliced on [progress: progress + number_of_comments]\n",
    "    alle_kommentare = pd.read_csv(\"shuffled_corona_relevante_kommentare.txt\", names=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\", \"topic_comment\", \"Topic_article\", \"Comment\"], \n",
    "                                    delimiter=\"\\t\", index_col=False, skiprows=progress, nrows=number_of_comments )\n",
    "    \n",
    "\n",
    "\n",
    "    ### Drop all rows that are already present in the active learned csv to we don't annotate twice\n",
    "    print(~alle_kommentare[\"Opinion\"].isin(bereits_comments))\n",
    "    alle_kommentare = alle_kommentare.loc[~alle_kommentare[\"Opinion\"].isin(bereits_comments)]\n",
    "    display(alle_kommentare)\n",
    "\n",
    "    ### Tokenize texts and get entropy, take topk \n",
    "    texte = {\"texts\" : [x for x in alle_kommentare[\"Opinion\"]]}\n",
    "    texte_ds= Dataset.from_dict(texte)\n",
    "    tokenized_text = texte_ds.map(preprocess_function, batched=True)\n",
    "    entropies = calculate_entropy(trainer.predict(tokenized_text).predictions)\n",
    "    indexes = torch.topk(entropies, int(number_of_comments/10)).indices\n",
    "    \n",
    "    # if os.path.isfile('annotated_data/active_learning_comments.csv'):\n",
    "    #     progress_csv =pd.read_csv(\"annotated_data/active_learning_comments.csv\",names=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\", \"topic_comment\", \"Topic_article\", \"Comment\"], encoding=\"utf-8-sig\", header=None)\n",
    "    #     print(type(progress_csv))\n",
    "    #     display(progress_csv)\n",
    "    #     for row, index in progress_csv.iterrows():\n",
    "    #         print(row, index)\n",
    "    newdf = pd.DataFrame(columns=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\", \"Topic_comment\", \"Topic_article\", \"Comment\", \"Method\"])\n",
    "    for nummer, x in enumerate(indexes):\n",
    "        print(x, nummer)\n",
    "        satz = texte[\"texts\"][x]\n",
    "        opinion = input(f\"Opinion --- {satz}\")\n",
    "        while opinion not in [\"neutral\", \"positive\", \"negative\", \"exit\"]:\n",
    "            opinion = input(f\"Opinion --- {satz}\")    \n",
    "        sentiment = input(f\"Sentiment --- {satz}\")\n",
    "        while sentiment not in [\"neutral\", \"positive\", \"negative\"]:\n",
    "            sentiment = input(f\"Sentiment --- {satz}\")\n",
    "        topic_comment = input(\"Topic comment\")\n",
    "        topic_article = input(\"Topic article\")\n",
    "\n",
    "\n",
    "        row = [alle_kommentare.loc[alle_kommentare.Opinion == satz]]\n",
    "        newdf = newdf.append(row)\n",
    "        newdf.reset_index(inplace=True, drop=True)\n",
    "        print(topic_article)\n",
    "        newdf.iloc[nummer,alle_kommentare.columns.get_loc(\"Topic_article\")] = topic_article\n",
    "        newdf.iloc[nummer,alle_kommentare.columns.get_loc(\"topic_comment\")] = topic_comment\n",
    "        newdf.iloc[nummer,alle_kommentare.columns.get_loc(\"Sentiment\")] = sentiment\n",
    "        newdf.iloc[nummer,alle_kommentare.columns.get_loc(\"Comment\")] = satz\n",
    "        newdf.iloc[nummer,alle_kommentare.columns.get_loc(\"Opinion\")] = opinion\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    newdf = newdf.drop(columns=list(newdf.columns[-2:]))\n",
    "    display(newdf)\n",
    "    newdf.to_csv(\"annotated_data/active_learning_comments.csv\", mode=\"a\", encoding=\"utf-8-sig\", index=False, header=False)\n",
    "            # df.append(line.split(\"\\t\")[0] + \"\\t\" + line.split(\"\\t\")[1] + \"\\t\" + line.split(\"\\t\")[2] + \"\\t\" + line.split(\"\\t\")[3] + \"\\t\" + line.split(\"\\t\")[4] + \"\\t\" + opinion + \"\\t\"\n",
    "            #                       + sentiment + \"\\t\" + klasse1 + \"\\t\" +  klasse2 + \"\\t\" + kommentar + \"\\n\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic_article\n",
      "Comment\n"
     ]
    }
   ],
   "source": [
    "alle_kommentare = pd.read_csv(\"shuffled_corona_relevante_kommentare.txt\", names=[\"ID\", \"Date\", \"Time\", \"Comment Level\", \"Username\", \"Opinion\", \"Sentiment\", \"topic_comment\", \"Topic_article\", \"Comment\"], \n",
    "                                    delimiter=\"\\t\", index_col=False, skiprows=1100, nrows=20 )\n",
    "    \n",
    "alle_kommentare.columns.get_loc(\"Topic_article\")\n",
    "\n",
    "for x in alle_kommentare.columns[-2:]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wenn ich mir diesen Trump so betrachte und sehe dass die Zustimmung  für Donald Trump wächst, kann man sich nur wünschen, dass er und seine Befürworter an covid 19 langsam krepieren. Dann hat der Rest der USA und die Welt ein riesiges Problem weniger.', 'Alle jubeln, Söder hat einen Fehler gemacht. Die CDU ist froh einen lästigen Kanzlerkandidaten los zu sein.', 'Wenn ich mir diesen Trump so betrachte und sehe dass die Zustimmung  für Donald Trump wächst, kann man sich nur wünschen, dass er und seine Befürworter an covid 19 langsam krepieren. Dann hat der Rest der USA und die Welt ein riesiges Problem weniger.', 'Alle jubeln, Söder hat einen Fehler gemacht. Die CDU ist froh einen lästigen Kanzlerkandidaten los zu sein.']\n",
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3     False\n",
      "4      True\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8      True\n",
      "9      True\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "13     True\n",
      "14     True\n",
      "15     True\n",
      "16    False\n",
      "17     True\n",
      "18     True\n",
      "19     True\n",
      "Name: Opinion, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Comment Level</th>\n",
       "      <th>Username</th>\n",
       "      <th>Opinion</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>topic_comment</th>\n",
       "      <th>Topic_article</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b83f12db-f415-4eaf-a960-2c1c2f484791</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>11:02</td>\n",
       "      <td>0</td>\n",
       "      <td>dirk-a7uDe1XWR</td>\n",
       "      <td>Gechlossene Wissenslücke Nun wissen es alle, w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ef3ed5b3-f09a-418e-80ee-dbc95df97cb0</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>16:49</td>\n",
       "      <td>0</td>\n",
       "      <td>Nelchen</td>\n",
       "      <td>„ Erleichterungen gerade für ältere Menschen E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98736fba-91ef-4b60-9b97-87695b410138</td>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>12:22</td>\n",
       "      <td>0</td>\n",
       "      <td>shivamich</td>\n",
       "      <td>Wenn ich sowas lese, frage ich mich umso mehr,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02fdea13-f70c-4c73-8970-97db86b98840</td>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>22:16</td>\n",
       "      <td>0</td>\n",
       "      <td>Reiner-7pPeyMPZg</td>\n",
       "      <td>Da die US-Amerikaner sehr auf ihren Rechten, s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f9736a44-470c-4b06-9688-78f690927615</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>17:01</td>\n",
       "      <td>0</td>\n",
       "      <td>René-aezmU-QWg</td>\n",
       "      <td>Wann legen wir die selbstherrlichen Regionalfü...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c449c319-bd29-47f8-87fb-9ec76d99c967</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>14:39</td>\n",
       "      <td>0</td>\n",
       "      <td>Sonic</td>\n",
       "      <td>Auch da wieder: Warum braucht Deutschland mehr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c6b4377d-e8e6-40d1-a967-fd9ada3b1453</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>11:33</td>\n",
       "      <td>0</td>\n",
       "      <td>Wilfried-zvyAH0EZg</td>\n",
       "      <td>Schulleitungsvereinigung. Was es nicht alles g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8ac89f4f-ac0b-4063-8dd7-db8002fa4f30</td>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>21:36</td>\n",
       "      <td>0</td>\n",
       "      <td>Wilfried-8dD6JHiMg</td>\n",
       "      <td>Die Dame hatte die Wahl:   - als Heldin: den P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76aab31b-ad5f-4b85-9055-7d82a53831f5</td>\n",
       "      <td>2021-05-15</td>\n",
       "      <td>09:51</td>\n",
       "      <td>0</td>\n",
       "      <td>MitStaunenUndZittern</td>\n",
       "      <td>Ich finde es mutig, von der Politik zu fordern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c2bca4d7-c8b7-49a6-9cb0-6db073f7ee12</td>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>18:06</td>\n",
       "      <td>0</td>\n",
       "      <td>Ratzeputz</td>\n",
       "      <td>Ich kann nicht mehr vor Lachen. Wir haben in S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39fb99e4-48af-43e3-9c17-17132c20c431</td>\n",
       "      <td>2020-12-11</td>\n",
       "      <td>21:12</td>\n",
       "      <td>0</td>\n",
       "      <td>Lazarussuchus</td>\n",
       "      <td>Donny will nach 8 Monaten beginnen Menschen zu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0b7e52ec-0190-4833-8518-8209110e3cd5</td>\n",
       "      <td>2020-11-25</td>\n",
       "      <td>07:55</td>\n",
       "      <td>0</td>\n",
       "      <td>Kommentatorin-eiQfyzvGR</td>\n",
       "      <td>Wenn wundert es. Letzten Samstag Betrieb im Ei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0ca2dbf4-94b1-443e-80b8-78ec425a44cb</td>\n",
       "      <td>2020-08-14</td>\n",
       "      <td>07:47</td>\n",
       "      <td>0</td>\n",
       "      <td>Robana</td>\n",
       "      <td>Was heißt denn es gab keine \"Testauswertungsso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2b124ee6-4614-4a4b-96a0-e393f2cfeff9</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Steffen-OJKwh4GZg</td>\n",
       "      <td>Es geht in den Niederlanden ja gar nicht darum...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>328abe87-b1af-46ab-bbb2-e10a129f5c5e</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>05:26</td>\n",
       "      <td>0</td>\n",
       "      <td>Martin-_S_T1Z_Mg</td>\n",
       "      <td>Was sollen denn das für Wissenschaftler sein? ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cc3809f6-bc15-4a53-9f7d-340d03f3cb2a</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>13:49</td>\n",
       "      <td>0</td>\n",
       "      <td>Jakob-jJ8obZvMg</td>\n",
       "      <td>Und das soll wie genau überprüft werden? Auswe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>587af53c-33da-4aad-8c4b-001b0091f104</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>09:06</td>\n",
       "      <td>0</td>\n",
       "      <td>LiberalerOekonom</td>\n",
       "      <td>Was wirklich bei Hartz IV geändert werden müss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>d6886f29-ee3f-47df-b646-c3a652b6d499</td>\n",
       "      <td>2020-04-29</td>\n",
       "      <td>06:57</td>\n",
       "      <td>0</td>\n",
       "      <td>Erich-FmYXwIPWg</td>\n",
       "      <td>Wir lassen uns doch hier gerade wieder vorführ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID        Date   Time  Comment Level  \\\n",
       "0   b83f12db-f415-4eaf-a960-2c1c2f484791  2020-03-30  11:02              0   \n",
       "1   ef3ed5b3-f09a-418e-80ee-dbc95df97cb0  2021-04-29  16:49              0   \n",
       "2   98736fba-91ef-4b60-9b97-87695b410138  2020-12-25  12:22              0   \n",
       "4   02fdea13-f70c-4c73-8970-97db86b98840  2020-03-28  22:16              0   \n",
       "5   f9736a44-470c-4b06-9688-78f690927615  2020-12-03  17:01              0   \n",
       "6   c449c319-bd29-47f8-87fb-9ec76d99c967  2021-03-15  14:39              0   \n",
       "7   c6b4377d-e8e6-40d1-a967-fd9ada3b1453  2020-08-25  11:33              0   \n",
       "8   8ac89f4f-ac0b-4063-8dd7-db8002fa4f30  2021-03-28  21:36              0   \n",
       "9   76aab31b-ad5f-4b85-9055-7d82a53831f5  2021-05-15  09:51              0   \n",
       "10  c2bca4d7-c8b7-49a6-9cb0-6db073f7ee12  2021-02-16  18:06              0   \n",
       "11  39fb99e4-48af-43e3-9c17-17132c20c431  2020-12-11  21:12              0   \n",
       "12  0b7e52ec-0190-4833-8518-8209110e3cd5  2020-11-25  07:55              0   \n",
       "13  0ca2dbf4-94b1-443e-80b8-78ec425a44cb  2020-08-14  07:47              0   \n",
       "14  2b124ee6-4614-4a4b-96a0-e393f2cfeff9  2020-03-21  10:00              0   \n",
       "15  328abe87-b1af-46ab-bbb2-e10a129f5c5e  2021-03-30  05:26              0   \n",
       "17  cc3809f6-bc15-4a53-9f7d-340d03f3cb2a  2020-09-29  13:49              0   \n",
       "18  587af53c-33da-4aad-8c4b-001b0091f104  2021-01-25  09:06              0   \n",
       "19  d6886f29-ee3f-47df-b646-c3a652b6d499  2020-04-29  06:57              0   \n",
       "\n",
       "                   Username  \\\n",
       "0            dirk-a7uDe1XWR   \n",
       "1                   Nelchen   \n",
       "2                 shivamich   \n",
       "4          Reiner-7pPeyMPZg   \n",
       "5            René-aezmU-QWg   \n",
       "6                     Sonic   \n",
       "7        Wilfried-zvyAH0EZg   \n",
       "8        Wilfried-8dD6JHiMg   \n",
       "9      MitStaunenUndZittern   \n",
       "10                Ratzeputz   \n",
       "11            Lazarussuchus   \n",
       "12  Kommentatorin-eiQfyzvGR   \n",
       "13                   Robana   \n",
       "14        Steffen-OJKwh4GZg   \n",
       "15         Martin-_S_T1Z_Mg   \n",
       "17          Jakob-jJ8obZvMg   \n",
       "18         LiberalerOekonom   \n",
       "19          Erich-FmYXwIPWg   \n",
       "\n",
       "                                              Opinion  Sentiment  \\\n",
       "0   Gechlossene Wissenslücke Nun wissen es alle, w...        NaN   \n",
       "1   „ Erleichterungen gerade für ältere Menschen E...        NaN   \n",
       "2   Wenn ich sowas lese, frage ich mich umso mehr,...        NaN   \n",
       "4   Da die US-Amerikaner sehr auf ihren Rechten, s...        NaN   \n",
       "5   Wann legen wir die selbstherrlichen Regionalfü...        NaN   \n",
       "6   Auch da wieder: Warum braucht Deutschland mehr...        NaN   \n",
       "7   Schulleitungsvereinigung. Was es nicht alles g...        NaN   \n",
       "8   Die Dame hatte die Wahl:   - als Heldin: den P...        NaN   \n",
       "9   Ich finde es mutig, von der Politik zu fordern...        NaN   \n",
       "10  Ich kann nicht mehr vor Lachen. Wir haben in S...        NaN   \n",
       "11  Donny will nach 8 Monaten beginnen Menschen zu...        NaN   \n",
       "12  Wenn wundert es. Letzten Samstag Betrieb im Ei...        NaN   \n",
       "13  Was heißt denn es gab keine \"Testauswertungsso...        NaN   \n",
       "14  Es geht in den Niederlanden ja gar nicht darum...        NaN   \n",
       "15  Was sollen denn das für Wissenschaftler sein? ...        NaN   \n",
       "17  Und das soll wie genau überprüft werden? Auswe...        NaN   \n",
       "18  Was wirklich bei Hartz IV geändert werden müss...        NaN   \n",
       "19  Wir lassen uns doch hier gerade wieder vorführ...        NaN   \n",
       "\n",
       "    topic_comment  Topic_article  Comment  \n",
       "0             NaN            NaN      NaN  \n",
       "1             NaN            NaN      NaN  \n",
       "2             NaN            NaN      NaN  \n",
       "4             NaN            NaN      NaN  \n",
       "5             NaN            NaN      NaN  \n",
       "6             NaN            NaN      NaN  \n",
       "7             NaN            NaN      NaN  \n",
       "8             NaN            NaN      NaN  \n",
       "9             NaN            NaN      NaN  \n",
       "10            NaN            NaN      NaN  \n",
       "11            NaN            NaN      NaN  \n",
       "12            NaN            NaN      NaN  \n",
       "13            NaN            NaN      NaN  \n",
       "14            NaN            NaN      NaN  \n",
       "15            NaN            NaN      NaN  \n",
       "17            NaN            NaN      NaN  \n",
       "18            NaN            NaN      NaN  \n",
       "19            NaN            NaN      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 201.63ba/s]\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: texts.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 18\n",
      "  Batch size = 1\n",
      "91it [04:17,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [04:29,  1.12it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14696/1661534743.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_new_sample_active_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14696/3843454950.py\u001b[0m in \u001b[0;36mget_new_sample_active_learning\u001b[1;34m(number_of_comments)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0msentiment\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"neutral\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"positive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"negative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Sentiment --- {satz}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mtopic_comment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Topic comment\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mtopic_article\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Topic article\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Program Files (x86)\\Miniconda3\\envs\\Masterarbeit\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "get_new_sample_active_learning(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fb0ed09b01ac7e66b2ee8fd1b727dbc61e234ad6836f9832d0e5faf71aa1bb7a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('Masterarbeit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
